(Files content cropped to 300k characters, download full ingest to see more)
================================================
File: README.md
================================================
# About

### What's Dispatch?

Put simply, Dispatch is:

> All of the ad-hoc things youâ€™re doing to manage incidents today, done for you, and a bunch of other things you should've been doing, but have not had the time!

Dispatch helps us effectively manage security incidents by deeply integrating with existing tools used throughout an organization \(Slack, GSuite, Jira, etc.,\) Dispatch is able to leverage the existing familiarity of these tools to provide orchestration instead of introducing another tool.

This means you can let Dispatch focus on creating resources, assembling participants, sending out notifications, tracking tasks, and assisting with post-incident reviews; allowing you to focus on actually fixing the issue!

![](https://github.com/Netflix/dispatch/raw/main/docs/images/screenshots/thumb-1.png) ![](https://github.com/Netflix/dispatch/raw/main/docs/images/screenshots/thumb-2.png) ![](https://github.com/Netflix/dispatch/raw/main/docs/images/screenshots/thumb-3.png) ![](https://github.com/Netflix/dispatch/raw/main/docs/images/screenshots/thumb-4.png)

## Project resources

- [Dispatch Blog Post](https://medium.com/@NetflixTechBlog/introducing-dispatch-da4b8a2a8072)
- [Source Code](https://github.com/netflix/dispatch)
- [Docs](https://netflix.github.io/dispatch/)
- [Issue tracker](https://github.com/netflix/dispatch/issues)
- [Docker](https://github.com/Netflix/dispatch-docker)


================================================
File: Dockerfile
================================================
FROM python:3.11.10-slim-bullseye as sdist

LABEL maintainer="oss@netflix.com"
LABEL org.opencontainers.image.title="Dispatch PyPI Wheel"
LABEL org.opencontainers.image.description="PyPI Wheel Builder for Dispatch"
LABEL org.opencontainers.image.url="https://dispatch.io/"
LABEL org.opencontainers.image.source="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.vendor="Netflix, Inc."
LABEL org.opencontainers.image.authors="oss@netflix.com"

SHELL ["/bin/bash", "-o", "pipefail", "-o", "errexit", "-c"]

# Get and set up Node for front-end asset building
RUN apt-get update && apt-get install -y --no-install-recommends \
  # Needed for fetching stuff
  ca-certificates \
  wget \
  && rm -rf /var/lib/apt/lists/*

RUN wget --quiet -O - https://deb.nodesource.com/setup_20.x | bash - \
  && apt-get install -y nodejs --no-install-recommends

ARG SOURCE_COMMIT
ENV DISPATCH_BUILD=${SOURCE_COMMIT:-unknown}
LABEL org.opencontainers.image.revision=$SOURCE_COMMIT
LABEL org.opencontainers.image.licenses="https://github.com/netflix/dispatch/blob/${SOURCE_COMMIT:-main}/LICENSE"

ARG DISPATCH_LIGHT_BUILD
ENV DISPATCH_LIGHT_BUILD=${DISPATCH_LIGHT_BUILD}

RUN echo "DISPATCH_LIGHT_BUILD=${DISPATCH_LIGHT_BUILD}"

# Allow build time variables via --build-arg
ARG VITE_DISPATCH_AUTH_REGISTRATION_ENABLED
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_PKCE_CLIENT_ID
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_PKCE_OPEN_ID_CONNECT_URL
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_SLUG
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_USE_ID_TOKEN
ARG VITE_SENTRY_DSN
ARG VITE_SENTRY_APP_KEY
ARG VITE_SENTRY_ENABLED

# Should be replaced in your build process script
ARG VITE_DISPATCH_COMMIT_HASH
ENV VITE_DISPATCH_COMMIT_HASH="Unknown"

ARG VITE_DISPATCH_COMMIT_MESSAGE
ENV VITE_DISPATCH_COMMIT_MESSAGE="Unknown"

COPY . /usr/src/dispatch/
RUN YARN_CACHE_FOLDER="$(mktemp -d)" \
  && export YARN_CACHE_FOLDER \
  && pushd /usr/src/dispatch \
  && python setup.py bdist_wheel \
  && rm -r "$YARN_CACHE_FOLDER" \
  && mv /usr/src/dispatch/dist /dist

# This is the image to be run
FROM python:3.11.10-slim-bullseye

LABEL maintainer="oss@dispatch.io"
LABEL org.opencontainers.image.title="Dispatch"
LABEL org.opencontainers.image.description="Dispatch runtime image"
LABEL org.opencontainers.image.url="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.documentation="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.source="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.vendor="Netflix, Inc."
LABEL org.opencontainers.image.authors="oss@netflix.com"

SHELL ["/bin/bash", "-o", "pipefail", "-o", "errexit", "-c"]

# add our user and group first to make sure their IDs get assigned consistently
RUN groupadd -r dispatch && useradd -r -m -g dispatch dispatch

# Sane defaults for pip
ENV PIP_NO_CACHE_DIR=off \
  PIP_DISABLE_PIP_VERSION_CHECK=1 \
  # Dispatch config params
  DISPATCH_CONF=/etc/dispatch

RUN apt-get update && apt-get install -y --no-install-recommends \
  # Needed for fetching stuff
  ca-certificates \
  wget gnupg \
  && rm -rf /var/lib/apt/lists/*

RUN echo "deb http://apt.postgresql.org/pub/repos/apt bullseye-pgdg main" > /etc/apt/sources.list.d/pgdg.list \
  && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -

RUN wget --quiet -O - https://deb.nodesource.com/setup_20.x | bash -

COPY --from=sdist /dist/*.whl /tmp/dist/
RUN buildDeps="" \
  && apt-get update \
  && apt-get install -y --no-install-recommends "$buildDeps" \
  # remove internal index when internal plugins are separated
  && pip install -U /tmp/dist/*.whl \
  && apt-get purge -y --auto-remove "$buildDeps" \
  # We install run-time dependencies strictly after
  # build dependencies to prevent accidental collusion.
  # These are also installed last as they are needed
  # during container run and can have the same deps w/
  && apt-get install -y --no-install-recommends \
  pkg-config postgresql-client-14 nodejs \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/* \
  # mjml has to be installed differently here because
  # after node 14, docker will install npm files at the
  # root directoy and fail, so we have to create a new
  # directory and use it for the install then copy the
  # files to the root directory to maintain backwards
  # compatibility for email generation
  && mkdir -p /mjml_install \
  # if our workdir is /, then pushd/popd doesn't work
  # for the npm install. It still tries to install in /,
  # which npm can't do
  && cd /mjml_install \
  && npm install --no-cache-dir mjml \
  && mv node_modules / \
  && cd / \
  && rm -rf /mjml_install

EXPOSE 8000
VOLUME /var/lib/dispatch/files

ENTRYPOINT ["dispatch"]
CMD ["server", "start", "dispatch.main:app", "--host=0.0.0.0"]

ARG SOURCE_COMMIT
LABEL org.opencontainers.image.revision=$SOURCE_COMMIT
LABEL org.opencontainers.image.licenses="https://github.com/netflix/dispatch/blob/${SOURCE_COMMIT:-main}/LICENSE"


================================================
File: Dockerfile
================================================
FROM python:3.11.10-slim-bullseye as sdist

LABEL maintainer="oss@netflix.com"
LABEL org.opencontainers.image.title="Dispatch PyPI Wheel"
LABEL org.opencontainers.image.description="PyPI Wheel Builder for Dispatch"
LABEL org.opencontainers.image.url="https://dispatch.io/"
LABEL org.opencontainers.image.source="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.vendor="Netflix, Inc."
LABEL org.opencontainers.image.authors="oss@netflix.com"

SHELL ["/bin/bash", "-o", "pipefail", "-o", "errexit", "-c"]

# Get and set up Node for front-end asset building
RUN apt-get update && apt-get install -y --no-install-recommends \
  # Needed for fetching stuff
  ca-certificates \
  wget \
  && rm -rf /var/lib/apt/lists/*

RUN wget --quiet -O - https://deb.nodesource.com/setup_20.x | bash - \
  && apt-get install -y nodejs --no-install-recommends

ARG SOURCE_COMMIT
ENV DISPATCH_BUILD=${SOURCE_COMMIT:-unknown}
LABEL org.opencontainers.image.revision=$SOURCE_COMMIT
LABEL org.opencontainers.image.licenses="https://github.com/netflix/dispatch/blob/${SOURCE_COMMIT:-main}/LICENSE"

ARG DISPATCH_LIGHT_BUILD
ENV DISPATCH_LIGHT_BUILD=${DISPATCH_LIGHT_BUILD}

RUN echo "DISPATCH_LIGHT_BUILD=${DISPATCH_LIGHT_BUILD}"

# Allow build time variables via --build-arg
ARG VITE_DISPATCH_AUTH_REGISTRATION_ENABLED
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_PKCE_CLIENT_ID
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_PKCE_OPEN_ID_CONNECT_URL
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_SLUG
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_USE_ID_TOKEN
ARG VITE_SENTRY_DSN
ARG VITE_SENTRY_APP_KEY
ARG VITE_SENTRY_ENABLED

# Should be replaced in your build process script
ARG VITE_DISPATCH_COMMIT_HASH
ENV VITE_DISPATCH_COMMIT_HASH="Unknown"

ARG VITE_DISPATCH_COMMIT_MESSAGE
ENV VITE_DISPATCH_COMMIT_MESSAGE="Unknown"

COPY . /usr/src/dispatch/
RUN YARN_CACHE_FOLDER="$(mktemp -d)" \
  && export YARN_CACHE_FOLDER \
  && pushd /usr/src/dispatch \
  && python setup.py bdist_wheel \
  && rm -r "$YARN_CACHE_FOLDER" \
  && mv /usr/src/dispatch/dist /dist

# This is the image to be run
FROM python:3.11.10-slim-bullseye

LABEL maintainer="oss@dispatch.io"
LABEL org.opencontainers.image.title="Dispatch"
LABEL org.opencontainers.image.description="Dispatch runtime image"
LABEL org.opencontainers.image.url="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.documentation="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.source="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.vendor="Netflix, Inc."
LABEL org.opencontainers.image.authors="oss@netflix.com"

SHELL ["/bin/bash", "-o", "pipefail", "-o", "errexit", "-c"]

# add our user and group first to make sure their IDs get assigned consistently
RUN groupadd -r dispatch && useradd -r -m -g dispatch dispatch

# Sane defaults for pip
ENV PIP_NO_CACHE_DIR=off \
  PIP_DISABLE_PIP_VERSION_CHECK=1 \
  # Dispatch config params
  DISPATCH_CONF=/etc/dispatch

RUN apt-get update && apt-get install -y --no-install-recommends \
  # Needed for fetching stuff
  ca-certificates \
  wget gnupg \
  && rm -rf /var/lib/apt/lists/*

RUN echo "deb http://apt.postgresql.org/pub/repos/apt bullseye-pgdg main" > /etc/apt/sources.list.d/pgdg.list \
  && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -

RUN wget --quiet -O - https://deb.nodesource.com/setup_20.x | bash -

COPY --from=sdist /dist/*.whl /tmp/dist/
RUN buildDeps="" \
  && apt-get update \
  && apt-get install -y --no-install-recommends "$buildDeps" \
  # remove internal index when internal plugins are separated
  && pip install -U /tmp/dist/*.whl \
  && apt-get purge -y --auto-remove "$buildDeps" \
  # We install run-time dependencies strictly after
  # build dependencies to prevent accidental collusion.
  # These are also installed last as they are needed
  # during container run and can have the same deps w/
  && apt-get install -y --no-install-recommends \
  pkg-config postgresql-client-14 nodejs \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/* \
  # mjml has to be installed differently here because
  # after node 14, docker will install npm files at the
  # root directoy and fail, so we have to create a new
  # directory and use it for the install then copy the
  # files to the root directory to maintain backwards
  # compatibility for email generation
  && mkdir -p /mjml_install \
  # if our workdir is /, then pushd/popd doesn't work
  # for the npm install. It still tries to install in /,
  # which npm can't do
  && cd /mjml_install \
  && npm install --no-cache-dir mjml \
  && mv node_modules / \
  && cd / \
  && rm -rf /mjml_install

EXPOSE 8000
VOLUME /var/lib/dispatch/files

ENTRYPOINT ["dispatch"]
CMD ["server", "start", "dispatch.main:app", "--host=0.0.0.0"]

ARG SOURCE_COMMIT
LABEL org.opencontainers.image.revision=$SOURCE_COMMIT
LABEL org.opencontainers.image.licenses="https://github.com/netflix/dispatch/blob/${SOURCE_COMMIT:-main}/LICENSE"


================================================
File: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright 2020 Netflix, Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.


================================================
File: MANIFEST.in
================================================
include setup.py README.md MANIFEST.in LICENSE AUTHORS
recursive-include ./ requirements*.txt
graft src/dispatch
global-exclude *~


================================================
File: playwright.config.ts
================================================
import type { PlaywrightTestConfig } from "@playwright/test"
import { devices } from "@playwright/test"

/**
 * @see https://playwright.dev/docs/test-configuration
 */
const config: PlaywrightTestConfig = {
  testDir: "./tests/static/e2e",
  outputDir: "./tests/static/e2e/artifacts/test-failures",
  use: {
    /* Maximum time each action such as `click()` can take. Defaults to 0 (no limit). */
    actionTimeout: 0,
    /* Base URL to use in actions like `await page.goto('/')`. */
    baseURL: "http://localhost:8080/",
    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: "on",
    video: "on",
    screenshot: "on",
  },
  /* Maximum time one test can run for. */
  timeout: 200 * 1000,
  expect: {
    /**
     * Maximum time expect() should wait for the condition to be met.
     * For example in `await expect(locator).toHaveText();`
     */
    timeout: 20000,
  },
  /* Run tests in files in parallel */
  fullyParallel: true,
  /* Fail the build on CI if you accidentally left test.only in the source code. */
  forbidOnly: !!process.env.CI,
  /* Retry on CI only */
  retries: process.env.CI ? 2 : 0,
  /* Opt out of parallel tests on CI. */
  workers: process.env.CI ? 1 : undefined,
  /* Reporter to use. See https://playwright.dev/docs/test-reporters */
  reporter: "html",
  /* Configure projects for major browsers */
  projects: [
    {
      name: "chromium",
      use: {
        ...devices["Desktop Chrome"],
      },
    },

    {
      name: "firefox",
      use: {
        ...devices["Desktop Firefox"],
      },
    },

    {
      name: "webkit",
      use: {
        ...devices["Desktop Safari"],
      },
    },
  ],
  /* Folder for test artifacts such as screenshots, videos, traces, etc. */
  // outputDir: 'test-results/',

  /* Run your local dev server before starting the tests */
  webServer: {
    command: "dispatch server develop",
    url: "http://localhost:8080/",
    reuseExistingServer: !process.env.CI,
  },
}

export default config


================================================
File: pyproject.toml
================================================
[tool.black]
line-length = 100
target_version = ['py311']
include = '\.pyi?$'

[tool.ruff]
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    # "I",  # isort
    "C",  # flake8-comprehensions
    "B",  # flake8-bugbear
]
ignore = [
    "E501",  # line too long, handled by black
    "B008",  # do not perform function calls in argument defaults
    "C901",  # complexity
]

# Allow autofix for all enabled rules (when `--fix`) is provided.
fixable = ["A", "B", "C", "D", "E", "F"]
unfixable = []

# Exclude a variety of commonly ignored directories.
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".hg",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "venv",
]

# Same as Black.
line-length = 100

# Allow unused variables when underscore-prefixed.
dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"

# Assume Python 3.11
target-version = "py311"

[tool.ruff.mccabe]
# Unlike Flake8, default to a complexity level of 10.
max-complexity = 10

[tool.ruff.isort]
known-third-party = ["fastapi", "pydantic", "starlette"]

[tool.ruff.per-file-ignores]
"tests/conftest.py" = ["E402"]
"src/dispatch/entity/service.py" = ["W605"]


================================================
File: requirements-base.in
================================================
aiocache
aiofiles
aiohttp
alembic
atlassian-python-api==3.32.0
attrs==22.1.0
bcrypt
blockkit
boto3
cachetools
chardet
click
cryptography<40,>=38.0.0
duo-client
email-validator
emails
fastapi
google-api-python-client
google-auth-oauthlib
h11
httpx
jinja2
jira==2.0.0
joblib
jsonpath_ng
lxml==5.3.0
markdown
msal
numpy
oauth2client
openai
pandas
pdpyras
protobuf<4.24.0,>=3.6.1
psycopg2-binary
pyarrow
pydantic==1.*
pyparsing
python-dateutil
python-jose
python-multipart
python-slugify
pytz
requests
schedule
schemathesis
sentry-asgi
sentry-sdk==1.45.0
sh
slack_sdk
slack-bolt
slowapi
spacy
sqlalchemy-filters
sqlalchemy-utils
sqlalchemy<1.4  # NOTE temporarily until https://github.com/kvesteri/sqlalchemy-utils/issues/505 is fixed
statsmodels
tabulate
tenacity
uvicorn
uvloop
validators==0.18.2


================================================
File: requirements-base.txt
================================================
#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile requirements-base.in
#
aiocache==0.12.3
    # via -r requirements-base.in
aiofiles==24.1.0
    # via -r requirements-base.in
aiohappyeyeballs==2.4.3
    # via aiohttp
aiohttp==3.11.11
    # via -r requirements-base.in
aiosignal==1.3.1
    # via aiohttp
alembic==1.14.0
    # via -r requirements-base.in
anyio==4.6.2.post1
    # via
    #   httpx
    #   openai
    #   starlette
atlassian-python-api==3.32.0
    # via -r requirements-base.in
attrs==22.1.0
    # via
    #   -r requirements-base.in
    #   aiohttp
    #   hypothesis
    #   jsonschema
backoff==2.2.1
    # via schemathesis
bcrypt==4.2.1
    # via -r requirements-base.in
blis==1.0.1
    # via thinc
blockkit==1.5.2
    # via -r requirements-base.in
boto3==1.35.56
    # via -r requirements-base.in
botocore==1.35.56
    # via
    #   boto3
    #   s3transfer
cachetools==5.5.0
    # via
    #   -r requirements-base.in
    #   google-auth
    #   premailer
catalogue==2.0.10
    # via
    #   spacy
    #   srsly
    #   thinc
certifi==2024.8.30
    # via
    #   httpcore
    #   httpx
    #   requests
    #   sentry-sdk
cffi==1.17.1
    # via cryptography
chardet==5.2.0
    # via
    #   -r requirements-base.in
    #   emails
charset-normalizer==3.4.0
    # via requests
click==8.1.8
    # via
    #   -r requirements-base.in
    #   schemathesis
    #   typer
    #   uvicorn
cloudpathlib==0.20.0
    # via weasel
colorama==0.4.6
    # via schemathesis
confection==0.1.5
    # via
    #   thinc
    #   weasel
cryptography==39.0.2
    # via
    #   -r requirements-base.in
    #   msal
    #   oauthlib
    #   pyjwt
cssselect==1.2.0
    # via premailer
cssutils==2.11.1
    # via
    #   emails
    #   premailer
cymem==2.0.8
    # via
    #   preshed
    #   spacy
    #   thinc
decorator==5.1.1
    # via validators
defusedxml==0.7.1
    # via jira
deprecated==1.2.14
    # via
    #   atlassian-python-api
    #   limits
distro==1.9.0
    # via openai
dnspython==2.7.0
    # via email-validator
duo-client==5.3.0
    # via -r requirements-base.in
ecdsa==0.19.0
    # via python-jose
email-validator==2.2.0
    # via -r requirements-base.in
emails==0.6
    # via -r requirements-base.in
fastapi==0.115.6
    # via -r requirements-base.in
frozenlist==1.5.0
    # via
    #   aiohttp
    #   aiosignal
google-api-core==2.22.0
    # via google-api-python-client
google-api-python-client==2.158.0
    # via -r requirements-base.in
google-auth==2.36.0
    # via
    #   google-api-core
    #   google-api-python-client
    #   google-auth-httplib2
    #   google-auth-oauthlib
google-auth-httplib2==0.2.0
    # via google-api-python-client
google-auth-oauthlib==1.2.1
    # via -r requirements-base.in
googleapis-common-protos==1.65.0
    # via google-api-core
graphql-core==3.2.5
    # via hypothesis-graphql
h11==0.14.0
    # via
    #   -r requirements-base.in
    #   httpcore
    #   uvicorn
httpcore==1.0.6
    # via httpx
httplib2==0.22.0
    # via
    #   google-api-python-client
    #   google-auth-httplib2
    #   oauth2client
httpx==0.28.1
    # via
    #   -r requirements-base.in
    #   openai
    #   schemathesis
hypothesis==6.91.0
    # via
    #   hypothesis-graphql
    #   hypothesis-jsonschema
    #   schemathesis
hypothesis-graphql==0.11.1
    # via schemathesis
hypothesis-jsonschema==0.22.1
    # via schemathesis
idna==3.10
    # via
    #   anyio
    #   email-validator
    #   httpx
    #   requests
    #   yarl
importlib-resources==6.4.5
    # via limits
iniconfig==2.0.0
    # via pytest
jinja2==3.1.5
    # via
    #   -r requirements-base.in
    #   spacy
jira==2.0.0
    # via -r requirements-base.in
jiter==0.7.0
    # via openai
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
joblib==1.4.2
    # via -r requirements-base.in
jsonpath-ng==1.7.0
    # via -r requirements-base.in
jsonschema==4.17.3
    # via
    #   hypothesis-jsonschema
    #   schemathesis
junit-xml==1.9
    # via schemathesis
langcodes==3.4.1
    # via spacy
language-data==1.2.0
    # via langcodes
limits==3.13.0
    # via slowapi
lxml==5.3.0
    # via
    #   -r requirements-base.in
    #   emails
    #   premailer
mako==1.3.6
    # via alembic
marisa-trie==1.2.1
    # via language-data
markdown==3.7
    # via -r requirements-base.in
markdown-it-py==3.0.0
    # via rich
markupsafe==3.0.2
    # via
    #   jinja2
    #   mako
    #   werkzeug
mdurl==0.1.2
    # via markdown-it-py
more-itertools==10.5.0
    # via cssutils
msal==1.31.1
    # via -r requirements-base.in
multidict==6.1.0
    # via
    #   aiohttp
    #   yarl
murmurhash==1.0.10
    # via
    #   preshed
    #   spacy
    #   thinc
numpy==2.0.2
    # via
    #   -r requirements-base.in
    #   blis
    #   pandas
    #   patsy
    #   scipy
    #   spacy
    #   statsmodels
    #   thinc
oauth2client==4.1.3
    # via -r requirements-base.in
oauthlib[signedtoken]==3.2.2
    # via
    #   atlassian-python-api
    #   jira
    #   requests-oauthlib
openai==1.59.6
    # via -r requirements-base.in
packaging==24.2
    # via
    #   limits
    #   pytest
    #   spacy
    #   statsmodels
    #   thinc
    #   weasel
pandas==2.2.3
    # via
    #   -r requirements-base.in
    #   statsmodels
patsy==0.5.6
    # via statsmodels
pbr==6.1.0
    # via jira
pdpyras==5.4.0
    # via -r requirements-base.in
pluggy==1.5.0
    # via pytest
ply==3.11
    # via jsonpath-ng
premailer==3.10.0
    # via emails
preshed==3.0.9
    # via
    #   spacy
    #   thinc
propcache==0.2.0
    # via
    #   aiohttp
    #   yarl
proto-plus==1.25.0
    # via google-api-core
protobuf==4.23.4
    # via
    #   -r requirements-base.in
    #   google-api-core
    #   googleapis-common-protos
    #   proto-plus
psycopg2-binary==2.9.10
    # via -r requirements-base.in
pyarrow==18.1.0
    # via -r requirements-base.in
pyasn1==0.6.1
    # via
    #   oauth2client
    #   pyasn1-modules
    #   python-jose
    #   rsa
pyasn1-modules==0.4.1
    # via
    #   google-auth
    #   oauth2client
pycparser==2.22
    # via cffi
pydantic==1.10.20
    # via
    #   -r requirements-base.in
    #   blockkit
    #   confection
    #   fastapi
    #   openai
    #   spacy
    #   thinc
    #   weasel
pygments==2.18.0
    # via rich
pyjwt[crypto]==2.9.0
    # via
    #   msal
    #   oauthlib
    #   pyjwt
pyparsing==3.2.1
    # via
    #   -r requirements-base.in
    #   httplib2
pyrate-limiter==2.10.0
    # via schemathesis
pyrsistent==0.20.0
    # via jsonschema
pytest==7.4.4
    # via
    #   pytest-subtests
    #   schemathesis
pytest-subtests==0.7.0
    # via schemathesis
python-dateutil==2.9.0.post0
    # via
    #   -r requirements-base.in
    #   botocore
    #   emails
    #   pandas
python-jose==3.3.0
    # via -r requirements-base.in
python-multipart==0.0.20
    # via -r requirements-base.in
python-slugify==8.0.4
    # via -r requirements-base.in
pytz==2024.2
    # via
    #   -r requirements-base.in
    #   pandas
pyyaml==6.0.2
    # via schemathesis
requests==2.32.3
    # via
    #   -r requirements-base.in
    #   atlassian-python-api
    #   emails
    #   google-api-core
    #   jira
    #   msal
    #   pdpyras
    #   premailer
    #   requests-oauthlib
    #   requests-toolbelt
    #   schemathesis
    #   spacy
    #   starlette-testclient
    #   weasel
requests-oauthlib==2.0.0
    # via
    #   atlassian-python-api
    #   google-auth-oauthlib
    #   jira
requests-toolbelt==1.0.0
    # via jira
rich==13.9.4
    # via typer
rsa==4.9
    # via
    #   google-auth
    #   oauth2client
    #   python-jose
s3transfer==0.10.3
    # via boto3
schedule==1.2.2
    # via -r requirements-base.in
schemathesis==3.21.2
    # via -r requirements-base.in
scipy==1.14.1
    # via statsmodels
sentry-asgi==0.2.0
    # via -r requirements-base.in
sentry-sdk==1.45.0
    # via
    #   -r requirements-base.in
    #   sentry-asgi
sh==2.1.0
    # via -r requirements-base.in
shellingham==1.5.4
    # via typer
six==1.16.0
    # via
    #   atlassian-python-api
    #   duo-client
    #   ecdsa
    #   jira
    #   junit-xml
    #   oauth2client
    #   patsy
    #   python-dateutil
    #   sqlalchemy-filters
    #   validators
slack-bolt==1.22.0
    # via -r requirements-base.in
slack-sdk==3.34.0
    # via
    #   -r requirements-base.in
    #   slack-bolt
slowapi==0.1.9
    # via -r requirements-base.in
smart-open==7.0.5
    # via weasel
sniffio==1.3.1
    # via
    #   anyio
    #   openai
sortedcontainers==2.4.0
    # via hypothesis
spacy==3.8.3
    # via -r requirements-base.in
spacy-legacy==3.0.12
    # via spacy
spacy-loggers==1.0.5
    # via spacy
sqlalchemy==1.3.24
    # via
    #   -r requirements-base.in
    #   alembic
    #   sqlalchemy-filters
    #   sqlalchemy-utils
sqlalchemy-filters==0.13.0
    # via -r requirements-base.in
sqlalchemy-utils==0.41.2
    # via -r requirements-base.in
srsly==2.4.8
    # via
    #   confection
    #   spacy
    #   thinc
    #   weasel
starlette==0.41.2
    # via
    #   fastapi
    #   schemathesis
    #   starlette-testclient
starlette-testclient==0.2.0
    # via schemathesis
statsmodels==0.14.4
    # via -r requirements-base.in
tabulate==0.9.0
    # via -r requirements-base.in
tenacity==9.0.0
    # via -r requirements-base.in
text-unidecode==1.3
    # via python-slugify
thinc==8.3.2
    # via spacy
tomli==2.0.2
    # via schemathesis
tomli-w==1.1.0
    # via schemathesis
tqdm==4.67.0
    # via
    #   openai
    #   spacy
typer==0.13.0
    # via
    #   spacy
    #   weasel
typing-extensions==4.12.2
    # via
    #   alembic
    #   fastapi
    #   limits
    #   openai
    #   pydantic
    #   schemathesis
    #   typer
tzdata==2024.2
    # via pandas
uritemplate==4.1.1
    # via google-api-python-client
urllib3==2.2.3
    # via
    #   botocore
    #   pdpyras
    #   requests
    #   sentry-sdk
uvicorn==0.34.0
    # via -r requirements-base.in
uvloop==0.21.0
    # via -r requirements-base.in
validators==0.18.2
    # via -r requirements-base.in
wasabi==1.1.3
    # via
    #   spacy
    #   thinc
    #   weasel
weasel==0.4.1
    # via spacy
werkzeug==3.1.3
    # via schemathesis
wrapt==1.16.0
    # via
    #   deprecated
    #   smart-open
yarl==1.17.1
    # via
    #   aiohttp
    #   schemathesis

# The following packages are considered to be unsafe in a requirements file:
# setuptools


================================================
File: requirements-dev.in
================================================
attrs==22.1.0
black
click
coverage
devtools
easydict
factory-boy
faker
ipython
pre-commit
pytest==7.4.4
pytest-mock
ruff
vulture


================================================
File: requirements-dev.txt
================================================
#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile requirements-dev.in
#
asttokens==2.4.1
    # via
    #   devtools
    #   stack-data
attrs==22.1.0
    # via -r requirements-dev.in
black==24.10.0
    # via -r requirements-dev.in
cfgv==3.4.0
    # via pre-commit
click==8.1.8
    # via
    #   -r requirements-dev.in
    #   black
coverage==7.6.10
    # via -r requirements-dev.in
decorator==5.1.1
    # via ipython
devtools==0.12.2
    # via -r requirements-dev.in
distlib==0.3.9
    # via virtualenv
easydict==1.13
    # via -r requirements-dev.in
executing==2.1.0
    # via
    #   devtools
    #   stack-data
factory-boy==3.3.1
    # via -r requirements-dev.in
faker==33.3.0
    # via
    #   -r requirements-dev.in
    #   factory-boy
filelock==3.16.1
    # via virtualenv
identify==2.6.1
    # via pre-commit
iniconfig==2.0.0
    # via pytest
ipython==8.31.0
    # via -r requirements-dev.in
jedi==0.19.1
    # via ipython
matplotlib-inline==0.1.7
    # via ipython
mypy-extensions==1.0.0
    # via black
nodeenv==1.9.1
    # via pre-commit
packaging==24.2
    # via
    #   black
    #   pytest
parso==0.8.4
    # via jedi
pathspec==0.12.1
    # via black
pexpect==4.9.0
    # via ipython
platformdirs==4.3.6
    # via
    #   black
    #   virtualenv
pluggy==1.5.0
    # via pytest
pre-commit==4.0.1
    # via -r requirements-dev.in
prompt-toolkit==3.0.48
    # via ipython
ptyprocess==0.7.0
    # via pexpect
pure-eval==0.2.3
    # via stack-data
pygments==2.18.0
    # via
    #   devtools
    #   ipython
pytest==7.4.4
    # via
    #   -r requirements-dev.in
    #   pytest-mock
pytest-mock==3.14.0
    # via -r requirements-dev.in
python-dateutil==2.9.0.post0
    # via faker
pyyaml==6.0.2
    # via pre-commit
ruff==0.8.6
    # via -r requirements-dev.in
six==1.16.0
    # via
    #   asttokens
    #   python-dateutil
stack-data==0.6.3
    # via ipython
traitlets==5.14.3
    # via
    #   ipython
    #   matplotlib-inline
typing-extensions==4.12.2
    # via
    #   faker
    #   ipython
virtualenv==20.27.1
    # via pre-commit
vulture==2.14
    # via -r requirements-dev.in
wcwidth==0.2.13
    # via prompt-toolkit


================================================
File: setup.cfg
================================================
[tool:pytest]
python_files = test*.py
addopts = --tb=native -p no:doctest -p no:warnings
norecursedirs = bin dist docs htmlcov script hooks node_modules .* {args}
looponfailroots = src tests
selenium_driver = chrome
self-contained-html = true

[coverage:run]
omit =
    dispatch/migrations/*
source =
    src
    tests

[black]
line_length=100


================================================
File: setup.py
================================================
#!/usr/bin/env python
import datetime
import json
import os
import os.path
import shutil
import sys
import traceback
from distutils import log
from distutils.command.build import build as BuildCommand
from distutils.core import Command
from subprocess import check_output

from setuptools import find_packages, setup
from setuptools.command.develop import develop as DevelopCommand
from setuptools.command.sdist import sdist as SDistCommand

ROOT_PATH = os.path.abspath(os.path.dirname(__file__))


# modified from:
# https://raw.githubusercontent.com/getsentry/sentry/055cfe74bb88bbb2083f37f5df21b91d0ef4f9a7/src/sentry/utils/distutils/commands/base.py
class BaseBuildCommand(Command):
    user_options = [
        ("work-path=", "w", "The working directory for source files. Defaults to ."),
        ("build-lib=", "b", "directory for script runtime modules"),
        (
            "inplace",
            "i",
            "ignore build-lib and put compiled javascript files into the source "
            + "directory alongside your pure Python modules",
        ),
        (
            "force",
            "f",
            "Force rebuilding of static content. Defaults to rebuilding on version "
            "change detection.",
        ),
    ]

    boolean_options = ["force"]

    def initialize_options(self):
        self.build_lib = None
        self.force = None
        self.work_path = os.path.join(ROOT_PATH, "src/dispatch/static/dispatch")
        self.inplace = None

    def get_root_path(self):
        return os.path.abspath(os.path.dirname(sys.modules["__main__"].__file__))

    def get_dist_paths(self):
        return []

    def get_manifest_additions(self):
        return []

    def finalize_options(self):
        # This requires some explanation.  Basically what we want to do
        # here is to control if we want to build in-place or into the
        # build-lib folder.  Traditionally this is set by the `inplace`
        # command line flag for build_ext.  However as we are a subcommand
        # we need to grab this information from elsewhere.
        #
        # An in-place build puts the files generated into the source
        # folder, a regular build puts the files into the build-lib
        # folder.
        #
        # The following situations we need to cover:
        #
        #   command                         default in-place
        #   setup.py build_js               0
        #   setup.py build_ext              value of in-place for build_ext
        #   setup.py build_ext --inplace    1
        #   pip install --editable .        1
        #   setup.py install                0
        #   setup.py sdist                  0
        #   setup.py bdist_wheel            0
        #
        # The way this is achieved is that build_js is invoked by two
        # subcommands: bdist_ext (which is in our case always executed
        # due to a custom distribution) or sdist.
        #
        # Note: at one point install was an in-place build but it's not
        # quite sure why.  In case a version of install breaks again:
        # installations via pip from git URLs definitely require the
        # in-place flag to be disabled.  So we might need to detect
        # that separately.
        #
        # To find the default value of the inplace flag we inspect the
        # sdist and build_ext commands.
        sdist = self.distribution.get_command_obj("sdist")
        build_ext = self.get_finalized_command("build_ext")

        # If we are not decided on in-place we are inplace if either
        # build_ext is inplace or we are invoked through the install
        # command (easiest check is to see if it's finalized).
        if self.inplace is None:
            self.inplace = (build_ext.inplace or sdist.finalized) and 1 or 0

        # If we're coming from sdist, clear the hell out of the dist
        # folder first.
        if sdist.finalized:
            for path in self.get_dist_paths():
                try:
                    shutil.rmtree(path)
                except (OSError, IOError):
                    pass

        # In place means build_lib is src.  We also log this.
        if self.inplace:
            log.debug("in-place js building enabled")
            self.build_lib = "src"
        # Otherwise we fetch build_lib from the build command.
        else:
            self.set_undefined_options("build", ("build_lib", "build_lib"))
            log.debug("regular js build: build path is %s" % self.build_lib)

        if self.work_path is None:
            self.work_path = self.get_root_path()

    def _needs_built(self):
        for path in self.get_dist_paths():
            if not os.path.isdir(path):
                return True
        return False

    def _setup_git(self):
        work_path = self.work_path

        if os.path.exists(os.path.join(work_path, ".git")):
            log.info("initializing git submodules")
            self._run_command(["git", "submodule", "init"])
            self._run_command(["git", "submodule", "update"])

    def _setup_js_deps(self):
        node_version = None
        try:
            node_version = self._run_command(["node", "--version"]).decode("utf-8").rstrip()
        except OSError:
            log.fatal("Cannot find node executable. Please install node" " and try again.")
            sys.exit(1)

        if node_version[2] is not None:
            log.info("using node ({0})".format(node_version))
            self._run_npm_command(["install"])
            self._run_npm_command(["run", "build", "--quiet"])

    def _run_command(self, cmd, env=None):
        cmd_str = " ".join(cmd)
        log.debug(f"running [{cmd_str}]")
        try:
            return check_output(cmd, cwd=self.work_path, env=env)
        except Exception:
            log.error(f"command failed [{cmd_str}] via [{self.work_path}]")
            raise

    def _run_npm_command(self, cmd, env=None):
        self._run_command(["npm"] + cmd, env=env)

    def update_manifests(self):
        # if we were invoked from sdist, we need to inform sdist about
        # which files we just generated.  Otherwise they will be missing
        # in the manifest.  This adds the files for what webpack generates
        # plus our own assets.json file.
        sdist = self.distribution.get_command_obj("sdist")
        if not sdist.finalized:
            return

        # The path down from here only works for sdist:

        # Use the underlying file list so that we skip the file-exists
        # check which we do not want here.
        files = sdist.filelist.files
        base = os.path.abspath(".")

        # We need to split off the local parts of the files relative to
        # the current folder.  This will chop off the right path for the
        # manifest.
        for path in self.get_dist_paths():
            for dirname, _, filenames in os.walk(os.path.abspath(path)):
                for filename in filenames:
                    filename = os.path.join(dirname, filename)
                    files.append(filename[len(base) :].lstrip(os.path.sep))

        for file in self.get_manifest_additions():
            files.append(file)

    def run(self):
        if self.force or self._needs_built():
            self._setup_git()
            self._setup_js_deps()
            self._build()
            self.update_manifests()


class BuildAssetsCommand(BaseBuildCommand):
    user_options = BaseBuildCommand.user_options + [
        (
            "asset-json-path=",
            None,
            "Relative path for JSON manifest. Defaults to {dist_name}/assets.json",
        ),
        (
            "inplace",
            "i",
            "ignore build-lib and put compiled javascript files into the source "
            + "directory alongside your pure Python modules",
        ),
        (
            "force",
            "f",
            "Force rebuilding of static content. Defaults to rebuilding on version "
            "change detection.",
        ),
    ]

    description = "build static media assets"

    def initialize_options(self):
        self.work_path = os.path.join(ROOT_PATH, "src/dispatch/static/dispatch")
        self.asset_json_path = os.path.join(self.work_path, "assets.json")
        BaseBuildCommand.initialize_options(self)

    def get_dist_paths(self):
        return [os.path.join(self.work_path, "/dist")]

    def get_manifest_additions(self):
        return (self.asset_json_path,)

    def _get_package_version(self):
        """
        Attempt to get the most correct current version of Dispatch.
        """
        pkg_path = os.path.join(ROOT_PATH, "src")

        sys.path.insert(0, pkg_path)
        try:
            import dispatch
        except Exception:
            version = None
            build = None
        else:
            log.info(f"pulled version information from 'dispatch' module. {dispatch.__file__}")
            version = self.distribution.get_version()
            build = dispatch.__build__
        finally:
            sys.path.pop(0)

        if not (version and build):
            json_path = self.get_asset_json_path()
            try:
                with open(json_path) as fp:
                    data = json.loads(fp.read())
            except Exception:
                pass
            else:
                log.info("pulled version information from '{}'".format(json_path))
                version, build = data["version"], data["build"]

        return {"version": version, "build": build}

    def _needs_static(self, version_info):
        json_path = self.get_asset_json_path()
        if not os.path.exists(json_path):
            return True

        with open(json_path) as fp:
            data = json.load(fp)
        if data.get("version") != version_info.get("version"):
            return True
        if data.get("build") != version_info.get("build"):
            return True
        return False

    def _needs_built(self):
        if BaseBuildCommand._needs_built(self):
            return True
        version_info = self._get_package_version()
        return self._needs_static(version_info)

    def _build(self):
        version_info = self._get_package_version()
        log.info(
            "building assets for {} v{} (build {})".format(
                self.distribution.get_name(),
                version_info["version"] or "UNKNOWN",
                version_info["build"] or "UNKNOWN",
            )
        )
        if not version_info["version"] or not version_info["build"]:
            log.fatal("Could not determine dispatch version or build")
            sys.exit(1)

        try:
            self._build_static()
        except Exception:
            traceback.print_exc()
            log.fatal("unable to build Dispatch's static assets!")
            sys.exit(1)

        log.info("writing version manifest")
        manifest = self._write_version_file(version_info)
        log.info("recorded manifest\n{}".format(json.dumps(manifest, indent=2)))

    def _build_static(self):
        # By setting NODE_ENV=production, a few things happen
        #   * Vue optimizes out certain code paths
        #   * Webpack will add version strings to built/referenced assets
        env = dict(os.environ)
        env["DISPATCH_STATIC_DIST_PATH"] = self.dispatch_static_dist_path
        env["NODE_ENV"] = "production"
        # TODO: Our JS builds should not require 4GB heap space
        env["NODE_OPTIONS"] = (env.get("NODE_OPTIONS", "") + " --max-old-space-size=4096").lstrip()
        # self._run_npm_command(["webpack", "--bail"], env=env)

    def _write_version_file(self, version_info):
        manifest = {
            "createdAt": datetime.datetime.utcnow().isoformat() + "Z",
            "version": version_info["version"],
            "build": version_info["build"],
        }
        with open(self.get_asset_json_path(), "w") as fp:
            json.dump(manifest, fp)
        return manifest

    @property
    def dispatch_static_dist_path(self):
        return os.path.abspath(os.path.join(self.build_lib, "src/static/dispatch/dist"))

    def get_asset_json_path(self):
        return os.path.abspath(os.path.join(self.build_lib, self.asset_json_path))


VERSION = "0.1.0.dev0"
IS_LIGHT_BUILD = os.environ.get("DISPATCH_LIGHT_BUILD") == "1"


def get_requirements(env):
    with open("requirements-{}.txt".format(env)) as fp:
        return [
            x.strip()
            for x in fp.read().split("\n")
            if not x.strip().startswith("#")
            and not x.strip().startswith("--")
            and not x.strip() == ""
        ]


install_requires = get_requirements("base")
dev_requires = get_requirements("dev")


class DispatchSDistCommand(SDistCommand):
    # If we are not a light build we want to also execute build_assets as
    # part of our source build pipeline.
    if not IS_LIGHT_BUILD:
        sub_commands = SDistCommand.sub_commands + [("build_assets", None)]


class DispatchBuildCommand(BuildCommand):
    def run(self):
        if not IS_LIGHT_BUILD:
            self.run_command("build_assets")
        BuildCommand.run(self)


class DispatchDevelopCommand(DevelopCommand):
    def run(self):
        DevelopCommand.run(self)
        if not IS_LIGHT_BUILD:
            self.run_command("build_assets")


cmdclass = {
    "sdist": DispatchSDistCommand,
    "develop": DispatchDevelopCommand,
    "build": DispatchBuildCommand,
    "build_assets": BuildAssetsCommand,
}

# Get the long description from the README file
with open(os.path.join(ROOT_PATH, "README.md"), encoding="utf-8") as f:
    long_description = f.read()

setup(
    name="dispatch",
    version=VERSION,
    long_description=long_description,
    long_description_content_type="text/markdown",
    author="Netflix, Inc.",
    classifiers=[  # Optional
        "Development Status :: 5 - Production/Stable",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: Apache",
        "Programming Language :: Python :: 3.11.2",
    ],
    package_dir={"": "src"},
    packages=find_packages("src"),
    python_requires=">=3.11",
    install_requires=install_requires,
    extras_require={"dev": dev_requires},
    cmdclass=cmdclass,
    zip_safe=False,
    include_package_data=True,
    entry_points={
        "console_scripts": ["dispatch = dispatch.cli:entrypoint"],
        "dispatch.plugins": [
            "dispatch_atlassian_confluence = dispatch.plugins.dispatch_atlassian_confluence.plugin:ConfluencePagePlugin",
            "dispatch_atlassian_confluence_document = dispatch.plugins.dispatch_atlassian_confluence.docs.plugin:ConfluencePageDocPlugin",
            "dispatch_aws_sqs = dispatch.plugins.dispatch_aws.plugin:AWSSQSSignalConsumerPlugin",
            "dispatch_aws_alb_auth = dispatch.plugins.dispatch_core.plugin:AwsAlbAuthProviderPlugin",
            "dispatch_auth_mfa = dispatch.plugins.dispatch_core.plugin:DispatchMfaPlugin",
            "dispatch_basic_auth = dispatch.plugins.dispatch_core.plugin:BasicAuthProviderPlugin",
            "dispatch_contact = dispatch.plugins.dispatch_core.plugin:DispatchContactPlugin",
            "dispatch_header_auth = dispatch.plugins.dispatch_core.plugin:HeaderAuthProviderPlugin",
            "dispatch_participant_resolver = dispatch.plugins.dispatch_core.plugin:DispatchParticipantResolverPlugin",
            "dispatch_pkce_auth = dispatch.plugins.dispatch_core.plugin:PKCEAuthProviderPlugin",
            "dispatch_ticket = dispatch.plugins.dispatch_core.plugin:DispatchTicketPlugin",
            "duo_auth_mfa = dispatch.plugins.dispatch_duo.plugin:DuoMfaPlugin",
            "generic_workflow = dispatch.plugins.generic_workflow.plugin:GenericWorkflowPlugin",
            "github_monitor = dispatch.plugins.dispatch_github.plugin:GithubMonitorPlugin",
            "google_calendar_conference = dispatch.plugins.dispatch_google.calendar.plugin:GoogleCalendarConferencePlugin",
            "google_docs_document = dispatch.plugins.dispatch_google.docs.plugin:GoogleDocsDocumentPlugin",
            "google_drive_storage = dispatch.plugins.dispatch_google.drive.plugin:GoogleDriveStoragePlugin",
            "google_drive_task = dispatch.plugins.dispatch_google.drive.plugin:GoogleDriveTaskPlugin",
            "google_gmail_email = dispatch.plugins.dispatch_google.gmail.plugin:GoogleGmailEmailPlugin",
            "google_groups_participants = dispatch.plugins.dispatch_google.groups.plugin:GoogleGroupParticipantGroupPlugin",
            "jira_ticket = dispatch.plugins.dispatch_jira.plugin:JiraTicketPlugin",
            "openai_artificial_intelligence = dispatch.plugins.dispatch_openai.plugin:OpenAIPlugin",
            "opsgenie_oncall = dispatch.plugins.dispatch_opsgenie.plugin:OpsGenieOncallPlugin",
            "pagerduty_oncall = dispatch.plugins.dispatch_pagerduty.plugin:PagerDutyOncallPlugin",
            "slack_contact = dispatch.plugins.dispatch_slack.plugin:SlackContactPlugin",
            "slack_conversation = dispatch.plugins.dispatch_slack.plugin:SlackConversationPlugin",
            "zoom_conference = dispatch.plugins.dispatch_zoom.plugin:ZoomConferencePlugin",
            "microsoft_teams_conference = dispatch.plugins.dispatch_microsoft_teams.conference.plugin:MicrosoftTeamsConferencePlugin",
        ],
    },
)


================================================
File: tox.ini
================================================
[tox]
envlist = py311

[testenv]
deps =
    pytest
    coverage
commands =
    pytest


================================================
File: .coveragerc
================================================
[run]
omit =
    */__init__.py
    */views.py
    */scheduled.py
    src/dispatch/rate_limiter.py
    src/dispatch/plugins/dispatch_test/*
    src/dispatch/api.py
    src/dispatch/extensions.py
    src/dispatch/scheduler.py

[report]
omit =
    */__init__.py
    */views.py
    */scheduled.py
    src/dispatch/rate_limiter.py
    src/dispatch/plugins/dispatch_test/*
    src/dispatch/api.py
    src/dispatch/extensions.py
    src/dispatch/scheduler.py



================================================
File: .dockerignore
================================================
__pycache__
.git
.dockerignore
.gitignore

.cache/
.coverage
.storybook-out/
.DS_Store
.venv
*.egg-info
*.pyc
*.log
*.egg
*.db
*.pid
MANIFEST
test.conf
pip-log.txt
package.json
/.artifacts
/coverage/
/cover
/build
/env
/tmp
node_modules
/wheelhouse
/test_cli/
.idea/
*.iml
.pytest_cache/
.vscode/tags
coverage.xml
junit.xml
*.codestyle.xml
package-lock.json


================================================
File: .editorconfig
================================================
root=true

[*]
charset=utf-8
end_of_line=lf
insert_final_newline=false
indent_style=space
indent_size=2
trim_trailing_whitespace=true

[*.py]
indent_size=4

[{*.ng,*.sht,*.html,*.shtm,*.shtml,*.htm}]
indent_style=space
indent_size=2

[{*.jhm,*.xslt,*.xul,*.rng,*.xsl,*.xsd,*.ant,*.tld,*.fxml,*.jrxml,*.xml,*.jnlp,*.wsdl}]
indent_style=space
indent_size=2

[{.babelrc,.stylelintrc,jest.config,.eslintrc,.prettierrc,*.json,*.jsb3,*.jsb2,*.bowerrc}]
indent_style=space
indent_size=2

[*.svg]
indent_style=space
indent_size=2

[*.js.map]
indent_style=space
indent_size=2

[*.less]
indent_style=space
indent_size=2

[*.vue]
indent_style=space
indent_size=2

[{.analysis_options,*.yml,*.yaml}]
indent_style=space
indent_size=2


================================================
File: .gitbook.yaml
================================================
root: ./docs/


================================================
File: .nvmrc
================================================
20.18.0


================================================
File: .pre-commit-config.yaml
================================================
# Quick Start:
#
# pip install pre-commit
# pre-commit install && pre-commit install -t pre-push
# pre-commit run --all-files
#
# To Skip Checks:
#
# git commit --no-verify
fail_fast: false

default_language_version:
  python: python3.11.2

repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    # ruff version.
    rev: v0.7.0
    hooks:
      # Run the linter.
      #
      # When running with --fix, Ruff's lint hook should be placed before Ruff's formatter hook,
      # and before Black, isort, and other formatting tools, as Ruff's fix behavior can output code changes that require reformatting.
      - id: ruff
        args: [--fix]
      # Run the formatter.
      - id: ruff-format

  # Typos
  - repo: https://github.com/crate-ci/typos
    rev: v1.26.1
    hooks:
      - id: typos
        exclude: ^(data/dispatch-sample-data.dump|src/dispatch/static/dispatch/src/|src/dispatch/database/revisions/)

  # Pytest
  - repo: local
    hooks:
      - id: tests
        name: run tests
        entry: pytest -v tests/
        language: system
        types: [python]
        stages: [push]


================================================
File: .prettierrc
================================================
{
  "endOfLine": "auto",
  "printWidth": 100,
  "semi": false,
  "singleQuote": false,
  "tabWidth": 2,
  "useTabs": false
}


================================================
File: bin/run.py
================================================
import uvicorn

if __name__ == "__main__":
    uvicorn.run("dispatch.main:app", host="0.0.0.0")


================================================
File: data/update-example-data.sh
================================================
#!/usr/bin/env bash
echo "Dropping existing database..."
dispatch database drop
echo "Restoring current dump file..."
dispatch database restore --dump-file ./dispatch-sample-data.dump
echo "Running database migrations..."
dispatch database upgrade
echo "Dumping sql to file..."
dispatch database dump --dump-file ./dispatch-sample-data.dump


================================================
File: data/.env
================================================
# General
LOG_LEVEL=ERROR
STATIC_DIR=""
DATABASE_HOSTNAME=localhost
DATABASE_CREDENTIALS=dispatch:dispatch
DISPATCH_ENCRYPTION_KEY=NJHDWDJ3PbHT8h


================================================
File: docker/Dockerfile
================================================
FROM python:3.11.10-slim-bullseye as sdist

LABEL maintainer="oss@netflix.com"
LABEL org.opencontainers.image.title="Dispatch PyPI Wheel"
LABEL org.opencontainers.image.description="PyPI Wheel Builder for Dispatch"
LABEL org.opencontainers.image.url="https://dispatch.io/"
LABEL org.opencontainers.image.source="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.vendor="Netflix, Inc."
LABEL org.opencontainers.image.authors="oss@netflix.com"

SHELL ["/bin/bash", "-o", "pipefail", "-o", "errexit", "-c"]

# Get and set up Node for front-end asset building
RUN apt-get update && apt-get install -y --no-install-recommends \
  # Needed for fetching stuff
  ca-certificates \
  wget \
  && rm -rf /var/lib/apt/lists/*

RUN wget --quiet -O - https://deb.nodesource.com/setup_20.x | bash - \
  && apt-get install -y nodejs --no-install-recommends

ARG SOURCE_COMMIT
ENV DISPATCH_BUILD=${SOURCE_COMMIT:-unknown}
LABEL org.opencontainers.image.revision=$SOURCE_COMMIT
LABEL org.opencontainers.image.licenses="https://github.com/netflix/dispatch/blob/${SOURCE_COMMIT:-main}/LICENSE"

ARG DISPATCH_LIGHT_BUILD
ENV DISPATCH_LIGHT_BUILD=${DISPATCH_LIGHT_BUILD}

RUN echo "DISPATCH_LIGHT_BUILD=${DISPATCH_LIGHT_BUILD}"

# Allow build time variables via --build-arg
ARG VITE_DISPATCH_AUTH_REGISTRATION_ENABLED
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_PKCE_CLIENT_ID
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_PKCE_OPEN_ID_CONNECT_URL
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_SLUG
ARG VITE_DISPATCH_AUTHENTICATION_PROVIDER_USE_ID_TOKEN
ARG VITE_SENTRY_DSN
ARG VITE_SENTRY_APP_KEY
ARG VITE_SENTRY_ENABLED

# Should be replaced in your build process script
ARG VITE_DISPATCH_COMMIT_HASH
ENV VITE_DISPATCH_COMMIT_HASH="Unknown"

ARG VITE_DISPATCH_COMMIT_MESSAGE
ENV VITE_DISPATCH_COMMIT_MESSAGE="Unknown"

COPY . /usr/src/dispatch/
RUN YARN_CACHE_FOLDER="$(mktemp -d)" \
  && export YARN_CACHE_FOLDER \
  && pushd /usr/src/dispatch \
  && python setup.py bdist_wheel \
  && rm -r "$YARN_CACHE_FOLDER" \
  && mv /usr/src/dispatch/dist /dist

# This is the image to be run
FROM python:3.11.10-slim-bullseye

LABEL maintainer="oss@dispatch.io"
LABEL org.opencontainers.image.title="Dispatch"
LABEL org.opencontainers.image.description="Dispatch runtime image"
LABEL org.opencontainers.image.url="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.documentation="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.source="https://github.com/netflix/dispatch"
LABEL org.opencontainers.image.vendor="Netflix, Inc."
LABEL org.opencontainers.image.authors="oss@netflix.com"

SHELL ["/bin/bash", "-o", "pipefail", "-o", "errexit", "-c"]

# add our user and group first to make sure their IDs get assigned consistently
RUN groupadd -r dispatch && useradd -r -m -g dispatch dispatch

# Sane defaults for pip
ENV PIP_NO_CACHE_DIR=off \
  PIP_DISABLE_PIP_VERSION_CHECK=1 \
  # Dispatch config params
  DISPATCH_CONF=/etc/dispatch

RUN apt-get update && apt-get install -y --no-install-recommends \
  # Needed for fetching stuff
  ca-certificates \
  wget gnupg \
  && rm -rf /var/lib/apt/lists/*

RUN echo "deb http://apt.postgresql.org/pub/repos/apt bullseye-pgdg main" > /etc/apt/sources.list.d/pgdg.list \
  && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -

RUN wget --quiet -O - https://deb.nodesource.com/setup_20.x | bash -

COPY --from=sdist /dist/*.whl /tmp/dist/
RUN buildDeps="" \
  && apt-get update \
  && apt-get install -y --no-install-recommends "$buildDeps" \
  # remove internal index when internal plugins are separated
  && pip install -U /tmp/dist/*.whl \
  && apt-get purge -y --auto-remove "$buildDeps" \
  # We install run-time dependencies strictly after
  # build dependencies to prevent accidental collusion.
  # These are also installed last as they are needed
  # during container run and can have the same deps w/
  && apt-get install -y --no-install-recommends \
  pkg-config postgresql-client-14 nodejs \
  && apt-get clean \
  && rm -rf /var/lib/apt/lists/* \
  # mjml has to be installed differently here because
  # after node 14, docker will install npm files at the
  # root directoy and fail, so we have to create a new
  # directory and use it for the install then copy the
  # files to the root directory to maintain backwards
  # compatibility for email generation
  && mkdir -p /mjml_install \
  # if our workdir is /, then pushd/popd doesn't work
  # for the npm install. It still tries to install in /,
  # which npm can't do
  && cd /mjml_install \
  && npm install --no-cache-dir mjml \
  && mv node_modules / \
  && cd / \
  && rm -rf /mjml_install

EXPOSE 8000
VOLUME /var/lib/dispatch/files

ENTRYPOINT ["dispatch"]
CMD ["server", "start", "dispatch.main:app", "--host=0.0.0.0"]

ARG SOURCE_COMMIT
LABEL org.opencontainers.image.revision=$SOURCE_COMMIT
LABEL org.opencontainers.image.licenses="https://github.com/netflix/dispatch/blob/${SOURCE_COMMIT:-main}/LICENSE"


================================================
File: docker/docker-compose.yml
================================================
services:
  postgres:
    image: postgres:14.6
    hostname: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: dispatch # Default password, change it
      POSTGRES_DB: dispatch
    volumes:
      - postgres-data:/var/lib/postgresql/data
    restart: unless-stopped

  pgadmin:
    image: dpage/pgadmin4
    depends_on:
      - postgres
    ports:
      - "5555:80"
    environment:
      PGADMIN_DEFAULT_EMAIL: dispatch@netflix.com
      PGADMIN_DEFAULT_PASSWORD: admin # Default password, change it
    restart: unless-stopped

volumes:
  postgres-data:


================================================
File: docker/.dockerignore
================================================
node_modules


================================================
File: docker/.env.example
================================================
# General
DISPATCH_UI_URL=""

# Persistence
DATABASE_HOSTNAME=""
DATABASE_CREDENTIALS=""

# Authentication
# For basic authentication see: https://netflix.github.io/dispatch/administration-guide/server#configuration-for-dispatch-auth-provider-basic
# For PKCE authentication see: https://netflix.github.io/dispatch/administration-guide/server#configuration-for-dispatch-auth-provider-pkce

# For additional server configuration options see: https://netflix.github.io/dispatch/administration-guide/server


================================================
File: docs/babel.config.js
================================================
module.exports = {
  presets: [require.resolve('@docusaurus/core/lib/babel/preset')],
};


================================================
File: docs/docusaurus.config.js
================================================
// @ts-check
// Note: type annotations allow type checking and IDEs autocompletion

const lightCodeTheme = require("prism-react-renderer/themes/github")
const darkCodeTheme = require("prism-react-renderer/themes/dracula")

/** @type {import('@docusaurus/types').Config} */
const config = {
  title: "Dispatch - Documentation",
  tagline: "Incident Management for Everyone",
  favicon: "img/favicon.ico",

  // Set the production url of your site here
  url: "https://netflix.github.io/",
  // Set the /<baseUrl>/ pathname under which your site is served
  // For GitHub pages deployment, it is often '/<projectName>/'
  baseUrl: "/dispatch",

  // GitHub pages deployment config.
  // If you aren't using GitHub pages, you don't need these.
  organizationName: "netflix", // Usually your GitHub org/user name.
  projectName: "dispatch", // Usually your repo name.
  trailingSlash: false,

  onBrokenLinks: "throw",
  onBrokenMarkdownLinks: "warn",

  // Even if you don't use internalization, you can use this field to set useful
  // metadata like html lang. For example, if your site is Chinese, you may want
  // to replace "en" with "zh-Hans".
  i18n: {
    defaultLocale: "en",
    locales: ["en"],
  },
  plugins: [
    [
      require.resolve("@cmfcmf/docusaurus-search-local"),
      {
        indexPages: true,
        style: undefined,
      },
    ],
  ],

  presets: [
    [
      "classic",
      /** @type {import('@docusaurus/preset-classic').Options} */
      ({
        docs: {
          sidebarPath: require.resolve("./sidebars.js"),
          editUrl: ({ docPath }) =>
            `https://github.com/netflix/dispatch/edit/main/docs/docs/${docPath}`,
        },
        theme: {
          customCss: require.resolve("./src/css/custom.css"),
        },
      }),
    ],
    [
      "redocusaurus",
      {
        // Plugin Options for loading OpenAPI files
        specs: [
          {
            spec: "scripts/openapi.yaml",
            route: "/docs/api/",
          },
        ],
        // Theme Options for modifying how redoc renders them
        theme: {
          // Change with your site colors
          primaryColor: "#E50914",
        },
      },
    ],
  ],

  themeConfig:
    /** @type {import('@docusaurus/preset-classic').ThemeConfig} */
    ({
      // Replace with your project's social card
      image: "img/docusaurus-social-card.jpg",
      navbar: {
        title: "Dispatch",
        items: [
          { to: "/docs/user-guide", label: "User Guide", position: "left" },
          { to: "/docs/administration", label: "Administration", position: "left" },
          { to: "/docs/api", label: "API", position: "left" },
          {
            to: "/docs/support",
            label: "Support",
            position: "left",
          },

          {
            href: "https://github.com/Netflix/dispatch",
            position: "right",
            className: "header-github-link",
            "aria-label": "GitHub repository",
          },
        ],
      },
      footer: {
        style: "dark",
        links: [],
        copyright: `Copyright Â© ${new Date().getFullYear()} Dispatch Documentation Built with Docusaurus.`,
      },
      prism: {
        theme: lightCodeTheme,
        darkTheme: darkCodeTheme,
      },
    }),
}

module.exports = config


================================================
File: docs/package.json
================================================
{
  "name": "",
  "version": "0.0.0",
  "private": true,
  "scripts": {
    "docusaurus": "docusaurus",
    "start": "docusaurus start",
    "build": "docusaurus build",
    "swizzle": "docusaurus swizzle",
    "deploy": "docusaurus deploy",
    "clear": "docusaurus clear",
    "serve": "docusaurus serve",
    "write-translations": "docusaurus write-translations",
    "write-heading-ids": "docusaurus write-heading-ids"
  },
  "dependencies": {
    "@cmfcmf/docusaurus-search-local": "^1.0.0",
    "@docusaurus/core": "2.4.0",
    "@docusaurus/preset-classic": "2.4.0",
    "@mdx-js/react": "^1.6.22",
    "clsx": "^1.2.1",
    "prism-react-renderer": "^1.3.5",
    "react": "^17.0.2",
    "react-dom": "^17.0.2",
    "redocusaurus": "^1.6.1"
  },
  "devDependencies": {
    "@docusaurus/module-type-aliases": "2.4.0"
  },
  "browserslist": {
    "production": [
      ">0.5%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "engines": {
    "node": ">=16.14"
  }
}


================================================
File: docs/sidebars.js
================================================
/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */

// @ts-check

/** @type {import('@docusaurus/plugin-content-docs').SidebarsConfig} */
const sidebars = {
  // By default, Docusaurus generates a sidebar from the docs folder structure
  adminSidebar: [{ type: "autogenerated", dirName: "administration" }],
  userGuideSidebar: [{ type: "autogenerated", dirName: "user-guide" }],
}

module.exports = sidebars


================================================
File: docs/.gitignore
================================================
# Dependencies
/node_modules

# Production
/build

# Generated files
.docusaurus
.cache-loader

# Misc
.DS_Store
.env.local
.env.development.local
.env.test.local
.env.production.local

npm-debug.log*
yarn-debug.log*
yarn-error.log*


================================================
File: docs/branding/FullColor_1280x1024.eps
================================================
%!PS-Adobe-3.0 EPSF-3.0
%%Creator: cairo 1.16.0 (https://cairographics.org)
%%CreationDate: Wed Jul  1 01:02:24 2020
%%Pages: 1
%%DocumentData: Clean7Bit
%%LanguageLevel: 2
%%BoundingBox: 0 0 961 769
%%EndComments
%%BeginProlog
50 dict begin
/q { gsave } bind def
/Q { grestore } bind def
/cm { 6 array astore concat } bind def
/w { setlinewidth } bind def
/J { setlinecap } bind def
/j { setlinejoin } bind def
/M { setmiterlimit } bind def
/d { setdash } bind def
/m { moveto } bind def
/l { lineto } bind def
/c { curveto } bind def
/h { closepath } bind def
/re { exch dup neg 3 1 roll 5 3 roll moveto 0 rlineto
      0 exch rlineto 0 rlineto closepath } bind def
/S { stroke } bind def
/f { fill } bind def
/f* { eofill } bind def
/n { newpath } bind def
/W { clip } bind def
/W* { eoclip } bind def
/BT { } bind def
/ET { } bind def
/BDC { mark 3 1 roll /BDC pdfmark } bind def
/EMC { mark /EMC pdfmark } bind def
/cairo_store_point { /cairo_point_y exch def /cairo_point_x exch def } def
/Tj { show currentpoint cairo_store_point } bind def
/TJ {
  {
    dup
    type /stringtype eq
    { show } { -0.001 mul 0 cairo_font_matrix dtransform rmoveto } ifelse
  } forall
  currentpoint cairo_store_point
} bind def
/cairo_selectfont { cairo_font_matrix aload pop pop pop 0 0 6 array astore
    cairo_font exch selectfont cairo_point_x cairo_point_y moveto } bind def
/Tf { pop /cairo_font exch def /cairo_font_matrix where
      { pop cairo_selectfont } if } bind def
/Td { matrix translate cairo_font_matrix matrix concatmatrix dup
      /cairo_font_matrix exch def dup 4 get exch 5 get cairo_store_point
      /cairo_font where { pop cairo_selectfont } if } bind def
/Tm { 2 copy 8 2 roll 6 array astore /cairo_font_matrix exch def
      cairo_store_point /cairo_font where { pop cairo_selectfont } if } bind def
/g { setgray } bind def
/rg { setrgbcolor } bind def
/d1 { setcachedevice } bind def
/cairo_data_source {
  CairoDataIndex CairoData length lt
    { CairoData CairoDataIndex get /CairoDataIndex CairoDataIndex 1 add def }
    { () } ifelse
} def
/cairo_flush_ascii85_file { cairo_ascii85_file status { cairo_ascii85_file flushfile } if } def
/cairo_image { image cairo_flush_ascii85_file } def
/cairo_imagemask { imagemask cairo_flush_ascii85_file } def
%%EndProlog
%%BeginSetup
%%EndSetup
%%Page: 1 1
%%BeginPageSetup
%%PageBoundingBox: 0 0 961 769
%%EndPageSetup
q 0 0 961 769 rectclip
1 0 0 -1 0 769 cm q
0.172549 0.203922 0.266667 rg
0 0 960.023 768.02 re f
1 g
183.801 600.234 m 183.801 504.086 l 222.953 504.086 l 233.117 504.086 242.09
 506.125 249.879 510.199 c 257.656 514.277 263.699 519.953 268 527.23 c 
272.305 534.508 274.457 542.816 274.457 552.16 c 274.457 561.504 272.305
 569.816 268 577.094 c 263.699 584.367 257.656 590.047 249.879 594.121 c
 242.09 598.199 233.117 600.234 222.953 600.234 c h
193.961 591.449 m 222.395 591.449 l 230.82 591.449 238.195 589.773 244.52
 586.426 c 250.84 583.09 255.738 578.465 259.215 572.559 c 262.688 566.648
 264.426 559.852 264.426 552.16 c 264.426 544.473 262.688 537.672 259.215
 531.766 c 255.738 525.855 250.84 521.234 244.52 517.895 c 238.195 514.547
 230.82 512.875 222.395 512.875 c 193.961 512.875 l h
295.207 600.234 m 295.207 527.984 l 304.953 527.984 l 304.953 600.234 l
 h
300.141 512.195 m 298.133 512.195 296.438 511.504 295.059 510.125 c 293.691
 508.758 293.008 507.109 293.008 505.18 c 293.008 503.348 293.691 501.746
 295.059 500.379 c 296.438 499 298.133 498.312 300.141 498.312 c 302.16 
498.312 303.852 498.977 305.223 500.305 c 306.598 501.633 307.289 503.215
 307.289 505.047 c 307.289 507.066 306.598 508.758 305.223 510.125 c 303.852
 511.504 302.16 512.195 300.141 512.195 c h
351.523 600.914 m 345.656 600.914 340.043 600.07 334.688 598.375 c 329.328
 596.68 325.141 594.555 322.117 591.996 c 326.52 584.301 l 329.543 586.684
 333.344 588.629 337.922 590.133 c 342.5 591.648 347.262 592.406 352.203
 592.406 c 358.801 592.406 363.676 591.379 366.824 589.32 c 369.984 587.254
 371.566 584.344 371.566 580.594 c 371.566 577.934 370.699 575.852 368.965
 574.344 c 367.223 572.828 365.023 571.68 362.363 570.902 c 359.715 570.125
 356.191 569.371 351.789 568.645 c 345.93 567.543 341.215 566.418 337.641
 565.277 c 334.066 564.133 331.023 562.191 328.512 559.441 c 325.992 556.695
 324.73 552.895 324.73 548.039 c 324.73 541.996 327.246 537.051 332.277 
533.211 c 337.32 529.363 344.324 527.438 353.297 527.438 c 357.973 527.438
 362.645 528.059 367.312 529.297 c 371.98 530.527 375.824 532.152 378.848
 534.172 c 374.594 542 l 368.637 537.875 361.539 535.812 353.297 535.812
 c 347.074 535.812 342.383 536.914 339.219 539.121 c 336.059 541.316 334.48
 544.195 334.48 547.758 c 334.48 550.508 335.375 552.707 337.168 554.363
 c 338.949 556.008 341.172 557.219 343.828 557.996 c 346.477 558.773 350.141
 559.574 354.816 560.402 c 360.586 561.504 365.211 562.602 368.688 563.695
 c 372.16 564.797 375.137 566.676 377.605 569.324 c 380.09 571.98 381.328
 575.648 381.328 580.328 c 381.328 586.637 378.695 591.648 373.426 595.363
 c 368.16 599.062 360.859 600.914 351.523 600.914 c h
436.539 527.438 m 443.312 527.438 449.445 528.973 454.941 532.043 c 460.434
 535.105 464.742 539.43 467.863 545.012 c 470.977 550.605 472.531 556.973
 472.531 564.109 c 472.531 571.348 470.977 577.758 467.863 583.34 c 464.742
 588.922 460.461 593.25 455.016 596.32 c 449.57 599.383 443.41 600.914 436.539
 600.914 c 430.68 600.914 425.391 599.703 420.676 597.281 c 415.957 594.859
 412.09 591.309 409.066 586.633 c 409.066 626.879 l 399.316 626.879 l 399.316
 527.984 l 408.652 527.984 l 408.652 542.266 l 411.586 537.508 415.457 533.848
 420.262 531.277 c 425.066 528.715 430.492 527.438 436.539 527.438 c h
435.859 592.273 m 440.891 592.273 445.469 591.102 449.594 588.762 c 453.711
 586.426 456.934 583.109 459.27 578.805 c 461.602 574.504 462.77 569.605
 462.77 564.109 c 462.77 558.617 461.602 553.742 459.27 549.488 c 456.934
 545.223 453.711 541.902 449.594 539.52 c 445.469 537.145 440.891 535.957
 435.859 535.957 c 430.727 535.957 426.125 537.145 422.047 539.52 c 417.973
 541.902 414.766 545.223 412.434 549.488 c 410.102 553.742 408.934 558.617
 408.934 564.109 c 408.934 569.605 410.102 574.504 412.434 578.805 c 414.766
 583.109 417.973 586.426 422.047 588.762 c 426.125 591.102 430.727 592.273
 435.859 592.273 c h
548.625 527.984 m 558.371 527.984 l 558.371 600.234 l 549.039 600.234 l
 549.039 585.953 l 546.102 590.809 542.234 594.516 537.43 597.074 c 532.625
 599.637 527.199 600.914 521.152 600.914 c 514.379 600.914 508.242 599.359
 502.75 596.25 c 497.254 593.137 492.953 588.789 489.84 583.207 c 486.719
 577.625 485.16 571.258 485.16 564.109 c 485.16 556.973 486.719 550.605 
489.84 545.012 c 492.953 539.43 497.254 535.105 502.75 532.043 c 508.242
 528.973 514.379 527.438 521.152 527.438 c 527.012 527.438 532.297 528.648
 537.016 531.07 c 541.73 533.504 545.602 537.051 548.625 541.719 c h
521.98 592.273 m 527.012 592.273 531.566 591.102 535.641 588.762 c 539.719
 586.426 542.922 583.109 545.258 578.805 c 547.59 574.504 548.758 569.605
 548.758 564.109 c 548.758 558.617 547.59 553.715 545.258 549.414 c 542.922
 545.109 539.719 541.793 535.641 539.461 c 531.566 537.125 527.012 535.957
 521.98 535.957 c 516.848 535.957 512.246 537.125 508.168 539.461 c 504.094
 541.793 500.887 545.109 498.555 549.414 c 496.223 553.715 495.055 558.617
 495.055 564.109 c 495.055 569.605 496.223 574.504 498.555 578.805 c 500.887
 583.109 504.094 586.426 508.168 588.762 c 512.246 591.102 516.848 592.273
 521.98 592.273 c h
617.715 588.832 m 621.141 595.836 l 619.312 597.488 617.07 598.75 614.422
 599.617 c 611.762 600.48 608.969 600.914 606.031 600.914 c 599.258 600.914
 594.039 599.09 590.379 595.438 c 586.715 591.773 584.883 586.598 584.883
 579.914 c 584.883 512.195 l 594.633 512.195 l 594.633 527.984 l 616.477
 527.984 l 616.477 536.223 l 594.633 536.223 l 594.633 579.352 l 594.633
 583.656 595.684 586.93 597.793 589.172 c 599.898 591.418 602.965 592.543
 606.992 592.543 c 611.395 592.543 614.969 591.305 617.715 588.832 c h
666.203 600.914 m 659.055 600.914 652.664 599.359 647.035 596.25 c 641.402
 593.137 636.984 588.766 633.785 583.133 c 630.574 577.5 628.969 571.16 
628.969 564.109 c 628.969 557.059 630.574 550.742 633.785 545.16 c 636.984
 539.566 641.402 535.215 647.035 532.105 c 652.664 528.992 659.055 527.438
 666.203 527.438 c 672.426 527.438 677.992 528.648 682.895 531.07 c 687.789
 533.504 691.656 537.051 694.504 541.719 c 687.223 546.668 l 684.84 543.094
 681.816 540.414 678.152 538.633 c 674.488 536.852 670.508 535.957 666.203
 535.957 c 660.984 535.957 656.293 537.125 652.129 539.461 c 647.953 541.793
 644.699 545.109 642.367 549.414 c 640.031 553.715 638.867 558.617 638.867
 564.109 c 638.867 569.691 640.031 574.617 642.367 578.879 c 644.699 583.133
 647.953 586.426 652.129 588.762 c 656.293 591.102 660.984 592.273 666.203
 592.273 c 670.508 592.273 674.488 591.402 678.152 589.66 c 681.816 587.918
 684.84 585.266 687.223 581.699 c 694.504 586.633 l 691.656 591.309 687.762
 594.859 682.82 597.281 c 677.879 599.703 672.34 600.914 666.203 600.914
 c h
749.297 527.438 m 758.367 527.438 765.578 530.07 770.934 535.34 c 776.293
 540.605 778.969 548.277 778.969 558.348 c 778.969 600.234 l 769.223 600.234
 l 769.223 559.309 l 769.223 551.797 767.34 546.07 763.582 542.133 c 759.828
 538.195 754.473 536.223 747.512 536.223 c 739.73 536.223 733.578 538.539
 729.051 543.168 c 724.508 547.785 722.238 554.168 722.238 562.324 c 722.238
 600.234 l 712.492 600.234 l 712.492 498.312 l 722.238 498.312 l 722.238
 540.625 l 724.898 536.41 728.562 533.164 733.23 530.879 c 737.895 528.582
 743.254 527.438 749.297 527.438 c h
749.297 527.438 m f
413.59 288.078 m 409.066 279.035 399.945 260.93 388.828 238.875 c 383.273
 227.84 377.207 215.82 370.965 203.453 c 368.059 197.668 l 404.336 226.945
 432.637 252.918 432.586 252.934 c 432.262 253.125 470.973 286.145 505.828
 328.715 c 508.461 332.02 511.117 335.449 513.727 338.961 c 528.555 348.832
 541.875 360.797 549.055 377.543 c 549.09 377.543 549.125 377.543 549.152
 377.543 c 543.23 356.387 528.559 337.898 515.59 320.852 c 479.656 277.039
 440.711 243.996 440.988 243.742 c 441.02 243.691 330.172 149.75 330.172
 149.75 c 359.766 209.102 l 366.008 221.473 372.07 233.488 377.629 244.527
 c 386.09 261.293 393.398 275.762 398.434 285.703 c 403.062 287.312 408.828
 289.359 415.465 291.836 c 414.855 290.594 414.234 289.355 413.59 288.078
 c f
630.191 426.934 m 591.164 348.949 l 553.766 372.012 l 588.441 360.004 l
 591.836 366.82 614.332 411.887 614.332 411.887 c 614.332 411.887 614.367
 411.953 614.426 412.066 c 610.887 410.508 591.465 401.812 591.465 401.812
 c 542.824 431.246 l 592.309 410.391 l 630.191 426.934 l f
549.289 377.93 m 549.227 377.773 549.156 377.629 549.09 377.477 c 541.906
 360.73 528.586 348.77 513.758 338.898 c 504.527 332.746 494.719 327.41 
485.426 322.227 c 459.582 309.02 434.145 298.723 415.496 291.77 c 408.859
 289.297 403.094 287.246 398.465 285.641 c 390.699 282.949 386.156 281.496
 386.203 281.387 c 386.215 281.336 247.047 239.57 247.047 239.57 c 297.91
 282.121 l 308.582 290.973 318.945 299.562 328.449 307.441 c 347.465 323.215
 363.082 336.125 370.887 342.574 c 399.73 366.355 417.426 378.238 444.004
 395.102 c 422.508 372.105 407.547 356.918 378.832 332.984 c 371.059 326.5
 355.469 313.555 336.457 297.785 c 326.953 289.906 316.59 281.309 305.918
 272.461 c 300.934 268.336 l 345.895 280.656 382.227 293.141 382.184 293.184
 c 381.961 293.473 430.652 308.258 479.617 333.328 c 503.215 345.828 529.734
 362.203 537.383 381.871 c 540.109 390.559 536.477 401.637 533.066 409.195
 c 529.461 416.926 524.965 422.223 521.754 425.477 c 496.105 447.895 473.293
 452.074 442.93 456.656 c 458.512 459.098 472.121 458.918 486.305 456.434
 c 500.195 453.543 515.887 448.68 530.617 434.234 c 537.527 426.176 554.668
 408.617 549.289 377.93 c f
Q Q
showpage
%%Trailer
end
%%EOF


================================================
File: docs/docs/changelog.mdx
================================================
---
description: Short description of changes.
---

# Changelog

:::info
Dispatch uses the [calver](https://calver.org/) version schema.
:::

See the the "released" page on the application repository for more information about changes:

[Releases](https://github.com/Netflix/dispatch/releases)


================================================
File: docs/docs/license.mdx
================================================
---
description: >-
  Dispatch is licensed under a three clause APACHE License. Full license text
  can be found below.
---

# License

## Authors

Dispatch was originally written and maintained by Marc Vilanova and Kevin Glisson.

A list of additional contributors can be seen on GitHub.

## Full License

Apache License

Version 2.0, January 2004

[http://www.apache.org/licenses/](http://www.apache.org/licenses/)

TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

1. Definitions.

   â€œLicenseâ€ shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.

   â€œLicensorâ€ shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.

   â€œLegal Entityâ€ shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, â€œcontrolâ€ means \(i\) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or \(ii\) ownership of fifty percent \(50%\) or more of the outstanding shares, or \(iii\) beneficial ownership of such entity.

   â€œYouâ€ \(or â€œYourâ€\) shall mean an individual or Legal Entity exercising permissions granted by this License.

   â€œSourceâ€ form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.

   â€œObjectâ€ form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.

   â€œWorkâ€ shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work \(an example is provided in the Appendix below\).

   â€œDerivative Worksâ€ shall mean any work, whether in Source or Object form, that is based on \(or derived from\) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link \(or bind by name\) to the interfaces of, the Work and Derivative Works thereof.

   â€œContributionâ€ shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, â€œsubmittedâ€ means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as â€œNot a Contribution.â€

   â€œContributorâ€ shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.

2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable \(except as stated in this section\) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution\(s\) alone or by combination of their Contribution\(s\) with the Work to which such Contribution\(s\) was submitted. If You institute patent litigation against any entity \(including a cross-claim or counterclaim in a lawsuit\) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:

   1. You must give any other recipients of the Work or Derivative Works a copy of this License; and
   2. You must cause any modified files to carry prominent notices stating that You changed the files; and
   3. You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and
   4. If the Work includes a â€œNOTICEâ€ text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.

   You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.

5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.
6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.
7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work \(and each Contributor provides its Contributions\) on an â€œAS ISâ€ BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.
8. Limitation of Liability. In no event and under no legal theory, whether in tort \(including negligence\), contract, or otherwise, unless required by applicable law \(such as deliberate and grossly negligent acts\) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work \(including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses\), even if such Contributor has been advised of the possibility of such damages.
9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.

END OF TERMS AND CONDITIONS

APPENDIX: How to apply the Apache License to your work.

To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets â€œ\[\]â€ replaced with your own identifying information. \(Donâ€™t include the brackets!\) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same â€œprinted pageâ€ as the copyright notice for easier identification within third-party archives.

Copyright 2018 Netflix, Inc.

Licensed under the Apache License, Version 2.0 \(the â€œLicenseâ€\); you may not use this file except in compliance with the License. You may obtain a copy of the License at

[http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0)

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an â€œAS ISâ€ BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.



================================================
File: docs/docs/support.mdx
================================================
---
description: >-
  We take the security of Dispatch seriously. The following are a set of
  policies we have adopted to ensure that security issues are addressed in a
  timely fashion.
---

# Support

## General Support

We provide support via our Github issue [tracker](https://github.com/Netflix/dispatch/issues). We do our best to respond in a timeline manner, but please keep in mind that open source is not a core responsibility of our job and we provide the code and support on a best effort basis.

## Reporting a Security Issue

We ask that you do not report a security issue to our standard GitHub issue tracker.

If you believe you've identified a security issue with `Dispatch`, please report it via our public Netflix bug bounty program at [https://hackerone.com/netflix](https://hackerone.com/netflix).

Once you've submitted the issue, it will be handled by our triage team, typically within 48 hours.

> **Note:** Any secrets in the codebase, for example in the `docker-compose.yml` file, are used for demonstration purposes and not meant for production systems.

## Support Versions

At any given time, we will provide security support for the `main` branch and the two most recent releases.

## Disclosure Process

Our process for taking a security issue from private discussion to public disclosure involves multiple steps.

Approximately one week before full public disclosure, we will send advance notification of the issue to a list of people and organizations, primarily composed of known users of `Dispatch`. This notification will consist of an email message containing:

- A full description of the issue and the affected versions of `Dispatch`.
- The steps we will be taking to remedy the issue.
- The patches, if any, will be applied to `Dispatch`.
- The date on which the `dispatch` team will apply these patches, issue new releases, and publicly disclose the issue.

Simultaneously, the reporter of the issue will receive notification of the date we plan to make the issue public.

On the day of disclosure, we will take the following steps:

- Apply the relevant patches to the `Dispatch` repository. The commit messages for these patches will indicate that they are for security issues but will not describe the issue in any detail; instead, they will warn of upcoming disclosure.
- Issue the relevant releases.

If a reported issue is particularly time-sensitive â€“ due to a known exploit in the wild, for example â€“ the time between advance notification and public disclosure may be shortened considerably.

The list of people and organizations who receives the advanced notification of security issues is not, and will not, be made public. This list generally consists of high-profile downstream users and is entirely at the discretion of the `Dispatch` team.


================================================
File: docs/docs/administration/cli.mdx
================================================
---
description: Overview of the Dispatch CLI.
---

# CLI

Dispatch ships with a robust CLI, providing configuration, server, scheduler, plugin, database, and shell commands. Here we'll give a partial overview; if you'd like a complete list of Dispatch commands available via the CLI, please use the command `dispatch --help` once you have installed the application.

## Server

The server sub-command contains all Dispatch server-related commands.

```bash
> dispatch server --help                                                                        develop â¬‡ â—¼
Usage: dispatch server [OPTIONS] COMMAND [ARGS]...

  Container for all dispatch server commands.

Options:
  --help  Show this message and exit.

Commands:
  config   Prints the current config as dispatch sees it.
  develop  Runs a simple server for development.
  routes   Prints all available routes.
  shell    Starts an ipython shell importing our app.
  start
```

### Config

The `config` command helps debug as it shows the configuration variables seen by the server \(combining envvars, defaults, and the .env file\).

```bash
> dispatch server config
>
Key                                       Value
----------------------------------------  -----------------------
DISPATCH_DOMAIN                           example.com
STATIC_DIR
METRIC_PROVIDERS                          spectator-metric
...
```

### Develop

The `develop` command starts the development server. This server will continually watch for file changes and reload the server accordingly. You'll find it useful to combine this with a `DEBUG` log level, as below.

```bash
> dispatch server develop --log-level debug
```

### Routes

The `routes` command is useful for development. This command shows which endpoints the server is currently listening on, the HTTP verb methods are accepted, and whether authentication is enabled.

```bash
> dispatch server routes
Path                                  Authenticated    Methods
------------------------------------  ---------------  ---------
/healthcheck                          False            GET
/documents/                           True             GET
/documents/{document_id}              True             GET
/documents/                           True             POST
...
```

### Shell

The `shell` command is useful for development. It drops you into an interactive python shell with the same context as the server itself.

```bash
> dispatch server shell
```

### Start

The `start` command starts a production-grade Dispatch web server. It's an alias to the [uvicorn](https://www.uvicorn.org/) web server, so it contains all of the options and flags available with that server.

```bash
> dispatch server start --help
Usage: dispatch server start [OPTIONS] APP

Options:
  --host TEXT                     Bind socket to this host.  [default:
                                  127.0.0.1]
  --port INTEGER                  Bind socket to this port.  [default: 8000]
  --uds TEXT                      Bind to a UNIX domain socket.
  --fd INTEGER                    Bind to socket from this file descriptor.
  --reload                        Enable auto-reload.
  --reload-dir TEXT               Set reload directories explicitly, instead
                                  of using the current working directory.
  ...
```

To start Dispatch, you will need to tell the start command where to find the `dispatch` [ASGI](https://asgi.readthedocs.io/en/latest/) application. For example, a common set of flags might be:

```bash
> dispatch server start dispatch.main:app --workers 6 --host 127.0.0.1 --port 8000 --proxy-headers
```

## Scheduler

The `scheduler` command contains all of the Dispatch scheduler logic.

```bash
> dispatch scheduler --help
Usage: dispatch scheduler [OPTIONS] COMMAND [ARGS]...

  Container for all dispatch scheduler commands.

Options:
  --help  Show this message and exit.

Commands:
  list   Prints and runs all currently configured periodic tasks, in...
  start  Starts the scheduler.
```

### List

The `list` command lists all tasks registered with the scheduler. Today the scheduler periods are hardcoded and cannot be adjusted.

```bash
> dispatch scheduler list
Task Name                        Period          At Time
-------------------------------  --------------  ---------
incident-status-report-reminder  1:00:00
incident-daily-summary           1 day, 0:00:00  18:00:00
calculate-incident-cost          0:05:00
incident-task-reminders          1:00:00
incident-task-sync               0:00:30
term-sync                        1:00:00
document-term-sync               1 day, 0:00:00
application-sync                 1:00:00
```

### Start

The `start` command starts the scheduler and allows tasks to be executed based on the defined period.

```bash
> dispatch scheduler start
Starting scheduler...
```

Often it's helpful to run a particular task immediately:

```bash
> dispatch scheduler start incident-status-report-reminder --eager
```

## Database

The `database` command contains all of the Dispatch database logic.

```bash
> dispatch database --help
Usage: dispatch database [OPTIONS] COMMAND [ARGS]...

  Container for all dispatch database commands.

Options:
  --help  Show this message and exit.

Commands:
  downgrade      Downgrades database schema to the next newest version.
  drop           Drops all data in database.
  heads          Shows the heads of the database.
  history        Shows the history of the database.
  init           Initializes a new database.
  populate       Populates database with default values.
  revision       Create new database revision.
  sync-triggers  Ensures that all database triggers have been installed.
  upgrade        Upgrades database schema to newest version.
```

:::info
Note: The database command is a combination of custom commands and `alembic` commands. For more information about alembic database migrations, see [here](https://alembic.sqlalchemy.org/en/latest/).
:::

### Init

The `init` command takes a fresh database and creates the necessary tables and values for Dispatch to operate.

```bash
> dispatch database init
```

### Revision

The `revision` command is an `alembic` command that creates a new database schema revision based on the application's models.

Commonly used in conjunction with the `--autogenerate` flag:

```bash
> dispatch database revision --autogenerate
```

### Upgrade/Downgrade

The `upgrade` and `downgrade` commands manage how `alembic` database migrations are deployed, allowing you to move the database forward and backward through revisions. You'll often need to run the `upgrade` command after installing a new version of Dispatch.

```bash
> dispatch database upgrade
```

### Restore/Dump

The `restore` and `dump` commands allow you to quickly backup and restore the Dispatch database. It can also be used to load our [example](https://github.com/Netflix/dispatch/blob/develop/data/dispatch-sample-data.dump) data set into your Dispatch installation.

Today, the `.dump` file must be located in `$CWD` and must be named `dispatch-backup.dump`.

## Plugins

The `plugin` command contains all of the logic for dealing with Dispatch's plugins.

### List

The `list` command lists all currently available plugins. This command is useful in determining which plugins are available to be used via configuration variables.

```bash
> dispatch plugins list
Title                             Slug                            Version     Type               Author         Description
--------------------------------  ------------------------------  ----------  -----------------  -------------  ---------------------------------------------------------
Dispatch - Document Resolver      dispatch-document-resolver      0.1.0       document-resolver  Kevin Glisson  Uses dispatch itself to resolve incident documents.
Dispatch - Participants           dispatch-participants           0.1.0       participant        Kevin Glisson  Uses dispatch itself to determine participants.
Google Docs - Document            google-docs-document            0.1.0       document           Kevin Glisson  Uses google docs to manage document contents.
Google Group - Participant Group  google-group-participant-group  0.1.0       participant_group  Kevin Glisson  Uses Google Groups to help manage participant membership.
...
```

### Install

The `install` command will try installing all available plugins.

```bash
> dispatch plugins install
INFO:dispatch.common.utils.cli:Attempting to load plugin: dispatch_basic_auth
INFO:dispatch.common.utils.cli:Successfully loaded plugin: dispatch_basic_auth
INFO:dispatch.common.utils.cli:Attempting to load plugin: dispatch_contact
INFO:dispatch.common.utils.cli:Successfully loaded plugin: dispatch_contact
INFO:dispatch.common.utils.cli:Attempting to load plugin: dispatch_document_resolver
...
```

Keep in mind that this will only make plugins available. To enable them [create and configure the plugin instance](./settings/plugins/index.mdx)


================================================
File: docs/docs/administration/faq.mdx
================================================
# FAQ

## Running â€˜dispatch database upgradeâ€™ seems stuck.

The upgrade is most likely stuck because an existing query on the database is holding onto a lock that the migration needs.

To resolve, login to your dispatch database and run:

> SELECT \* FROM pg_locks l INNER JOIN pg_stat_activity s ON \(l.pid = s.pid\) WHERE waiting AND NOT granted;

The result of this query will give you a list of queries that are currently waiting to be executed. From there, attempt to identify the PID of the query blocking the migration. Once found, execute:

> select pg_terminate_backend\(&lt;blocking-pid&gt;\);

See [http://stackoverflow.com/questions/22896496/alembic-migration-stuck-with-postgresql](http://stackoverflow.com/questions/22896496/alembic-migration-stuck-with-postgresql) for more.


================================================
File: docs/docs/administration/index.mdx
================================================
---
title: Introduction
sidebar_position: 0
---

# Administration

The Dispatch Web UI is home to all of Dispatch administration abilities; these contain things that are likely to change frequently \(less often changed items live in the Dispatch configuration file\).

To access Dispatch settings, look for the `Settings` menu item and select a project which you want to administer.

<div style={{textAlign: 'center'}}>

![settings](/img/admin-ui-settings.png)

</div>


================================================
File: docs/docs/administration/installation.mdx
================================================
---
sidebar_position: 1
tags:
  - Getting started
---

# Installation

Dispatch relies on multiple services to work, which are all orchestrated by `Docker Compose`.

### Requirements

- [Docker](https://www.docker.com/) 17.05.0+
- [Docker Compose](https://docs.docker.com/compose/) 1.19.0+
- A dedicated \(sub\)domain to host Dispatch on \(for example, dispatch.yourcompany.com\).
- At least 2400MB memory
- 2 CPU Cores

## Installing Dispatch Server

We strongly recommend using Docker for installing Dispatch and all its services. If you need to do something custom, you can use this repository as the basis of your setup. If you do not wish to use the Docker images we provide, you can still find Dispatch on PyPI; however, we don't recommend that method. You'll need to work your way back from the main Dispatch image. It is not too hard, but you are likely to spend a lot more time and hit some bumps.

To install Dispatch from the repository, clone the repository locally:

```bash
git clone https://github.com/Netflix/dispatch-docker.git
```

Before starting the installation, we strongly recommend you check out [how to configure your Dispatch instance](./settings/server.mdx) as you'd need to rebuild your images \(`docker-compose build`\) if you want to change your configuration settings. You may copy and edit the example configs provided in the repository. If none exists, the install script will use these examples as actual configurations.

:::info
Note: Dispatch will not start without at least a few required configuration variables. See the example [.env](https://github.com/Netflix/dispatch/blob/latest/docker/.env.example) configuration file.
:::

:::info
Note: Dispatch does not contain any data by default. For evaluation purposes, we do provide an example data set located [here](https://github.com/Netflix/dispatch/blob/main/data/dispatch-sample-data.dump). For instructions on how to restore this data, see [here](cli.mdx).
:::

To start, run the install script:

```bash
./install.sh
```

:::info
Note: The `core` Docker service is not needed once the `web` and `schedule` services, which depend on it, are built.
:::

### The "first" user problem

For any new Dispatch installation, new users are expected to register themselves via the `/auth/register` endpoint in the Dispatch UI. By default, users registering via this method are granted regular "user" permissions within Dispatch. There is no direct way through the UI to allow a user to obtain an "Owner" role (as no other Owners exist to grant them access).

For these users, we have a CLI command that allows users to be granted the role of their choosing:

```bash
docker exec -it dispatch_web_1 bash
dispatch user update --role Owner --organization <name-of-the-organization> <email-address-of-registered-user>
```

The default organization name in the sample data file is "default".

After one owner user has been established, they can grant this role to others via the UI.

## Going to Production

Before you deploy Dispatch to production, there are a few considerations and steps that should be taken.

### Basics

Because of the sensitivity of the information stored and maintained by Dispatch. You must follow standard host hardening practices:

- Run Dispatch with a limited user
- Disabled any unneeded services
- Enable remote logging
- Restrict access to the host

### Credential Management

Dispatch plugins require API tokens to communicate with third-party resources. These tokens are stored in either an environment variable or in the Dispatch `.env` file.

By default, these strings are in plain text, but Dispatch does provide hooks that allow for these credentials to be decrypted on server start. See the [Secret Provider](./settings/server.mdx#general) configuration option.

### Authentication

Dispatch provides a "Basic" authentication provider that controls access via a username and password combination to get going quickly. By default, this provider allows for **open registration**, which means that anyone will be able to create a Dispatch account if they have network access to your server.

Dispatch provides a "PKCE" authentication method to integrate existing and more robust SSO solutions for more robust authentication. See the [Authentication Provider](./settings/server.mdx#authentication)

### TLS/SSL

#### Nginx

Nginx is a popular choice to serve a Python project:

- Itâ€™s fast.
- Itâ€™s lightweight.
- Configuration files are simple.

Nginx doesnâ€™t run any Python process; it only serves requests from outside to the Python server.

Therefore, there are two steps:

- Run the Python process.
- Run Nginx.

You will benefit from having:

- The possibility to have several projects listening to the port 80;
- Your web site processes wonâ€™t run with admin rights, even if â€“the user doesnâ€™t work on your OS;
  -The ability to manage a Python process without touching Nginx or the other processes. Itâ€™s convenient for updates.

You must create an Nginx configuration file for Dispatch. On GNU/Linux, they usually go into `/etc/nginx/conf.d/`. Name it `dispatch.conf`.

proxy_pass passes the external request to the Python process. The port must match the one used by the Dispatch process.

You can make some adjustments to get a better user experience:

```nginx
server_tokens off;
add_header X-Frame-Options DENY;
add_header X-Content-Type-Options nosniff;
add_header X-XSS-Protection "1; mode=block";

server {
    listen 80;
    return 301 https://$host$request_uri;
}

server {
    listen 443;
    access_log /var/log/nginx/log/dispatch.access.log;
    error_log /var/log/nginx/log/dispatch.error.log;

    location /api {
        proxy_pass http://127.0.0.1:8000;
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_redirect off;
        proxy_buffering off;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
    }

    location / {
        root /path/to/dispatch/static/dist;
        include mime.types;
        index index.html;
    }
}
```

Nginx will serve the favicon and static files, which it is much better at than python.

We recommended that you deploy TLS when deploying Dispatch. It may be obvious given Dispatchâ€™s purpose, but the sensitive nature of Dispatch and what it controls makes this essential. A sample config for Dispatch that also terminates TLS:

:::info
Some paths will have to be adjusted based on where you have chosen to install Dispatch.
:::

```nginx
server_tokens off;
add_header X-Frame-Options DENY;
add_header X-Content-Type-Options nosniff;
add_header X-XSS-Protection "1; mode=block";

server {
    listen 80;
    return 301 https://$host$request_uri;
}

server {
    listen 443;
    access_log /var/log/nginx/log/dispatch.access.log;
    error_log /var/log/nginx/log/dispatch.error.log;

    # certs sent to the client in SERVER HELLO are concatenated in ssl_certificate

    ssl_certificate /path/to/signed_cert_plus_intermediates;
    ssl_certificate_key /path/to/private_key;
    ssl_session_timeout 1d;
    ssl_session_cache shared:SSL:50m;

    # Diffie-Hellman parameter for DHE cipher suites, recommended 2048 bits

    ssl_dhparam /path/to/dhparam.pem;

    # modern configuration. tweak to your needs.

    ssl_protocols TLSv1.1 TLSv1.2;
    ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK';
    ssl_prefer_server_ciphers on;

    # HSTS (ngx_http_headers_module is required) (15768000 seconds = 6 months)

    add_header Strict-Transport-Security max-age=15768000;

    # OCSP Stapling ---

    # fetch OCSP records from URL in ssl_certificate and cache them

    ssl_stapling on;
    ssl_stapling_verify on;

    ## verify chain of trust of OCSP response using Root CA and Intermediate certs

    ssl_trusted_certificate /path/to/root_CA_cert_plus_intermediates;

    resolver <IP DNS resolver>;

    location /api {
        proxy_pass http://127.0.0.1:8000;
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_redirect off;
        proxy_buffering off;
        proxy_set_header Host $host;
        proxy_set_header        X-Real-IP       $remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
    }

    location / {
        root /path/to/dispatch/static/dist;
        include mime.types;
        index index.html;
    }
}
```

Apache
An example apache config:

```apache
<VirtualHost \*:443>
...
SSLEngine on
SSLCertificateFile /path/to/signed_certificate
SSLCertificateChainFile /path/to/intermediate_certificate
SSLCertificateKeyFile /path/to/private/key
SSLCACertificateFile /path/to/all_ca_certs

    # intermediate configuration, tweak to your needs
    SSLProtocol             all -SSLv2 -SSLv3
    SSLCipherSuite          ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA
    SSLHonorCipherOrder     on

    # HSTS (mod_headers is required) (15768000 seconds = 6 months)
    Header always set Strict-Transport-Security "max-age=15768000"
    ...

# Set the dispatch DocumentRoot to static/dist

DocumentRoot /www/dispatch/dispatch/static/dist

# Uncomment to force http 1.0 connections to proxy

# SetEnv force-proxy-request-1.0 1

#Don't keep proxy connections alive
SetEnv proxy-nokeepalive 1

# Only need to do reverse proxy

ProxyRequests Off

# Proxy requests to the API to the dispatch service (and sanitize redirects from it)

ProxyPass "/api" "http://127.0.0.1:8000/api"
ProxyPassReverse "/api" "http://127.0.0.1:8000/api"

</VirtualHost>
```

:::info
The above config is somewhat incomplete. If you have a working apache config, please let us know!
:::

Also included in the configurations above are several best practices when it comes to deploying TLS. Things like enabling HSTS, disabling vulnerable ciphers are all excellent ideas for deploying Dispatch into a production environment.

For more SSL configuration options see: [Mozilla SSL Configuration Generator](https://mozilla.github.io/server-side-tls/ssl-config-generator/)


================================================
File: docs/docs/administration/upgrading.mdx
================================================
---
sidebar_position: 2
description: Staying up to date.
---

# Upgrading

If you're upgrading to a new major release, you should generate a new configuration file using the latest Dispatch version. Doing so ensures that any new settings are visible and configured if required.

Beyond that, upgrades are simple as bumping the version of Dispatch \(which will cause any changed dependencies to upgrade\), running data migrations, and restarting all related services.

:::info
In some cases, you may want to stop services before doing the upgrade process or avoid intermittent errors.
:::

## Upgrading Dispatch

### Upgrading the package

The easiest way to upgrade the Dispatch package using `pip`:

```bash
pip install --upgrade dispatch
```

You may prefer to install a fixed version rather than the latest, as it will allow you to control changes.

If you're installing from source code, you may have additional unfulfilled requirements, so take the necessary precautions of testing your environment before committing to the upgrade.

### Running Migrations

Just as during the initial setup, migrations are applied with the upgrade command.

```bash
dispatch database upgrade
```

### Restarting services

You'll need to ensure that _all_ of Dispatch's services are restarted after an upgrade. Restarting these services is required because Python loads modules in memory, and code changes will not be reflected until they are restarted.

These services include:

- server -- `dispatch server start`
- scheduler -- `dispatch scheduler start`


================================================
File: docs/docs/administration/user.mdx
================================================
---
sidebar_position: 3
---

# User Management

Users or organizational members represent users of the Dispatch UI and are different from individual contacts or incident participants. These user accounts are used to control access to the Dispatch UI only. We do not currently support the creation or removal of users via the Dispatch UI, except in the case of self-registration.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-users.png)

</div>

**Role:** Dispatch uses role-based access control (RBAC) for its UI. Currently, this is only used to protect sensitive incidents whose visibility is set to restricted. We do not currently have any controls surrounding Dispatch configuration and settings. There are four roles defined by Dispatch:

- Member: Can access everything except restricted incidents unless they are a direct participant.
- Admin: Allows full access to the Dispatch UI and all incidents, whether their visibility is open or restricted.
- Manager: Currently the same as Admin.
- Owner: Allows full access to the Dispatch UI and to manager organizations.

**Settings:**

- Default Projects: List of projects that Dispatch will use to apply filtering across the UI (e.g. case or incident tables and dashboards).


================================================
File: docs/docs/administration/contributing/core.mdx
================================================
# Core

## API

### Folder Structure

Dispatch's backend is a typical python web app. Its folder structure is a simple one and is mirrored between the backend code \(python\) and the frontend code \(javascript\).

```text
â”œâ”€â”€ dispatch
â”‚   â”œâ”€â”€ alembic
â”‚   â”œâ”€â”€ application
â”‚   â”œâ”€â”€ auth
â”‚   â”œâ”€â”€ common
â”‚   â”œâ”€â”€ conversation
â”‚   â”œâ”€â”€ definition
...
```

Looking at the Dispatch folder structure, we try to group code by its subject. For example, all of the `definitions` code \(models, views, services\) is contained within the `definitions` folder.

### Starting the Development Server

For backend development, you will most likely want to use the `develop` command. This command starts a web server, creates a supervisor process to check for file changes, and reloads the server process when necessary.

```bash
> dispatch server develop --log-level debug
```

### Creating Models

During development, if you need to add or modify database models, there are a few things to consider:

- Is this a new model?
- Am I adding columns? Removing columns?
- Do I need to migrate any data?

Dispatch uses a combination of [SQLAlchemy](https://www.sqlalchemy.org/) models and [Alembic](https://alembic.sqlalchemy.org/en/latest/) to manage its database models.

#### Is this a new model?

When creating a new model, ensure that you are always inheriting from the `Base` Dispatch class \(`dispatch.database.Base`\). Check to see if your model requires any of the pre-existing mixins available to you in `dispatch.models` \(like `ResourceMixin` or `TimestampMixin`\).

For Alembic to see your new model, you must import the model at the bottom of the `dispatch.models` python module. This import ensures the model is available for Alembic introspection.

When you're ready, create a new migration for your model by running the following command:

```bash
> dispatch database revision --autogenerate
```

This command will generate an alembic file for you. The generated file will be automatically populated with several code pieces that enable everyday actions. If you need to migrate _data_ as part of your migration, you will have to write the data migration code yourself.

:::info
Alembic migrations are a _starting_ point and almost always need to be modified. Review the migration file before continuing.
:::

Once you're happy with the migration file, commit the modifications to the database:

```bash
> dispatch database upgrade
```

#### Am I adding columns? Am I Removing columns?

Similar to adding models, you will have to run a dispatch `revision` command to have Alembic create a new revision:

```bash
> dispatch database revision --autogenerate
```

Adding columns is relatively straightforward. It is encouraged that you do not add _and_ remove columns \(or tables\) within the same revision. Instead, it's better to add your new column on one revision and later remove/deprecate the old column once you are sure there is no code depending on that column.

#### Do I need to migrate any data?

Sometimes, a schema change necessitates some data migration. Migrating data can be a tricky operation, be careful to test this change several times \(ensuring backups are in place for worst-case scenarios\).

Alembic can help us with data migration; just like with the removal of columns, it's encouraged to create separate revisions for schema changes \(e.g., creating/deleting tables\) and modifying data itself. Staging these changes reduces the overall risk of the change.

```bash
> dispatch database revision
```

Creates a new empty revision, which you can then use to modify existing data if need be, as an example:

```python
connection = op.get_bind()
# Select all existing names that need migrating.
results = connection.execute(sa.select([
    t_users.c.id,
    t_users.c.name,
    ])).fetchall()
# Iterate over all selected data tuples.
for id_, name in results:
    # Split the existing name into first and last.
    firstname, lastname = name.rsplit(' ', 1)
    # Update the new columns.
    connection.execute(t_users.update().where(t_users.c.id == id_).values(
        lastname=lastname,
        firstname=firstname,
        ))
```

### Standards

For Dispatch's Python code base, all code style is controlled and enforced by [black](https://black.readthedocs.io/en/stable/). Additionally, we use various [flake8](https://flake8.pycqa.org/en/latest/) rules to ensure that our codebase is consistent. All settings are set in the `setup.cfg` located in the project's root directory and respected by tools locally.

When submitting a PR to Dispatch's GitHub project, code must have passing tests and no black or flake8 violations. PRs will not be evaluated if these checks are not met.

## UI

### Folder Structure

Similar to the API folder structure, we've chosen to group files based on the type of model they are related to:

```text
src
â”‚   â”œâ”€â”€ API
â”‚   â”œâ”€â”€ app
â”‚   â”œâ”€â”€ application
â”‚   â”œâ”€â”€ assets
â”‚   â”œâ”€â”€ auth
â”‚   â”œâ”€â”€ components
â”‚   â”œâ”€â”€ dashboard
â”‚   â”œâ”€â”€ definition
â”‚   â”œâ”€â”€ document
...
```

### Starting the Development Server

From Dispatch's static directory:

```bash
> cd <path-to-static>/dispatch npm run serve
```

This command starts a local server, that again, like the API, will automatically reload itself when changes are detected. Additionally, this server acts as a proxy to the local API server, such that from the frontend's perspective, it is only talking to one server. This command helps avoid CORS-related issues and is closer to how the application is deployed \(static and API on the same hostname\).

### Standards

Similar to the Python API, we use a combination of [eslint](https://eslint.org/) and [prettier](https://prettier.io/) to give our code a consistent look and feel. We are not currently enforcing any of these checks on open PRs but plan to do so in the future.


================================================
File: docs/docs/administration/contributing/environment.mdx
================================================
---
description: Quick guide for setting your environment for Dispatch development.
---

# Environment

:::info
This guide assumes you're using an OS of the Linux/Unix variant \(Ubuntu/OS X\) and is not meant to be exhaustive.

## Easy Mode

Install Dispatch with PIP:

```bash
> DISPATCH_LIGHT_BUILD=1 pip install -e .[dev]
```

Run dev server:

```bash
> STATIC_DIR="" dispatch server develop # or set STATIC_DIR to "" in .env
```

This command will run the webpack-dev-server in another process when starting the dev server and forward static files through HTTP.

## API

### System

Ensure you have python3 available on your system:

```bash
> which python3
/home/kglisson/.pyenv/shims/python3
```

Above, you can see that we're using [pyenv](https://github.com/pyenv/pyenv) to manage our python versions on our system. The rest of the guide will assume pyenv is being used.

Once we have python installed, let's ensure it's a new enough version:

```bash
> python --version
Python 3.10.11
```

:::info
Dispatch requires `python 3.10+`.

Create a new virtualenv just for Dispatch:

```bash
> pyenv virtualenv dispatch
```

Install Dispatch with pip:

```bash
> pip install -e /path/to/dispatch
```

Test it by seeing if the `dispatch` command is in your path:

```bash
> dispatch --help
```

## UI

Dispatch uses the [Vue Cli](https://cli.vuejs.org/) to manage its single-page app \(SPA\) and the [Vuetify](https://vuetifyjs.com/en/) framework for material based components.

To get started developing with Vue, first navigate to the root static directory:

```bash
> cd <dispatch-source-patch>/src/dispatch/static/dispatch
```

Ensure you have node installed:

```bash
> which node
/home/kglisson/.nvm/versions/node/v12.7.0/bin/node
```

Notice that we are using [nvm](https://github.com/nvm-sh/nvm) to manage our installations of Node. The rest of the guide assumes the usage of nvm.

Check to make sure we have the correct version of Node:

```bash
> node --version
v12.7.0
```

:::info
To correctly build it's components Dispatch requires node 12.7.0+

Install required node modules with `npm` :

```bash
> npm install
```

Test the development server:

```bash
> npm run serve
```


================================================
File: docs/docs/administration/contributing/index.mdx
================================================
---
description: >-
  Want to contribute back to Dispatch? These pages describe the general development flow, our philosophy, the test suite, and issue tracking.
---

# Contributing

## Documentation

Dispatch documentation is managed via Gitbook.

## Doing a release

Creating a release of Dispatch requires the step below.

### Updating sample data

If the database schema changes, we will need to update the sample data accordingly.

- Run the Bash script `update-example-data.sh` in the `data` directory.
- Create a commit with any changes
- Create a pull request with the change
- Merge change

### Bumping the version number

- Update the version number in `dispatch/__about__.py`
- Create a new entry in the changelog
- Create a commit with the changelog changes
- Create a pull request with the change
- Merge change

### Change log

- Create a new changelog with all significant changes since the last release
- Update GitHub releases: https://github.com/Netflix/dispatch/releases
- Publish the release

### Update 'latest' tag

We rely on the latest tag to identify the most current stable version. Follow the steps below to update this tag:

Delete the previous tag:

```
git tag -d latest
```

Create a new tag:

```
git tag -a latest <commit>
```

Push the tag:

```
git push origin latest
```


================================================
File: docs/docs/administration/contributing/plugins/index.mdx
================================================
---
description: Make Dispatch your own by writing a plugin!
---

# Plugins

Each plugin has its interface, but in general, all plugins are structured the same way.

```bash
setup.py
dispatch_pluginname/
dispatch_pluginname/__init__.py
dispatch_pluginname/plugin.py
```

The `__init__.py` file should contain no plugin logic, and at most, a VERSION = â€˜x.x.xâ€™ line. For example, if you want to pull the version using pkg_resources \(which is what we recommend\), your file might contain:

```python
try:
    VERSION = __import__('pkg_resources') \
        .get_distribution(__name__).version
except Exception as e:
    VERSION = 'unknown'
```

Inside of `plugin.py` declare your own `Plugin` class:

```python
import dispatch_pluginname
from dispatch.plugins.base.conversation import ConversationPlugin

class PluginName(ConversationPlugin):
    title = 'Plugin Name'
    slug = 'pluginname'
    description = 'My awesome plugin!'
    version = dispatch_pluginname.VERSION

    author = 'Your Name'
    author_url = 'https://github.com/yourname/dispatch_pluginname'

    def create(self, items, **kwargs):
        return "Conversation Created"

    def add(self, items, **kwargs):
        return "User Added"

    def send(self, items, **kwargs):
        return "Message sent"
```

Register your plugin via `entry_points` by modifying your `setup.py`:

```python
setup(
    # ...
    entry_points={
       'dispatch.plugins': [
            'pluginname = dispatch_pluginname.conversations:PluginName'
        ],
    },
)
```

You can potentially package multiple plugin types in one package, say you want to create a conversation and conference plugins for the same third-party. To accomplish this, alias the plugin in entry points to point at multiple plugins within your package:

```python
setup(
    # ...
    entry_points={
        'dispatch.plugins': [
            'pluginnameconversation = dispatch_pluginname.plugin:PluginNameConversation',
            'pluginnameconference = dispatch_pluginname.plugin:PluginNameConference'
        ],
    },
)
```

Once your plugin files are in place, you can load your plugin into your instance by installing your package:

```bash
> pip install -e .
```

:::info
For more information about python packages see: [Python Packaging](https://packaging.python.org/en/latest/distributing.html)
:::


================================================
File: docs/docs/administration/contributing/plugins/interfaces.mdx
================================================
---
description: Describes the plugin interface for each type of plugin.
---

# Interfaces

We do our best to keep this documentation up-to-date. However, the code itself is still the best place to look for the most current documentation.

## Conversation

Conversation plugins are deeply integrated within Dispatch. They server as the real-time communication channel used for incidents. By default Dispatch supports `Slack` as a conversation channel, if you wish to use another platform for conversations you will need to implement the following interface:

```python
def create(self, name: str, participants: List[dict]):
    """Creates a new conversation."""
    return {
        "id": "abc123",
        "name": "example",
        "weblink": "https://example.com"
    }

def send(
    self,
    conversation_id: str,
    text: str,
    message_template: dict,
    notification_type: str,
    items: Optional[List] = None,
    blocks: Optional[List] = None,
    persist: bool = False,
    **kwargs,
):
    """Sends a new message based on data and type."""
    return {
        "id": "abc123",
        "timestamp": "1232324384"
    }

def send_direct(
    self,
    user: str,
    text: str,
    message_template: dict,
    notification_type: str,
    items: Optional[List] = None,
    blocks: Optional[List] = None,
    **kwargs,
):
    """Sends a message directly to a user."""
    return {
        "id": "abc123",
        "timestamp": "1232324384"
    }

def send_ephemeral(
    self,
    conversation_id: str,
    user: str,
    text: str,
    message_template: dict = None,
    notification_type: str = None,
    items: Optional[List] = None,
    blocks: Optional[List] = None,
    **kwargs,
):
    """Sends an ephemeral message to a user in a channel."""
    return {
        "id": "abc123",
        "timestamp": "1232324384"
    }

def add(self, conversation_id: str, participants: List[str]):
    """Adds users to conversation."""
    return

def open_dialog(self, trigger_id: str, dialog: dict):
    """Opens a dialog with a user."""
    return

def open_modal(self, trigger_id: str, modal: dict):
    """Opens a modal with a user."""
    return

def archive(self, conversation_id: str):
    """Archives conversation."""
    return

def get_participant_username(self, participant_id: str):
    """Gets the participant's username."""
    return "username"

def get_participant_email(self, participant_id: str):
    """Gets the participant's email."""
    return "username@example.com"

def get_participant_avatar_url(self, participant_id: str):
    """Gets the participant's avatar url."""
    return "https://example.com/username.png"

def set_topic(self, conversation_id: str, topic: str):
    """Sets the conversation topic."""
    return

def get_command_name(self, command: str):
    """Gets the command name."""
    return "/some-command-name"
```

:::info
Not all of the above functions will make sense for your conversation, but all are called by Dispatch in various flows, implement all of the functions for full functionality.,
:::

## Document Resolver

Dispatch ships with an internal document resolver that attempts to gather documents related to an incident from within Dispatch's document store. However, you may already have a robust external document store. The interface is as follows:

```python
def get(
        self, incident_type: str, incident_priority: str, incident_description: str, db_session=None
    ):
    """Get documents related to the current incident."""
    return [{
           "name": "foo",
           "description": "bar",
           "weblink": "https://example.com/bar",
           "resource_type": "external-type",
           "resource_id": "abc123" }]
```

## Document

While there are other plugin interfaces for document management \(storage, resolution, etc.,\), this interface focuses solely on updating the document itself. Documents are a part of the incident document template system, finding and replacing key terms and injecting incident-specific information. Currently, we only ever update document using this interface:

```python
 def update(self, document_id: str, **kwargs):
     """Replaces text in document."""
     return
```

## Metric

The `metric` is an optional plugin that allows you to use whatever metric system you have deployed within your organization.

```python
def gauge(self, name: str, value, tags=None):
    """Create a new gauge metric."""
    return

def counter(self, name: str, value=None, tags=None):
    """Create a new counter metric."""
    return

def timer(self, name: str, value, tags=None):
    """Create a new timer metric."""
    return
```

## Oncall

The on-call plugin resolves or engages individuals directly. Dispatch ship's with support for `PagerDuty` but also provides this interface to add your own.

```python
def get(self, service_id: str = None, service_name: str = None):
    """Gets the oncall person."""
    return "joe@example.com"

def page(
    self, service_id: str, incident_name: str, incident_title: str, incident_description: str
):
    """Pages the oncall person."""
    return
```

## Participant Group

Often permissions for resources are managed by external entities or "groups". By default, Dispatch uses Google Groups to help manage these permissions as these groups' permission integrate nicely with the rest of the G Suite.

```python
def create(
        self, name: str, participants: List[str], description: str = None, role: str = "MEMBER"
    ):
    """Creates a new participant group."""
    return {
        "weblink": "https://example.com/my-incident",
        "email": "my-incident@example.com"
        "name": "my-incident"
    }

def add(self, email: str, participants: List[str], role: str = "MEMBER"):
    """Adds participants to existing participant group."""
    return

def remove(self, email: str, participants: List[str]):
    """Removes participants from existing participant group."""
    return

def delete(self, email: str):
    """Deletes an existing participant group."""
    return
```

## Participant

Similar to the document resolver plugin, Dispatch can pull participants into incidents automatically. To accomplish this, Dispatch ships with the `DispatchParticipantPlugin`. Internal to Dispatch \(services, individuals, teams\), this plugin determines who should be involved with the incident itself.

```python
def get(
    self,
    incident_type: str,
    incident_priority: str,
    incident_description: str,
    db_session=None,
):
    """Fetches participants from Dispatch."""
    return
```

## Storage

By default, Dispatch uses Google Drive for all incident artifact storage. It provides a standard interface for all incident participants and tight integration with the rest of the G Suite.

Each incident gets its own dedicated space \(a Team Drive in the case of Drive\). From there, Dispatch expects the following interface when dealing with incident artifacts:

```python
def get(self, file_id: str, mime_type=None):
    """Fetches document text."""
    return "Document text"

def create(self, name: str, participants: List[str], role: str = Roles.file_organizer.value):
    """Creates a new drive."""
    return {
        "id": "abc123"
        "weblink": "https://example.com",
        "name": "example-drive"
        "description": "This is a drive"
    }

def delete(self, drive_id: str, empty: bool = True):
    """Deletes a drive."""
    return

def list(self, **kwargs):
    """Lists all available drives."""
    return [
        {
          "id": "abc123",
          "weblink": "https://example.com",
          "name": "example-drive"
          "description": "This is a drive"
        }
    }

def add_participant(
    self,
    drive_or_file_id: str,
    participants: List[str],
    role: str = "owner",
    user_type: str = "user",
):
    """Adds participants to existing drive."""
    return

def remove_participant(self, drive_id: str, participants: List[str]):
    """Removes participants from existing drive."""
    return

def create_file(self, drive_id: str, name: str, file_type: str = "folder"):
    """Creates a new file in existing drive."""
    return {
        "id": "abc123",
        "weblink": "https://example.com",
        "name": "file-name",
    }

def delete_file(self, drive_id: str, file_id: str):
    """Removes a file from existing drive."""
    return

def copy_file(self, drive_id: str, file_id: str, name: str):
    """Creates a copy of the given file and places it in the specified drive."""
    return {
        "id": "abc123",
        "weblink": "https://example.com",
        "name": "file-name",
    }

def move_file(self, new_drive_id: str, file_id: str):
    """Moves a file from one place to another."""
    return {
        "id": "abc123",
        "weblink": "https://example.com",
        "name": "file-name",
    }

def archive(self, source_drive_id, dest_folder_id, folder_name):
    """Archives a shared team drive to a specific folder."""
    return

def list_files(self, drive_id: str, q: str = None):
    """Lists all files in drive."""
    return [
        {
            "id": "abc123",
            "weblink": "https://example.com",
            "name": "file-name",
        }
    ]
```

## Task

:::info
This interface is not stable and will need to be refactored or generalized. Please file an issue for guidance if you are trying to extend tasks.
:::

Dispatch supports a lightweight tasking system to track incident tasks. By default, this uses the G Suit comment system to assign, create and resolve tasks. If you have an external system you'd like Dispatch to monitor, the following interface can be used:

```python
def list(self, file_id: str, **kwargs):
    """Lists all available tasks."""
    return
```

The Dispatch scheduler will attempt to sync tasks every 30 seconds.

## Term

Term plugins are used for getting organization specific information within Dispatch from external systems and have a very simple interface:

```python
def get(self, **kwargs):
    return [{
        "text": "foo",
        "definitions": [{
            "text": "bar"
        }],
    }]
```

## Ticket

```python
def create(
        self, title: str, incident_type: str, incident_priority: str, commander: str, reporter: str
    ):
    """Creates a ticket."""
    return

def update(
    self,
    ticket_id: str,
    title: str = None,
    description: str = None,
    incident_type: str = None,
    priority: str = None,
    status: str = None,
    commander_email: str = None,
    reporter_email: str = None,
    conversation_weblink: str = None,
    document_weblink: str = None,
    storage_weblink: str = None,
    labels: List[str] = None,
    cost: str = None,
):
    """Updates ticket fields."""
    return
```

## Workflow

:::info
This interface is not stable and will need to be refactored or generalized. Please file an issue for guidance if you are trying to extend workflow creation.

```python
def get_instance(
        self, workflow_id: str, instance_id: str, **kwargs)
    ):
    """Fetches an individual workflow instance."""
    return

def run(
    self,
    workflow_id: str, params: dict, **kwargs):
):
    """Runs the given workflow"""
    return
```


================================================
File: docs/docs/administration/contributing/plugins/testing.mdx
================================================
---
description: How to test your plugins.
---

# Testing

Dispatch provides a basic test-based testing framework for plugins. In a simple plugin, you'll need to do a few things to get it working:

## Require Dispatch

Augment your plugins `setup.py` to ensure that it depends on `dispatch`

```python
setup(
    # ...
    install_requires=[
       'dispatch',
    ]
)
```

## Running Tests

Running tests follows the py.test standard. As long as your test files and methods are named appropriately \(`test_filename.py` and `test_function()`\) you can call out to py.test:


================================================
File: docs/docs/administration/settings/cost_model.mdx
================================================
# Cost Model

Our Cost Model is a feature that enables teams to estimate response cost for each incident based on the incident type. Users can opt in to create and use personalized cost calculations for each type of incident based on participant activity. The cost models are automatically applied to each incident based on the incident type.

If an incident type does not have a specific cost model assigned, the default classic cost model will be used when calculating the incident costs. See [Incident Cost Type](./incident/incident-cost-type.mdx###calculating-incident-cost).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-cost-model.png)

</div>

## Key Features

### Customizable Cost Models
Users have the flexibility to define their unique cost models based on their organization's workflow and tools. This customization can be tailored to each incident type, providing a versatile approach to cost calculation. The cost model for an incident type can be changed at any time. When cost model changes are made to the incident type or an incident changes its type, all participant activity costs moving forward will be calculated using the new cost model.

### Plugin-Based Tracking
Users can track costs from their existing tools by using our plugin-based tracking system. Users have the flexibility to select which plugins and specific plugin events they want to track, offering a targeted approach to cost calculation.

### Effort Assignment
For each tracked activity, users can assign a quantifiable measure of effort, represented in seconds of work time. This feature provides a more accurate representation of the cost of an incident.

### Incident Cost Calculation
Incident cost calculation is based on the cost model and effort assignment for each tracked participant activity. This helps in understanding resource utilization and cost of an incident.


## Currently Supported Plugin Events

### Slack: Channel Activity
This event tracks activity within a specific Slack channel. By periodically polling channel messages, this gathers insights into the activity and engagement levels of each participant.

### Slack: Thread Activity
This event tracks activity within a specific Slack thread. By periodically polling thread replies, this gathers insights into the activity and engagement levels of each participant.


<div style={{textAlign: 'center'}}>

![](/img/admin-ui-edit-cost-model.png)

</div>

## Cost Calculation Examples

Below, we illustrate the use of the cost model through two examples. These are based on the following values:

<b>Cost Model 1</b>

| Plugin Event | Response Time (seconds)
|  ------------ | -------------
| Slack Channel Activity | 300

The employee hourly rate can be adjusted by modifying the `Annual Employee Cost` and `Business Year Hours` fields in the [project settings](./project.mdx). In these examples, we will use the following value:
```
hourly_rate = 100
```

#### Example 1

Consider the following Slack channel activity for `Incident 1`:

| Slack Channel Activity Timestamp | Participant
|  ------------ | -------------
| 100 | Cookie Doe
| 200 | Nate Flex

The resulting recorded participant activity will be:

| Participant | started_at | ended_at | Plugin Event | Incident
|  ------------ | ------------- | ------------- |  ------------- | -------------
| Cookie Doe | 100 | 400 | Slack Channel Activity | Incident 1
| Nate Flex | 200 | 500 | Slack Channel Activity | Incident 1


The incident cost is then calculated as:

```
( (400 - 100) + (500 - 200) ) / SECONDS_IN_HOUR * hourly_rate = $16.67
```

#### Example 2

Consider the following Slack channel activity for `Incident 2`:

| Slack Channel Activity Timestamp | Participant
|  ------------ | -------------
| 100 | Cookie Doe
| 150 | Cookie Doe
| 200 | Nate Flex
| 500 | Cookie Doe

The resulting recorded participant activity will be:

| Participant | started_at | ended_at | Plugin Event | Incident
|  ------------ | ------------- | ------------- |  ------------- | -------------
| Cookie Doe | 100 | 450 | Slack Channel Activity | Incident 2
| Nate Flex | 200 | 500 | Slack Channel Activity | Incident 2
| Cookie Doe | 500 | 800 | Slack Channel Activity | Incident 2


The incident cost is then calculated as:

```
( (450 - 100) + (500 - 200) + (800 - 500) ) / SECONDS_IN_HOUR * hourly_rate = $26.39
```


================================================
File: docs/docs/administration/settings/index.mdx
================================================
---
sidebar_position: 4
---

# Settings

The Dispatch Web UI is home to all of Dispatch administration abilities; these contain things that are likely to change frequently \(less often changed items live in the Dispatch configuration file\).

To access Dispatch settings, look for the `Settings` menu item and select a project which you want to administer.

<div style={{textAlign: 'center'}}>

![settings](/img/admin-ui-settings.png)

</div>


================================================
File: docs/docs/administration/settings/messaging.mdx
================================================
# Messaging

Dispatch supports sending email notifications to participants of, for example, an incident.

## Notification templates

Templates for emails are [part](https://github.com/Netflix/dispatch/tree/main/src/dispatch/messaging/email/templates) of Dispatch
and are [Jinja](https://jinja.palletsprojects.com/) templates that during runtime are compiled into [MJML](https://mjml.io/) format.

There is a way to customize these templates. To do this, if you run Dispatch with [Docker Compose](https://github.com/Netflix/dispatch-docker/),
mount a volume with a customized templates dir as part of the docker compose:

```
  web:
    image: dispatch-local
    ...
    volumes:
      - "../dispatch-templates/messaging-email-templates:/usr/local/lib/python3.11/site-packages/dispatch/messaging/email/templates"
```

Such approach allows you to customize the common template for _all projects_.

You can also "patch" the templates _per project_. Create a folder per project (identified by project id):

```
dispatch/messaging/email/templates/project_id/<project_id>/base.mjml
```

This will be used at the first place if exists,
otherwise the resolution process will gracefully fall back to the default template:

```
dispatch/messaging/email/templates/base.mjml
```

## Markdown in the notifications

:::warning
Watch out for security implications related to unescaped HTML that may propagate through the system.
:::

By default, notification text is just a plain text with special characters and HTML escaped.

It is possible, however, to enable Markdown syntax with a server setting:

```
DISPATCH_MARKDOWN_IN_INCIDENT_DESC=True
DISPATCH_ESCAPE_HTML=False
```


================================================
File: docs/docs/administration/settings/project.mdx
================================================
---
description: Overview of the Dispatch projects.
sidebar_position: 0
---

# Projects

Every case or incident within Dispatch is tied to a project. The project configuration determines how cases or incidents are created and managed. This allows multiple teams to use Dispatch in different ways.

From having their own case or incident types and priorities to providing the team with a view of their metrics.

### When should I create a new project vs using an existing one?

Generally, you would create a new project when the teams involved have very little overlap when handling cases or incidents.

For example, you might create a `security` project for the handling of all security-related cases or incidents and a `reliability` project for all outage-related incidents.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-project.png)

</div>

**Name:** A name for your project.

**Description:** A description for your project.

**Color:** A color for your project, so you can visually differentiate it from other projects.

**Annual Employee Cost:** An annual average cost per employee.

**Business Year Hours:** Number of working hours in a year. Used to calculate hourly rate.

**Owner Email:** The email account of the project owner.

**Owner Conversation:** The conversation of the project owner (e.g. Slack channel).


================================================
File: docs/docs/administration/settings/server.mdx
================================================
---
description: >-
  Describes additional configuration options available for the Dispatch server
  itself. Additional plugin-specific configuration can be found in the plugin's
  documentation.
---

# Server

## First Install

Dispatch uses the same configuration system as [Starlette](https://www.starlette.io/config/).

By default, the config is read from environment variables or `.env` files.

:::info
All config items prefixed with `VITE_` are envvars for the Vue frontend. These variables are used only during the building of the javascript bundle. See [here](https://vitejs.dev/guide/env-and-mode.html) for details. You will want to include these variables in `src/dispatch/static/dispatch/.env` during build time.
:::

:::info
In general, do not include any quotation marks when adding configuration values.
:::

### General

#### `LOG_LEVEL` \[default: 'WARNING'\]

> Controls the level of logging the application will perform during operations. Possible values: CRITICAL, ERROR, WARNING, INFO, DEBUG

#### `STATIC_DIR` \[default: './src/static/dispatch/dist'\]

> Controls where on the local disk, static content for the Dispatch Web UI should be served. This variable can also be explicitly set to `''` if you wish to serve static content outside of the Dispatch server.

#### `METRIC_PROVIDERS` \[default: ""\]

> A comma-separated list of metric providers where Dispatch will send key system metrics.

#### `SECRET_PROVIDER` \[default: None\]

> Defines the provider to use for configuration secret decryption. Available options are: `kms-secret` and `metatron-secret`

#### `ENV_TAGS` \[default: ""\]

> A comma-separated list of tags that Dispatch will attempt to pull from the environment. For example, the string `foo:bar,baz:blah` will create two tags: `foo` with the environment value for `bar` and `baz` with the environment value for `blah`.

#### `SENTRY_DSN` \[default: none\]

> Optional configuration for using Sentry to report Dispatch errors.

#### `MJML_PATH` \[default: /node_modules/.bin]

> Dispatch uses [MJML](https://mjml.io/documentation/) to generate its HTML emails. This package also requires the `node` binary to be available on the standard path (or set in Dispatch's path). Use this variable to adjust the location where Dispatch should look for the `mjml` command. **If you are using the stock docker image of Dispatch you must manually set this field to the default path.**

#### `DISPATCH_UI_URL`

> URL of the Dispatch's Admin UI, used by messaging to refer to the Admin UI.

### Authentication

#### `DISPATCH_AUTHENTICATION_PROVIDER_SLUG` \['default': dispatch-auth-provider-basic\]

> Used by Dispatch to determine which authentication provider to use; by default, Dispatch ships with a PKCE authentication provider.

:::info
If you wish to disable authentication set `DISPATCH_AUTHENTICATION_PROVIDER_SLUG=`
:::

#### Configuration for `dispatch-auth-provider-basic`

:::warning
Today, basic authentication allows self-registration without approval.
:::

:::info
For this plugin to work, you need to set `DISPATCH_JWT_SECRET`.
:::

#### `DISPATCH_JWT_SECRET`

> Used by the basic auth provider to mint JWT tokens.

#### `DISPATCH_JWT_ALG` \['default': 'HS256'\]

> Used by the basic auth provider to mint JWT tokens.

#### `DISPATCH_JWT_EXP` \['default': 86400 \]

> Used by the basic auth provider to mint JWT tokens and set their expiration.

#### `DISPATCH_JWT_AUDIENCE`

> Override what the `Audience` is expected to be in the PKCE JWT decode

#### `DISPATCH_JWT_EMAIL_OVERRIDE`

> Override where Dispatch should find the user email in the idtoken.

#### `DISPATCH_AUTHENTICATION_DEFAULT_USER` \['default': dispatch@example.com\]

> Used as the default anonymous user when authentication is disabled.

#### Configuration for `dispatch-auth-provider-pkce`

:::info
For this plugin to work with your OIDC setup, you may need to set
`DISPATCH_JWT_AUDIENCE` and `DISPATCH_PKCE_DONT_VERIFY_AT_HASH`.
:::

#### `DISPATCH_AUTHENTICATION_PROVIDER_PKCE_JWKS`

> Used by Dispatch's authentication backend to pull the JSON Web Key Set \(JWKS\) public key from the specified provider.
> This will likely be the `jwks_uri` URL from your OIDC provider.
> This is required when using the `dispatch-auth-provider-pkce` auth provider.

#### `DISPATCH_PKCE_DONT_VERIFY_AT_HASH` \['default': false\]

> Depending on what values your OIDC provider sends, you may need to set this to `true` for the Dispatch backend
> to be able to decode the JWT token.

#### `DISPATCH_AUTHENTICATION_PROVIDER_PKCE_OPEN_ID_CONNECT_URL`

> The well-known configuration URL for your OIDC provider, without a trailing slash. Used by the Dispatch
> Web UI to authenticate a user via Proof Key Code Exchange \(PKCE\).

#### `DISPATCH_AUTHENTICATION_PROVIDER_PKCE_CLIENT_ID`

> The client id to send to the OpenID Connect endpoint.

#### `DISPATCH_AUTHENTICATION_PROVIDER_USE_ID_TOKEN` \['default': false\]

> Use `id_token` instead of default `access_token`. [Details](https://developer.okta.com/docs/reference/api/oidc/#tokens-and-claims)
> Depends on the identity provider.

#### Configuration for `dispatch-auth-provider-header`

> Authenticate users based on HTTP request headers. Useful when Dispatch is behind a reverse proxy performing authentication.

#### `DISPATCH_AUTHENTICATION_PROVIDER_HEADER_NAME` \['default': remote-user\]

:::info
Make sure the reverse proxy strips this header from incoming requests (i.e. user-provided). Failure to do so will result in authentication bypass.
:::

> The HTTP request header to use as the user name, this value is case-insensitive.

#### Configuration for `dispatch-auth-provider-aws-alb`

> Authenticate users based on [AWS Application Load Balancer authenticate](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/listener-authenticate-users.html).

#### `DISPATCH_AUTHENTICATION_PROVIDER_AWS_ALB_ARN`

> ARN of your Load Balancer, used to validate the signer.
> The format is `arn:aws:elasticloadbalancing:region-code:account-id:loadbalancer/app/load-balancer-name/load-balancer-id`.
> This is required when using the `dispatch-auth-provider-aws-alb` auth provider.

#### `DISPATCH_AUTHENTICATION_PROVIDER_AWS_ALB_EMAIL_CLAIM` \['default': email\]

> Override where Dispatch should find the user email in the users claims.

#### `DISPATCH_AUTHENTICATION_PROVIDER_AWS_ALB_PUBLIC_KEY_CACHE_SECONDS` \['default': 300\]

> Override how long Dispatch should cache the public key, used to validate the payload.

:::info
Add a ALB listener action without authenticate for `/api/v1/{organization}/events/*` if you want plugins to be public. Plugins determine their own authentication.
:::

### Persistence

#### `DATABASE_HOSTNAME`

> Dispatch relies on a `Postgres` database. This hostname should point to a supporter version of `Postgres (9.6+)`.

#### `DATABASE_CREDENTIALS` \[secret: True\]

> Credentials specified in `username:password` format to be used to authenticate to the `postgres` database.

#### `DATABASE_NAME` \[default: 'dispatch'\]

> Allows the user to specify the database name for the `Dispatch` backend.

#### `DATABASE_PORT` \[default: '5432'\]

> Allows the user to specify the database port for the `Dispatch` backend.

### Models

### Incident Cost

Dispatch [calculates](https://github.com/Netflix/dispatch/blob/develop/src/dispatch/incident/service.py#L279) the cost of an incident by adding up the time participants have spent on each incident role \(e.g., Incident Commander\) and applying an [engagement multiplier](https://github.com/Netflix/dispatch/blob/develop/src/dispatch/incident/service.py#L266) that's based on the incident role. It also includes time spent on incident review-related activities. Dispatch calculates and published the cost for all incidents [every 5 minutes](https://github.com/Netflix/dispatch/blob/develop/src/dispatch/incident/scheduled.py#L257).


================================================
File: docs/docs/administration/settings/templates.mdx
================================================
# Templates

Templates are used by Dispatch to create case or incident specific documentation. These templates are copied and filled out to the best of Dispatch's abilities. After their creation, they are normal documents that are associated to your case or incident and can be used for collaborating and capturing facts and findings.

There are several types of templates that Dispatch supports:

- Case
- Incident
- Executive
- Review
- Tracking

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-create-edit-template.png)

</div>
**Name:** Name of the template.

**Description:** Description of the template.

**Weblink:** The weblink to the template.

**External Id:** External identifier for the document template. Used for API integration (e.g. Google doc file id). Typically, the unique id in the weblink.

Enabling evergreen for a template instructs Dispatch to send an email reminder to the template owner informing them that they should review the template to ensure that the template is up to date.

**Evergreen Owner:** The email address representing the owner of this document template.

**Evergreen Reminder Interval:** Number of days that should elapse between reminders sent to the document template owner.

### Case Template

A copy of this template is created for each new case on case creation. It contains the current state of the case and is used by the case owner/ assignee to capture facts and findings.

- [Example Case Document](https://docs.google.com/document/d/1g1cl9liXG8US0eBnrZYRaeWa7Ek_hoZJ5PPadas44vI)

#### Template Variables

The following is a list of available variables that Dispatch will attempt to resolve on document creation. Note: we do not currently re-resolve these.

NOTE: All variables must be enclosed in a `{{}}`

- `case_name` - The case's name
- `case_title` - The cases's title
- `case_description` - The case's description
- `case_resolution` - The case's resolution
- `case_owner` - The case's owner
- `case_type` - The case's type
- `case_severity` - The case's severity
- `case_priority` - The case's priority
- `case_status` - The case's status
- `case_storage_weblink` - Link to the storage resource

### Incident Template

A copy of this template is created for each new incident on incident creation. It contains the current state of the incident and is used by incident participants to share knowledge about the incident.

- [Example Incident Document](https://docs.google.com/document/d/1fv--CrGpWJJ4nyPR0N0hq4JchHJPuqsXN4azE9CGQiE)

#### Template Variables

The following is a list of available variables that Dispatch will attempt to resolve on document creation. Note: we do not currently re-resolve these.

NOTE: All variables must be enclosed in a `{{}}`

- `name` - The name of the incident
- `title` - The incident's title
- `description` - The incident's description
- `resolution` - The incident's resolution
- `commander_fullname` - The current commander's name
- `type` - The incident's type
- `priority` - The incident's priority
- `status` - The incident's status
- `conversation_weblink` - Link to the conversation resource (if any)
- `conference_weblink` - Link to the conference resource (if any)
- `storage_weblink` - Link to the storage resource (if any)
- `document_weblink` - Link to the incident document (if any)
- `ticket_weblink` - Link to the incident ticket (if any)

### Executive Template

Often during an incident an executive report needs to be drafted that provides a high-level overview of the incident and the current actions that are being carried out. A copy of this template will be created, filled, and stored in the incident storage every time a new executive report is drafted.

- [Example Executive Report](https://docs.google.com/document/d/1dab6k14p5ageo5B_d1YlB_zS9hMGHDMXy9RUbIZous4)

### Review Template

A copy of this template is automatically created when an incident is marked as stable. It is used by the incident commander and participants for reconciling any incident learnings, discussions, or post-incident tasks.

- [Example Incident Review Document](https://docs.google.com/document/d/1MkCTyheZRtKzMxOBhLgh3PrvarERA9Bwo0joM7D9tmg)

### Tracking Template

Some incidents require the tracking of multiple assets, this template is a simple spreadsheet that allows incident participants to collaborate on tabular data.

- [Example Incident Tracking Sheet](https://docs.google.com/spreadsheets/d/1Odk4KlL7uMF_yd7OvTOCaPWmtTA_WzFBIA4lMeU5cGY)

### Template Association

Case and incident templates can be associated to their corresponding types. This allows our templates to closely match a given case or incident type and provide additional context and direction for those given types.

Additionally, templates can be associated with multiple case or incident types, if for example, you only want to use one template.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-associate-case-template.png)

</div>

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-associate-incident-template.png)

</div>


================================================
File: docs/docs/administration/settings/case/case-priority.mdx
================================================
# Case Priority

In addition to case types, Dispatch allows you to specify the case's priority.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-case-priorities.png)

</div>

**Name:** The name of the case priority presented to the user.

**Description:** The description of the case priority presented to the user.

**View Order:** The order in which the priority will be listed in menus and dropdowns.

**Color:** The color used for the case priority in the UI.

**Default Case Priority:** If the reporter of a case does not provide a priority, a default will be used. Enable the setting to make this case priority the default.

**Enabled:** Whether this case priority is enabled or not.


================================================
File: docs/docs/administration/settings/case/case-severity.mdx
================================================
# Case Severity

In addition to case types, Dispatch allows you to specify the case's severity.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-case-severities.png)

</div>

**Name:** The name of the case severity presented to the user.

**Description:** The description of the case severity presented to the user.

**View Order:** The order in which the severity will be listed in menus and dropdowns.

**Color:** The color used for the case severity in the UI.

**Default Case Severity:** If the reporter of a case does not provide a severity, a default will be used. Enable the setting to make this case severity the default.

**Enabled:** Whether this case severity is enabled or not.


================================================
File: docs/docs/administration/settings/case/case-type.mdx
================================================
# Case Types

Dispatch allows you to categorize your cases by defining case types and to map them to various Dispatch resources (e.g. templates, oncall services, and incident types).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-case-types.png)

</div>

**Name:** The name of the case type presented to the user.

**Description:** The description of the case type presented to the user.

**Visibility:** Allows you to specify how visible a case of this type will be. Note: this option is currently not being leveraged.

**Case Template:** Allows you to create a new or map an existing case document template to the case type.

**Oncall Service:** Allows you to map an existing oncall service that will be used to determining the owner of the case.

**Incident Type:** The type of incident that will be created and linked to the case if a case of this type is moved to the Escalated status.

**Exclude From Metrics:** Enable this setting to exclude all cases of this type from metrics (e.g., test cases).

**Default Case Type:** If the creator of a case does not provide a case type, a default case type is used. Enable this setting to make this case type the default.

**Enabled:** Whether the case type is enabled or not.

**Plugin Metadata:** Allows you to define and pass metadata key-value pairs to plugins. For example, create issues in different Jira projects based on the case type.


================================================
File: docs/docs/administration/settings/case/index.mdx
================================================
---
sidebar_position: 4
---

# Case

Cases are meant to triage events that do not raise to the level of incidents, but can be escalated to incidents if necessary. If you map a case type to an incident type and you escalate the case, then Dispatch will automatically create an incident and link the two.

While Dispatch holds some strong opinions about _how_ to run cases. It does allow for quite a lot of flexibility. Below you will find several different areas that allow you to make the case experience fit your organization.


================================================
File: docs/docs/administration/settings/contact/index.mdx
================================================
---
sidebar_position: 5
---

# Contact


================================================
File: docs/docs/administration/settings/contact/individual.mdx
================================================
# Individual

In Dispatch, Individuals are either internal or external people identifiers. Typically, an organization will maintain a robust internal directory for user identities. Dispatch does not expect to replace those data stores. Instead, it keeps a lightweight notion of identities to associate with incidents for filtering and metrics.

It's common for incident response teams to maintain a list of contacts and run books to specify whom to contact when an incident occurs. Dispatch handles this for incident response teams by pulling the right individuals directly into an incident. By assigning terms, incident types, or incident priorities to individuals, Dispatch can instantly add them to the incident \(if internal\) or suggest reaching out to them \(if external\).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-contacts-individuals.png)

</div>

**Name:** Name of the individual.

**Email:** Email address associated with the individual.

**Company:** Company associated with the individual.

#### Engagement

In addition to fields about the individual, Dispatch allows you to associate the individual with other Dispatch primitives. For instance, if you would like to involve an individual for all incidents of a given priority, associate that priority with the individual.


================================================
File: docs/docs/administration/settings/contact/service.mdx
================================================
# Service

Like `Teams`, there are often groups of individuals (teams) responsible for an application or service that need to be involved in an incident. However, in these circumstances, we don't want to engage the _whole_ team. We only want to engage the individual that is on-call for the service. `Services` allow Dispatch to resolve these individuals via third-party on-call services (e.g., PagerDuty, OpsGenie).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-contacts-services.png)

</div>

**Name:** Name of the service.

**Description:** Description of the service.

**Plugin:** The associated service plugin that Dispatch will use to resolve the on-call person.

**External Id:** The external ID used by Dispatch and the defined plugin to resolve the on-call person.

**Enabled:** Flag that determines if this particular service is active.

#### Engagement

In addition to the service fields, Dispatch allows you to associate the service with other Dispatch primitives. For instance, if you would like to involve a service for all incidents of a given priority, associate that priority with the service.


================================================
File: docs/docs/administration/settings/contact/team.mdx
================================================
# Team

Like `Individuals`, there are often groups of individuals (teams) that need to be engaged and notified during an incident. Dispatch manages those groups \(typically, team distribution lists\), providing a centralized data store for that contact data.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-contacts-teams.png)

</div>

**Name:** Name of the team.

**Email:** Email address associated with the team.

**Company:** Company associated with the team.

#### Engagement

In addition to fields about the team, Dispatch allows you to associate a team with other Dispatch primitives. For instance, if you would like to involve an entire team for all incidents of a given priority, associate that priority with the team.


================================================
File: docs/docs/administration/settings/data/data-format.mdx
================================================
# Data Formats

Data sources are not always uniformed in nature. It's often helpful to understand what the underlying data format for a given data source is. Here, Dispatch allows you to define common data formats that sources in your environment use.

Some example data formats:

- JSON
- CSV
- Syslog
- XML
- Non-standard


================================================
File: docs/docs/administration/settings/data/environment.mdx
================================================
# Environment

Data sources often have a corresponding environment to which they apply. For example, one data set may only contain information from the production account. When responding to incidents and using data sources for investigation, it's essential to understand the data source's scope.

Some examples of a data source's environment could be:

- Production
- Staging
- Testing
- Development


================================================
File: docs/docs/administration/settings/data/index.mdx
================================================
# Data

Along with incident orchestration, Dispatch is adept at building a catalog of data that can be used to resolve incidents.


================================================
File: docs/docs/administration/settings/data/status.mdx
================================================
# Status

When using a data source in the coarse of an investigation, one needs to understand the current state of that database. Here, Dispatch allows you define your own data source statuses.

Some example status:

- Production
- Testing
- Staging
- Deprecated


================================================
File: docs/docs/administration/settings/data/transport.mdx
================================================
# Transport

Allows the user define their own transport layers for their data sources.

Example source transports:

- REST API
- Syslog
- Hive
- S3
- Kafka
- Kinesis


================================================
File: docs/docs/administration/settings/data/type.mdx
================================================
# Type

You may have several different systems you need to interact with in order to access/query a data source. It's type denotes the underlying technology or system that it's most closely associated with.

Some examples of a data source's type:

- Hive
- ES (ElasticSearch)
- BigQuery
- Splunk


================================================
File: docs/docs/administration/settings/incident/incident-cost-type.mdx
================================================
# Incident Cost Types

Dispatch allows you to define incident cost types. These types can then be used when editing and adding costs to incidents. Dispatch calculates the incident response cost for all incidents every 5 minutes and saves the result to the default incident cost type. We recommend creating at least the response cost type and making it the default to take advantage of this useful feature. You can find the list of incident cost types (or Forms of Loss) recommended by the Factor Analysis of Information Risk (FAIR) Institute [here](https://www.fairinstitute.org/blog/a-crash-course-on-capturing-loss-magnitude-with-the-fair-model).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-cost-types.png)

</div>

**Name:** The name of the incident cost type presented to the user.

**Description:** The description of the incident cost type presented to the user.

**Category:** The Factor Analysis of Information Risk (FAIR) Form of Loss (FOL) or category.

**Default:** Whether the incident cost type is the default or not.

**Editable:** Whether this cost type can be edited or not.

### Calculating Incident Cost

Dispatch [calculates](https://github.com/Netflix/dispatch/blob/develop/src/dispatch/incident/service.py#L279) the cost of an incident by adding up the time participants have spent on each incident role \(e.g., Incident Commander\) and applying an [engagement multiplier](https://github.com/Netflix/dispatch/blob/develop/src/dispatch/incident/service.py#L266) that's based on the incident role. It also includes time spent on incident review-related activities. Dispatch calculates and published the cost for all incidents [every 5 minutes](https://github.com/Netflix/dispatch/blob/develop/src/dispatch/incident/scheduled.py#L257).

If you can tweak incident cost parameters on a per-project basis by editing your project [here](../project.mdx)


================================================
File: docs/docs/administration/settings/incident/incident-priority.mdx
================================================
# Incident Priority

In addition to incident types, Dispatch allows you to specify the incident's _priority_.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-priorities.png)

</div>

**Name:** The name of the incident priority presented to the user.

**Description:** The description of the incident priority presented to the user when reporting.

**View Order:** The order in which the priority will be listed in menus and dropdowns.

**Tactical Report Reminder:** Number of hours between reminders.

**Executive Report Reminder:** Number of hours between reminders.

**Page Commander:** Ensures that the incident commander is paged for all incidents with this priority (if configured paging service and plugin allows).

**Color:** The color used for the incident priority in the UI.

**Default Incident Priority:** If the reporter of an incident does not provide an incident priority, a default will be used. Enable the setting to make this incident priority the default.

**Enabled:** Whether this incident priority is enabled or not.


================================================
File: docs/docs/administration/settings/incident/incident-type.mdx
================================================
# Incident Types

Dispatch allows you to categorize your incidents by defining incidents types and to map them to various Dispatch resources (e.g. templates).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-types.png)

</div>

**Name:** The name of the incident type presented to the user.

**Description:** The description of the incident type presented to the user.

**Visibility:** Allows you to specify how visible an incident of this type will be. For example, if `Open` is chosen, then notifications about an incident of this type will be sent on incident creation and update, and updates included on daily incident reports. All Dispatch users will be able to see incidents of this type in the Web UI regardless of their role. Also, Dispatch will use the Google domain provided to add organization-wide permission to the incident folder and its contents when the incident is marked as closed. However, if `Restricted` is chosen, incidents of this type will not be included in notifications, won't be visible to Dispatch users with a `member` role in the Web UI, and Dispatch won't open the incident folder and its contents to the whole organization. This setting defaults to `Open`.

**Incident Template:** Allows you to create a new or map an existing incident document template to the incident type.

**Executive Template:** Allows you to create a new or map an existing executive report document template to the incident type.

**Review Template:** Allows you to create a new or map an existing post-incident review document template to the incident type.

**Tracking Template:** Allows you to create a new or map an existing incident tracking sheet template to the incident type.

**Exclude From Metrics:** Enable this setting to exclude all incidents of this type from metrics (e.g., "Simulation" or "Test" incidents).

**Default Incident Type:** If the reporter of an incident does not provide an incident type, a default incident type is used. Enable this setting to make this incident type the default.

**Enabled:** Whether the incident type is enabled or not.

**Plugin Metadata:** Allows you to define and pass metadata key-value pairs to plugins. For example, create issues in different Jira projects based on the incident type.

**Cost Model:** Allows you to define how to calculate incident response costs. If an incident type does not have a cost model assigned, the default classic cost model will be used when calculating the incident costs. See [Cost Model](../cost_model.mdx).


================================================
File: docs/docs/administration/settings/incident/index.mdx
================================================
---
sidebar_position: 3
---

# Incident

While Dispatch holds some strong opinions about _how_ to run incidents. It does allow for quite a lot of flexibility. Below you will find several different areas that allow you to make the incident experience fit your organization.


================================================
File: docs/docs/administration/settings/incident/notification.mdx
================================================
# Notification

Notifications allow you to specify who should be sent incident notifications (in addition to those directly involved).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-notifications.png)

</div>

**Name:** The name you wish to present to the user.

**Description:** The description presented to the user when the notification is viewed.

**Type:** The plugin type that should be used to send the notification (email or conversation).

**Target:** The recipient of the notification whatever makes sense for the selected plugin type. (e.g. a Slack conversation name without `#` or an email address.)

**Filters:** The search filter which will be used to determine when a notification should be sent.

**Enabled:** Whether the notification is enabled or not.


================================================
File: docs/docs/administration/settings/incident/workflow.mdx
================================================
# Workflows

Workflows allow you to extend Dispatch, invoking your response automation. Dispatch does not currently include the ability to author workflows directly. Instead, the workflow functionality allows for existing workflows to be invoked from Dispatch. We rely on external workflow orchestration tools to execute those workflows, with Dispatch keeping track of resulting artifacts and workflow status.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-workflows.png)

</div>

**Name:** The name you wish to present to the user.

**Description:** The description presented to the user when the workflow is viewed.

**Resource Id:** The _external_ resource id used by Dispatch to associate the workflow with an external system.

**Plugin:** The plugin to use to resolve and execute this workflow. NOTE: This plugin must be enabled and installed before being associated with a workflow.

**Enabled:** By default, users can't invoke workflows. Activate the "Enabled" setting to allow the use of the workflow.

**Workflow Parameters:** Allows for custom parameters (strings only) to be presented to and set by the user. These are passed to the underlying workflow.


================================================
File: docs/docs/administration/settings/knowledge/definition.mdx
================================================
# Definitions

Definitions collect and manage term definitions from various sources; this enables incident participants to understand the language and terms used throughout an incident.

A definition can be associated with one or more terms \(in case of term overload\).


================================================
File: docs/docs/administration/settings/knowledge/index.mdx
================================================
# Knowledge

Along with incident orchestration, Dispatch is adept at building a knowledge base of incident data. Below we outline the primitives at your disposal and describe how you can manually add to the incident knowledge base.


================================================
File: docs/docs/administration/settings/knowledge/runbooks.mdx
================================================
# Runbooks

Runbooks allow for Dispatch users to provide documents dynamically to incident participants that may be useful during an incident.

Where templates are used to document the state of the incident runbooks typically document steps to take to resolve an incident.

How closely these two ideas are related depends on the incident and how your organization runs it's incidents.

Today, there are two types of runbooks although their actual usage is the same.

- Incident
- Investigation

### Engagement

Runbook documents are dynamically matched to an incident based on their engagement filter. Similar to notification's a user can define for which incidents a document should be recommended to incident participants.

On incident creation (or when an important incident variable changes e.g. incident type) Dispatch will send the incident channel a document suggestion notification.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-create-edit-runbook.png)

</div>

**Name:** Name of the document.

**Description:** Short description of the document.

**Weblink:** A hyperlink representing the document.

**ID:** The external ID that is used to fetch the document.

### Evergreen

Enabling evergreen for a runbook instructs Dispatch to send an email reminder to the runbook owner, informing them that they should check to ensure that the runbook in question is up to date.


================================================
File: docs/docs/administration/settings/knowledge/tag-type.mdx
================================================
# Tag Types

Within Dispatch, tag types are a way to categorize collections of tags (e.g. actor, action, asset, result, etc.).

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-knowledge-tag-types.png)

</div>

**Name:** The name for the tag type.

**Description:** A short description of the tag type.

**Exclusive:** Whether an incident should only have a tag of this type or not.


================================================
File: docs/docs/administration/settings/knowledge/tag.mdx
================================================
# Tags

Within Dispatch, tags are a flexible piece of metadata. They can be manually attached to incidents or automatically discovered based on incident data.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-knowledge-tags.png)

</div>

**Name:** The tag string itself, or what you would expect to be in incident data.

**Description:** A short description of the tag (if applicable).

**Type:** The type of the tag that will be used to disambiguate or categorize this tag from other tags. Tag types can be defined by users or plugins that syncing tags from external sources (e.g., application names).

**Source:** Where the tag originated. For tags created via the UI, Dispatch is the default source.

**URI:** The external tag locator (if available).

**Discoverable:** Dispatch can automatically discover tags. Meaning given a set of predefined tags, it will crawl all incident data available to it and, using NLP, associate this data to incidents (current incident and retroactively). If a tag is general enough (e.g., "the") that you do not want to make it discoverable, this flag can disable that functionality on an individual tag basis.


================================================
File: docs/docs/administration/settings/knowledge/term.mdx
================================================
# Terms

Terms are words or phrases that may not have any meaning to an outside observer but have deep organizational meaning (e.g., acronyms and names).

As an example, take the term PCI. In the security world, this acronym typically refers to the Payment Card Industry security standard.

Any defined term can be associated with Teams, Services, or Individuals for incident inclusion.


================================================
File: docs/docs/administration/settings/plugins/configuring-atlassian-confluence.mdx
================================================
---
description: Configuration page for Atlassian Confluence.
---

# Configuring Atlassian Confluence

:::info
Dispatch ships with Atlassian Confluence storage and document plugins. This page describes the available configurations for the plugins.
:::

## Dispatch configuration variables for storage plugin

### `API URL` \[Required\]

> URL of the confluence cloud instance.

### `Username` \[Required\]

> Username for accessing the confluence instance. This user should have permission to create pages in the space.

### `Password` \[Required\]

> API token to access the confluence instance. Please refer to the [link](https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/) on creating a new API token.

### `Incident template ID` \[Required\]

> This is the page id of the template that contains the post incident review document details. The plugin uses this template to create a new page and then replace the supported variables with the incident details.

### `Default Space ID` \[Required\]

> This is the default space [key](https://confluence.atlassian.com/doc/space-keys-829076188.html) where all the pages will be created in confluence.

### `Parent ID of the pages` \[Required\]

> This is the page id, where all the new pages and subpages will be created.

## Dispatch Configuration Variables for document plugin

### `API URL` \[Required\]

> URL of the confluence cloud instance.

### `Username` \[Required\]

> Username for accessing the confluence instance. This user should have permission to create pages in the space.

### `Password` \[Required\]

> API token to access the confluence instance. Please refer to the [link](https://support.atlassian.com/atlassian-account/docs/manage-api-tokens-for-your-atlassian-account/) on creating a new API token.


================================================
File: docs/docs/administration/settings/plugins/configuring-duo.mdx
================================================
---
description: Configuration options for the Duo plugin.
---

# Configuring Duo

:::info
Dispatch ships with Duo support for additional multi-factor authentication checks within the application, such as when a snooze rule is created. This plugin is not required for core functionality.
:::

## `Integration Key` \[Required. Secret: True\]

> Auth API integration key ('DI...').

## `Integration Secret Key` \[Required. Secret: True\]

> Secret token used in conjunction with integration key.

## `API Hostname` \[Required\]

> API hostname ('api-....duosecurity.com')

## Duo Setup

Log in to the Duo Admin Panel and navigate to `Applications`. Click `Protect an Application` and locate the entry for Auth API in the applications list. Click `Protect` to the far-right to configure the application and get your `integration key`, `secret key`, and `API hostname`.


================================================
File: docs/docs/administration/settings/plugins/configuring-g-suite.mdx
================================================
---
description: Configuration page for all G Suite plugins.
---

# Configuring G Suite Integration

:::info
Dispatch ships with several G Suite plugins \(Docs, Groups, Drive, etc.,\). This page documents the available configuration
for these plugins and the permissions required to enable them.
:::

## Dispatch Configuration Variables

### `GOOGLE_DOMAIN` \[Required\]

> Base domain for which this Google Cloud Platform \(GCP\) service account resides.

### `GOOGLE_DEVELOPER_KEY` \[Required. Secret: True\]

> This is used by the Google API Discovery Service and prevents rate limiting.

### `GOOGLE_SERVICE_ACCOUNT_CLIENT_EMAIL` \[Required\]

> The `client_email` value from your Google Cloud Platform \(GCP\) service account configuration file.

### `GOOGLE_SERVICE_ACCOUNT_CLIENT_ID` \[Required\]

> The `client_id` value from your Google Cloud Platform \(GCP\) service account configuration file.

### `GOOGLE_SERVICE_ACCOUNT_DELEGATED_ACCOUNT` \[Required\]

> Account to delegate to from the Google Cloud Platform \(GCP\) service account.
> Outgoing emails and other artifacts will appear to be from this account.

### `GOOGLE_SERVICE_ACCOUNT_PRIVATE_KEY` \[Required. Secret: True\]

> The `private_key` value from your Google Cloud Platform \(GCP\) service account configuration file.

### `GOOGLE_SERVICE_ACCOUNT_PRIVATE_KEY_ID` \[Required\]

> The `private_key_id` value from your Google Cloud Platform \(GCP\) service account configuration file.

### `GOOGLE_SERVICE_ACCOUNT_PROJECT_ID` \[Required\]

> The `project_id` value from your Google Cloud Platform \(GCP\) service account configuration file.

### `GOOGLE_USER_OVERRIDE` \[Optional. Default: None\]

> Used for development to funnel all emails to a specific user.

## G Suite Setup

To set up G Suite integration, you'll need to create some resources in Google Cloud Platform and then link them to your
G Suite organization.

## Enable Required APIs in Google Cloud Platform

Navigate to the Google Cloud Platform \(GCP\) [console](https://console.cloud.google.com/). You will want to
create a new GCP Project for Dispatch's integration.

Create a new service account within the GCP project \(APIs & Services &gt; Credentials &gt; Create Credentials &gt; Service Account\).
You do not need to assign any Google Cloud permissions to this service account when prompted.

Once created, download the JSON based key. You'll use these values to configure Dispatch:

- `project_id` -&gt; `GOOGLE_SERVICE_ACCOUNT_PROJECT_ID`
- `private_key_id` -&gt; `GOOGLE_SERVICE_ACCOUNT_PRIVATE_KEY_ID`
- `private_key` -&gt; `GOOGLE_SERVICE_ACCOUNT_PRIVATE_KEY`
- `client_email` -&gt; `GOOGLE_SERVICE_ACCOUNT_CLIENT_EMAIL`
- `client_id` -&gt; `GOOGLE_SERVICE_ACCOUNT_CLIENT_ID`

Then, create a Developer API key \(APIs & Services &gt; Credentials &gt; Create Credentials &gt; API Key\), and set it to the value for `GOOGLE_DEVELOPER_KEY`.

Enable the following APIs \(APIs and Services &gt; Library\):

- Google Drive API
- Google Drive Activity API
- Google People API
- Google Docs API
- Google Calendar API
- Gmail API
- Admin SDK \(necessary to create and manage groups\)

Finally, create your OAuth application which is how G Suite will authorize the service account and API key \(APIs & Services &gt; OAuth Consent Screen\).
Specify the following scopes:

```text
https://www.googleapis.com/auth/documents
https://www.googleapis.com/auth/drive
https://www.googleapis.com/auth/directory.readonly
https://www.googleapis.com/auth/drive.activity.readonly
https://mail.google.com/
https://www.googleapis.com/auth/admin.directory.group
https://www.googleapis.com/auth/apps.groups.settings
https://www.googleapis.com/auth/calendar
```

**Note:** If you will not use Google Meet for your conference, then you do not need the `https://www.googleapis.com/auth/calendar` scope.

## Connecting Dispatch to G Suite

Navigate to the G Suite Admin [Domain-wide Delegation](https://admin.google.com/ac/owl/domainwidedelegation) page
\(Security &gt; API Controls &gt; Domain-wide Delegation\) and add a new API client.

Enter the Client ID you used for `GOOGLE_SERVICE_ACCOUNT_CLIENT_ID`, and then paste in a comma-separated list of the OAuth scopes above.


================================================
File: docs/docs/administration/settings/plugins/configuring-jira.mdx
================================================
---
description: Configuration options for the Jira plugin.
---

# Configuring Jira

:::info
Dispatch ships with Jira support. Each Jira installation is unique, so you will likely want to create a Jira-specific plugin for your organization. This plugin is not required for core functionality. However, a plugin of type `ticket` must always be enabled.
:::

## `JIRA_BROWSER_URL` \[Required\]

> URL for Jira browser links.

## `JIRA_API_URL` \[Required\]

> URL for the Jira API server.

## `JIRA_USERNAME` \[Required\]

> Username for the Jira service account.

## `JIRA_PASSWORD` \[Required. Secret: True\]

> Password for the Jira service account.

## `JIRA_PROJECT_ID` \[Required\]

> ID for Jira project. You can find the JIRA project like [this](https://community.atlassian.com/t5/Jira-questions/JIRA-Project-ID/qaq-p/193094) or like [this](https://confluence.atlassian.com/jirakb/how-to-get-project-id-from-the-jira-user-interface-827341414.html).

## `JIRA_ISSUE_TYPE_NAME` \[Required\]

> Name of the Jira issue type.

## `JIRA_HOSTING_TYPE` \[Default: 'Cloud'\]

> Type of Jira hosting used (e.g. Cloud, Server).


================================================
File: docs/docs/administration/settings/plugins/configuring-opsgenie.mdx
================================================
---
description: Configuration options for the Opsgenie plugin.
---

# Configuring Opsgenie

:::info
Dispatch ships with support for resolving on-call schedules via the Opsgenie API. Below is how to configure the Opsgenie plugin to work with `Dispatch.`
:::

## `OPSGENIE_API_KEY` \[Required. Secret: True\]

> Opsgenie API key.

## `OPSGENIE_TEAM_ID` \[Required\]

> Id for the Opsgenie team.


================================================
File: docs/docs/administration/settings/plugins/configuring-pagerduty.mdx
================================================
---
description: Configuration options for the PagerDuty plugin.
---

# Configuring PagerDuty

:::info
Dispatch ships with support for resolving on-call schedules via the PagerDuty API.
:::

### Env Configuration

Add the following env vars to your `.env` file.

## `PAGERDUTY_API_KEY` \[Required. Secret: True\]

> PagerDuty API key.

## `PAGERDUTY_API_FROM_EMAIL` \[Required\]

> Email to be added to all outgoing incident pages.

## Oncall Service Configuration

Go to /services on your Web server running Dispatch and add a new service. Select type `pagerduty-oncall` and add your PagerDuty Service ID in the external id field.

<div style={{textAlign: 'center'}}>

![](/img/pagerduty-service-setup.png)

</div>


================================================
File: docs/docs/administration/settings/plugins/configuring-slack.mdx
================================================
---
description: Configuration options for the Slack plugin.
---

# Configuring Slack

Dispatch ships with support for Slack. Below is how to configure the Slack plugin to work with `Dispatch`.

## Events Mode vs Socket Mode

Dispatch supports both [Events Mode](https://api.slack.com/events-api) and [Socket Mode](https://api.slack.com/apis/connections/socket).

Which mode should you choose?

- If Dispatch will be listening on a public static HTTP endpoint, then we recommend using **events mode**.
- If Dispatch will be deployed behind a corporate firewall or you have security concerns, then we recommend using **socket mode**.

See the [Dispatch Configuration](#dispatch-configuration) section below for further details on the variables.

### Events Mode

Events mode requires specific URL mapping that must be **publicly** accessible:

- `Dispatch` receives general events at the `/api/v1/<organization>/events/slack/event` endpoint (e.g. member joins channel, reactions).
- `Dispatch` receives command events at the `/api/v1/<organization>/events/slack/command` endpoint (`/dispatch-*` commands)
- `Dispatch` receives action events at the `/api/v1/<organization>/events/slack/action` endpoint (dialogs and modals).

### Socket Mode

To enable socket mode, add the socket mode app token in the `Socket Mode App Token` section of the `Slack Plugin - Conversation Management` and the `Slack Plugin - Contact Information Resolver` plugins Dispatch Web UI under Settings -> Project -> Plugins.

Socket mode does not require the mapping of endpoints. These values are ignored in socket mode.

Socket mode requires that you run a separate process (from the main Dispatch webserver) to receive WebSocket events.

The easiest way to run this process is via the following CLI command:

```
dispatch server slack <organization> <project>
```

This process has to be daemonized similarly to the Dispatch webserver.

## Slack Configuration

You will need to set the following configuration settings for your Slack app in the [Slack API Web UI](https://api.slack.com/apps) for both `events mode` and `socket mode`.

### Event Subscriptions

To enable Dispatch to process Slack events, under `Events Subscriptions`, ensure that the `Request URL` points to the events subscription API endpoint of the Dispatch server at `/api/v1/<organization>/events/slack/event`. Replace `<organization>` with your organization's name. The default one is `default`.

Then, under the `Subscribe to bot events` section, add the following bot user events:

| Event Name            | Description                               |
| --------------------- | ----------------------------------------- |
| member_joined_channel | A user joined a public or private channel |
| member_left_channel   | A user left a public or private channel   |
| message.groups        | A message was posted to a private channel |

### Interactivity

To enable Dispatch to generate interactive components such as dialogs and modals, ensure that the `Request URL` points to the events action API endpoint of the Dispatch server at `/api/v1/<organization>/events/slack/action`. Replace `<organization>` with your organization's name. The default one is `default`.

### Slash Commands

To enable Dispatch's slash commands, you must add them to your Slack app first. Ensure that the `Command` field in the Slack API Web UI matches the name of the command name in the Slack plugin in the Dispatch Web UI and that the `Request URL` points to the events command API endpoint of the Dispatch server at `/api/v1/<organization>/events/slack/command`.

<div style={{textAlign: 'center'}}>

![](/img/slack-setup-commands-0.png)

</div>

<div style={{textAlign: 'center'}}>

![](/img/slack-setup-commands-1.png)

</div>

<div style={{textAlign: 'center'}}>

![](/img/slack-setup-commands-2.png)

</div>

### OAuth & Permissions

The `Bot User OAuth Access Token` is used to issue queries against the Slack API.

#### Scopes

The following are the bot and user scopes required for the Dispatch Slack App to function correctly.

**Bot Token Scopes**

```text
bookmarks:write
channels:read
chat:write
commands
files:read
groups:history
groups:read
groups:write
im:history
im:read
im:write
mpim:history
mpim:read
mpim:write
pins:write
reactions:read
reactions:write
team:read
users:read
users:read.email
users.profile:read
users:write
```

**User Token Scopes**

```text
channels:read
groups:history
groups:read
```

## Dispatch Configuration

The Dispatch Slack plugins for conversation management and resolving contact information are configured in the Dispatch Web UI under Settings -> Project -> Plugins. Add the desired plugin(s) using the `NEW` button and then edit the plugin(s) configuration by clicking on the three vertical dots.

### Conversation Management Plugin

#### API Bot Token

> The Slack app's bot token necessary to communicate with the Slack API. Slack refers to this as your "Bot User OAuth Access Token" and should be revealed to app collaborators when installing the app.

#### Socket Mode App Token

> The Slack app's socket mode token provided when socket mode is enabled to authenticate to the WebSocket API. Its value will be ignored if socket mode is not used.

#### Signing Secret

> The secret used to verify signatures included on each HTTP request that Slack sends. Slack refers to this as your "Signing Secret."

#### App User Id

> The Slack app's bot user id so that Dispatch can filter events generated by the app's user \(e.g., message posted in the channel\). You can use the [auth.test](https://api.slack.com/methods/auth.test/test) endpoint and the app's bot token \(`xoxb-*`\) to get the bot user-id \(`UXXXXXXXX`\)."

#### Private Channels

> Whether you want Dispatch to create public or private incident Slack channels.

#### Ban Threads

> Whether you want Dispatch to allow or ban threaded messages in incident channels.

#### Timeline Event Reaction

> The reaction used for adding Slack messages posted in the incident channel to the incident timeline.

#### Command Strings

> The name of the slash commands that your Slack app will expose.

<div style={{textAlign: 'center'}}>

![](/img/slack-plugin-conversation-management.png)

</div>

You can override their values if you wish to do so. Included below are their descriptions for easy cut & paste into your Slack app slash commands set-up.

| Command Name                                                                        | Command Description                                                                                                         |
| ----------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| `/dispatch-add-timeline-event`                                                      | Opens a modal to add an event to the incident timeline.                                                                     |
| `/dispatch-assign-role`                                                             | Opens a modal for assigning a role to a participant.                                                                        |
| `/dispatch-engage-oncall`                                                           | Opens a modal to engage an on-call person.                                                                                  |
| `/dispatch-list-incidents <organization-slug\|'default'> <project-slug\|'default'>` | Lists current active and stable incidents and closed incidents in the last 24 hours.                                        |
| `/dispatch-list-my-tasks`                                                           | Opens a modal with the list of your open and resolved incident tasks.                                                       |
| `/dispatch-list-participants`                                                       | Opens a modal with the list of incident participants.                                                                       |
| `/dispatch-list-signals`                                                            | Opens a modal with the list of signal definitions configured for the conversation from where command was ran.               |
| `/dispatch-list-tasks`                                                              | Opens a modal with the list of open and resolved incident tasks.                                                            |
| `/dispatch-list-workflows`                                                          | List workflows previously run during this incident.                                                                         |
| `/dispatch-report-executive`                                                        | Opens a modal to write an executive report.                                                                                 |
| `/dispatch-report-incident <organization-slug\|'default'>`                          | Opens a modal to report an incident. This command can be run from non-incident channels where the Dispatch bot is a member. |
| `/dispatch-report-tactical`                                                         | Opens a modal to write a tactical report.                                                                                   |
| `/dispatch-run-workflow`                                                            | Run a workflow and associate artifacts with this incident.                                                                  |
| `/dispatch-update-incident`                                                         | Opens a modal to update the incident.                                                                                       |
| `/dispatch-notifications-group`                                                     | Opens a modal to edit the notifications group.                                                                              |
| `/dispatch-update-participant`                                                      | Opens a modal to update participant metadata.                                                                               |
| `/dispatch-create-task`                                                             | Opens a modal to create an incident task.                                                                                   |
| `/dispatch-create-case`                                                             | Opens a modal to create a case.                                                                                   |

### Contact Information Resolver Plugin

#### API Bot Token

> The Slack app's bot token necessary to communicate with the Slack API. Slack refers to this as your "Bot User OAuth Access Token" and should be revealed to app collaborators when installing the app.

#### Socket Mode App Token

> The Slack app's socket mode token provided when socket mode is enabled to authenticate to the WebSocket API. Its value will be ignored if socket mode is not used.

#### Signing Secret

> The secret used to verify signatures included on each HTTP request that Slack sends. Slack refers to this as your "Signing Secret."

#### Profile Department Field Id

> The profile field ID where Department is mapped.

#### Profile Team Field Id

> The profile field ID where the Team is mapped.

#### Profile Weblink Field Id

> The profile field ID where the weblink is mapped.

<div style={{textAlign: 'center'}}>

![](/img/slack-plugin-contact-information-resolver.png)

</div>


================================================
File: docs/docs/administration/settings/plugins/configuring-zoom.mdx
================================================
---
description: Configuration options for the Zoom plugin.
---

# Configuring Zoom

:::info
Dispatch ships with Zoom conference support. The Zoom plugin creates a conference call with a valid time of 6 weeks and generates a password to protect the call. The Web URL returned by the plugin to the messaging is created such that you need to click it and not worry about entering the password.
:::

## `ZOOM_API_USER_ID` \[Required. Secret: True\]

> Email / User ID attached to the JWT credentials.

## `ZOOM_API_KEY` \[Required\]

> JWT API Key.

## `ZOOM_API_SECRET` \[Required. Secret: True\]

> JWT API Secret.

## Create the Zoom Application for your API Keys

To create the API Keys required for the Zoom plugin, navigate to the Zoom Marketplace and select [create an App](https://marketplace.zoom.us/develop/create). Ensure that you are logged in as the user that you wish to tie the API credentials to.

Create a `JWT` application to generate the JWT API Key and Secret. Make sure to set the `Intent to publish: No`.


================================================
File: docs/docs/administration/settings/plugins/index.mdx
================================================
# Plugins

Before being able to configure and use the plugins, refer to the [CLI](../../cli.mdx#plugins) documentation about installing plugins.

Much of Dispatch's functionality comes from its plugins. The current Dispatch web UI is limited to enabling and disabling plugins on a per-project basis. To make modifications to how plugins behave or are configured, changes must be deployed via the server configuration file. See the [server](../server.mdx) configuration documentation for more information.

By default, no plugins are _required_ to create an incident. As you enable plugins, they will be additive to the incident process (e.g., creating slack channels, google docs, etc.)

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-plugins.png)

</div>

Looking to add your own functionality to Dispatch via plugins? See the [contributing](../../contributing/plugins/index.mdx) documentation.


================================================
File: docs/docs/administration/settings/signal/definition.mdx
================================================
# Signal Definition

Signal Definitions are your starting point for onboarding a new Signal into Dispatch and allow a number of different configuration options.

## Sending Signals to Dispatch

You can send a signal to Dispatch by making a `POST` request to the `/{organization}/signals/instances` API endpoint.

```python
import requests

API_TOKEN = ""
API_ENDPOINT = "http://localhost:8080/api/v1/default/signals/instances"

signal_instance = {
  "project": "Test",
  "raw": {
    "name": "process_events",
    "externalId": "someExternalValue",
    "id": "<uuid>", # this will be used as the instance's uuid if provided
    "variant": "A" , # an additional indicator for signal subtypes
    "hostIdentifier": "host1",
    "calendarTime": "2022-10-19T10:35:01Z",
    "time": 1618698901,
    "columns": {
      "pid": 888,
      "path": "/usr/bin/security",
      "cmdline": "/usr/bin/security dump-keychain",
      "state": "running",
      "parent": 555,
      "created_at": 1918698901,
      "updated_at": 2118698901
    }
  }
}

requests.Session()
r = session.post(
    API_ENDPOINT,
    json=signal_instance,
    headers={
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_TOKEN}",
    },
)
```

:::note

You can view the full API documentation for the `/instances` endpoint in the [API Reference](https://netflix.github.io/dispatch/docs/api#tag/signals/operation/create_signal_instance__organization__signals_instances_post).

:::

## Creating a Signal Definition

At a high level, you'll need to configure some basic metadata about your `signal` such as the name, description, and variant.
You can also configure whether a `signal` should create a case or not. Choosing not to create a case can be useful for contextual signals that
don't necessarily warrant triage and investigation on their own. But, you can still use these signals to enrich other signals and cases.

![](/img/admin-ui-signal-definition.png)

**Variant**: The same signal can have multiple varitants with different definitions.

**Owner**: Typically the team or owner that produces the Siganl.

**External ID**: This ID will be used to correctly associate incoming signals to this definition. This ID should be unique across all Signal Definitions.

**Conversation Target**: Defines the channel name where the Case for the Signal will be created.


================================================
File: docs/docs/administration/settings/signal/engagement-filter.mdx
================================================
# Engagement Filter

Engagement Filters are used to automate the process of reaching out to a user involved in a specific Signal Instance. Engagement Filters make use of Entity Types that match email addresses for users in your environment and custom message you configure to be sent to those users. Engagement Filters also support multi-factor authentication when validating suspicious behavior. This feature is useful when you want to be confident the user you engaged is actually who they say they are and not a malicious actor.

### Creating an Engagement Filter

To create an Engagement Filter, follow these steps:

1. Navigate to a Signal Definition edit page.
2. Click on the '+' icon adjacent to the 'Engagement Filter(s)' dropdown menu.

![](/img/admin-ui-signal-engagement-filter.png)


================================================
File: docs/docs/administration/settings/signal/entity-type.mdx
================================================
# Entity Type

Entity Types enable the extraction of entities from the raw Signal Instance data. Once extracted, these entities are stored for further use, enabling features like automatic correlations, engagement filters, and signal filters.

### Creating an Entity Type

To create an Entity Type, follow these steps:

1. Navigate to a Signal Definition edit page.
2. Click on the '+' icon adjacent to the 'Entity Type(s)' dropdown menu.

Upon clicking, the Entity Type playground will be launched in a modal window. This playground is an interactive tool designed to aid you in creating and validating your Entity Type. Entity Types can be constructed using either regular expressions or the JSON Path format.

![](/img/admin-ui-signal-entity-type.png)

In the illustrated example, a new Entity Type is defined using the JSON Path format. The JSON Path expression, columns.cmdline, is used to extract the value of the cmdline column from the raw Signal Instance data. The playground editor accentuates the extracted value within the raw Signal Instance data, validating a successful match with the desired value.

Once you are satisfied with your Entity Type, proceed through the playground to the naming and description stage. Here, you'll provide a suitable name and a brief description for the Entity Type. By clicking 'Save', the Entity Type gets successfully created and is then linked with the corresponding Signal Definition.

![](/img/admin-ui-signal-entity-type-name.png)


================================================
File: docs/docs/administration/settings/signal/filter.mdx
================================================
# Filter

Signal Filters are used to define how Signals should be grouped together or when they should be snoozed.

:::note
To create a Signal Filter, you must first define the Entity Types that will be used to deduplicate or snooze Signals.
:::

## Snooze Filter

Snooze filters make use of entities extracted from signals to define when a signal should be snoozed. This feature is useful when an influx of signals is expected for a given period of time (e.g. some known administration activities) and you want to temporarily stop cases from being created. Even when a signal is snoozed it will still be processed and associated entities will be created.

For example, you can create a `Snooze Filter` that will snooze all incoming signals that contain a specific JA3 hash.

:::info
You also have the option to create a `Snooze Filter` without specifying any entities, which will snooze all incoming signals matching that filter.
:::

### Creating a Snooze Filter

To create an Snooze Filter, follow these steps:

1. Navigate to a Signal Definition edit page.
2. Click on the '+' icon adjacent to the 'Signal Filter(s)' dropdown menu.
3. Select the `Snooze` radio button under the `BASIC` tab.


![](/img/admin-ui-signal-filter-snooze.png)

## Deduplication Filter

In order to perform signal duplication, a duplication filter must be created. Deduplication filters leverage extracted signal entity types and a sliding time window in order to determine if a signal should be marked as a duplicate. If a match is found, the current signal is marked as duplicate and it is associated with the existing case.

:::info
By default, all Signals are deduplicated over a one hour window unless a custom Deduplication Filter is defined.
:::

### Creating a Deduplication Filter

To create an Deduplication Filter, follow these steps:

1. Navigate to a Signal Definition edit page.
2. Click on the '+' icon adjacent to the 'Signal Filter(s)' dropdown menu.
3. Select the `Deduplication` radio button under the `BASIC` tab.

![](/img/admin-ui-signal-filter-dedupe.png)


================================================
File: docs/docs/administration/settings/signal/index.mdx
================================================
---
sidebar_position: 4
---

# Signal

Signals are a way to define different events that you ingest into Dispatch and raise to the level of cases.


================================================
File: docs/docs/user-guide/data.mdx
================================================
# Data

The data view is how one accesses Dispatch's internal data catalog. It provides the ability to store metadata about data sources likely to be used to resolve incidents.


================================================
File: docs/docs/user-guide/index.mdx
================================================
---
title: Introduction
sidebar_position: 0
---

# User Guide

There are two _main_ personas within Dispatch: an incident commander and an incident participant.

The incident commander is responsible for driving an incident to resolution. They act as a tie-breaking vote on contentious decisions and are responsible for understanding the _entire_ incident context. Depending on the team and scale of the incident, they are also responsible for delegating tasks and asking questions of other incident participants.

Incident participants are subject matter experts (SMEs) brought into the incident to help resolve tasks or answer the incident commander's questions.

Next, you will find more information about how each of these personas interacts with Dispatch.


================================================
File: docs/docs/user-guide/cases/index.mdx
================================================
# Cases

Most participants will never have to use the Dispatch Case UI. But for commanders and power users, this view provides a way to search, filter, and interact with cases even if they are closed.


================================================
File: docs/docs/user-guide/dashboard/incident.mdx
================================================
---
description: How to get useful incident metrics.
sidebar_position: 1
---

# Incidents

## Aggregated top-line metrics

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-dashboard-top-line.png)

</div>

These metrics are aggregated across all currently filtered incidents.

## Breakdown on key incident facets

### By Incident Type

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-dashboard-type.png)

</div>

### By Incident Priority

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-dashboard-priority.png)

</div>

## Forecasting

Dispatch has the ability to do some _simple_ forecasting. It looks at prior incident history and applies [Exponential Smoothing](https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/#:~:text=Exponential%20smoothing%20is%20a%20time%20series%20forecasting%20method%20for%20univariate%20data.&text=Exponential%20smoothing%20forecasting%20methods%20are,decreasing%20weight%20for%20past%20observations) to guess how many incidents will be encountered in the future.

This works okay for small incident loads but becomes better with more incidents. If there isn't enough data to make a reasonable forecast one will not be displayed in the UI.

An example forecast:

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-dashboard-forecast.png)

</div>


================================================
File: docs/docs/user-guide/dashboard/index.mdx
================================================
---
description: How to get useful metrics.
sidebar_position: 1
---

# Dashboards

Dispatch provides basic dashboarding and reporting functionality that allows users to understand how incidents impact their organization. It comes preconfigured with useful aggregations like the number of incidents by type and priority.

Additionally, all of the dashboard graphs are dynamic. This dynamism allows us to identify interesting subsets of data by filtering by different incident facets.


================================================
File: docs/docs/user-guide/incidents/commander.mdx
================================================
---
description: What to expect as an incident commander.
---

# Commander

## Reporting

Within Dispatch, Incident Commanders \(ICs\) are also participants and will receive all of the participant messaging. When resolved as the Incident Commander, you are assigned that Dispatch role, and your identity is propagated.

All Slack commands are listed below, or you may view _groups_ of commands relating to [People](#people), [Communications](#communications), [Tasks](#tasks), and [Incident Resources & Metadata](#incident-resources-and-metadata).

## All Slack commands

- [`/dispatch-add-timeline-event`](#%2Fdispatch-add-timeline-event)
- [`/dispatch-assign-role`](#%2Fdispatch-assign-role)
- [`/dispatch-engage-oncall`](#%2Fdispatch-engage-oncall)
- [`/dispatch-list-my-tasks`](#%2Fdispatch-list-my-tasks)
- [`/dispatch-list-participants`](#%2Fdispatch-list-participants)
- [`/dispatch-list-tasks`](#%2Fdispatch-list-tasks)
- [`/dispatch-list-workflows`](#%2Fdispatch-list-workflows)
- [`/dispatch-list-incidents`](#%2Fdispatch-list-incidents)
- [`/dispatch-notifications-group`](#%2Fdispatch-notifications-group)
- [`/dispatch-report-executive`](#%2Fdispatch-report-executive)
- [`/dispatch-report-incident`](#%2Fdispatch-report-incident)
- [`/dispatch-report-tactical`](#%2Fdispatch-report-tactical)
- [`/dispatch-update-incident`](#%2Fdispatch-update-incident)
- [`/dispatch-update-participant`](#%2Fdispatch-update-participant)
- [`/dispatch-run-workflow`](#%2Fdispatch-list-workflow)
- [`/dispatch-create-task`](#%2Fdispatch-create-task)
- [`/dispatch-create-case`](#%2Fdispatch-create-case)
## People

These commands help manage the people helping resolve the incident.

### /dispatch-assign-role

Anyone helping run an incident may play various roles. For example, you may have a scribe or an executive liaison, or you may hand off the incident to a new Incident Commander. At any of these times, use `/dispatch-assign-role` to quickly assign a role to any individual.

It's essential to use this command when handing off responsibility for incident leadership. Doing so will help avoid any confusion about the identity of the current Incident Commander.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-assign-role.png)

</div>

### /dispatch-engage-oncall

You'll need the help of various teams to resolve an incident. To quickly engage an on-call member of another team, use `/dispatch-engage-oncall` to determine their identity and optionally page them.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-engage-oncall.png)

</div>

### /dispatch-list-participants

Use this command to determine which teams and individuals are engaged in the incident. The output looks like this:

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-list-participants.png)

</div>

### /dispatch-update-participant

Participants in an incident, or the Incident Commander, may want to know a participant's area of expertise or their expected contribution to resolving an incident. Use `/dispatch-update-participant` to update the reason a participant was added. The dialog appears like this:

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-update-participant.png)

</div>

## Communications

These commands help manage incident communications.

### /dispatch-notifications-group

An incident notifications group consists of individuals or distribution lists. Manage this group by using `/dispatch-notifications-group.`

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-notifications-group.png)

</div>

### /dispatch-report-executive

Some stakeholders are invested in an incident's progress but aren't expected to be directly involved with the incident. For example, your Chief Financial Officer may want to know of an ongoing security incident regarding financial data but will likely not be directing participants or their actions. To keep external stakeholders such as these informed, use `/dispatch-report-executive` to build and distribute a high-level report.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-report-executive.png)

</div>

### /dispatch-report-incident

Use `/dispatch-report-incident` to report a new incident.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-report-incident.png)

</div>

### /dispatch-report-tactical

Regular tactical reports, such as using the Conditions, Actions, and Needs (CAN) format, are critical to keeping your participants well-informed. Use `/dispatch-report-tactical` to easily create these.

The report form will appear like this:

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-status-report.png)

</div>

The output in the Slack channel will appear like this:

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-status-report-response.png)

</div>

## Tasks

Dispatch provides a lightweight bridge between Google Docs comments assigned as tasks and your Slack incident channel.

It looks like this, in the Incident Document:

<div style={{textAlign: 'center'}}>

![](/img/google-docs-task-comment.png)

</div>

The following commands help manage these tasks associated with an incident.

### /dispatch-list-my-tasks

Any individual who issues the `/dispatch-list-my-tasks` command will see a list of tasks created by or assigned to them.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-list-my-tasks.png)

</div>

### /dispatch-list-tasks

Use `/dispatch-list-tasks` to display a temporary message listing all tasks associated with the incident.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-list-tasks.png)

</div>

## Incident resources and metadata

These commands help manage incident resources and metadata (data about the incident).

### /dispatch-update-incident

This command allows the IC to modify several aspects of the incident without ever leaving the conversation interface.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-edit-incident.png)

</div>

### /dispatch-add-timeline-event

This command helps you add an event to the incident timeline. You may use local time (derived from your Slack profile) or Coordinated Universal Time (UTC).

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-add-timeline-event.png)

</div>

### /dispatch-list-workflows

This command will list all workflows associated with the current incident.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-list-workflows.png)

</div>

### /dispatch-run-workflow

This command will run a pre-configured workflow and associate its artifacts with the current incident.

<div style={{textAlign: 'center'}}>

![](/img/slack-conversation-run-workflow.png)

</div>

### /dispatch-create-task

This command will create a task for the current incident.
<div style={{textAlign: 'center'}}>

{/* TODO(averyl): replace this image */}
![](/img/slack-conversation-create-task.png)

</div>

### /dispatch-create-case

This command will create a case for the current incident.

<div style={{textAlign: 'center'}}>

</div>


================================================
File: docs/docs/user-guide/incidents/feedback.mdx
================================================
# Feedback

Dispatch sends a direct message on incident close to all incident participants asking them to rate their satisfaction on how to incident was handled and to provide feedback. Feedback submitted by incident participants is stored and displayed in the feedback section of the UI, and shared with the incident's commander via email on a daily basis.

#### Direct Message

<div style={{textAlign: 'center'}}>

![](/img/user-guide-incident-feedback-conversation-direct-message.png)

</div>

#### Feedback Modal

<div style={{textAlign: 'center'}}>

![](/img/user-guide-incident-feedback-conversation-modal.png)

</div>

#### Feedback UI Table

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-feedback.png)

</div>


================================================
File: docs/docs/user-guide/incidents/forms.mdx
================================================
---
description: How to create custom incident forms
---

# Forms

## Creating a custom form

Within Dispatch, admins can create a custom form under Settings -> (choose Project) -> Incident / Form Types. This brings up a table of existing form types (if any). Click on the NEW button to create a new form type.

### Form schema

The form schema takes a JSON array of form objects of the following type:

| Attribute | Possible values             | Notes                             |
| --------- | --------------------------- | --------------------------------- |
| type      | boolean, select, text, date |                                   |
| title     |                             | this is the question              |
| if        |                             | conditional (see below)           |
| name      |                             | unique identifier string          |
| multiple  | true, false                 | only for select                   |
| options   |                             | list of options / only for select |
| hint      |                             | shown as small text (optional)    |

The following fields are required for each form object: `type`, `title`, and `name`. For `select` types, there must be a corresponding `options` attribute.

Note: be sure to set the form type to "Enabled" so that it will appear in the forms tab in the incident.

#### Conditionals

The `if` attribute can be a complex JavaScript boolean expression. Refer to other form items using the format `$<name>` where `<name>` is the unique name identifier.

##### Example

```
   [
     { "type": "boolean", "title": "Is this a good form?", "name": "good_form", "hint": "Check if you like"},
     { "type": "select", "if": "$good_form", "title": "How good?", "options": [ "Very much", "A lot", "It's ok" ], "multiple": false, "name": "like_level"},
     { "type": "text", "if": "$good_form && $like_level && $like_level.includes('A lot')", "title": "Provide more feedback", "name": "feedback"}
   ]
```

## Fill out a form in an incident

After an incident is opened, go to the View/Edit panel and select the Forms tab at the top. This view will list all of the forms that have been filled out so far. They can either be in the Draft or Completed state. Users can either edit an existing form or create a new one based on any of the enabled form types created as above.

While a form is being completed, the user can **Cancel** to discard any changes, **Save as Draft** to save the filled in information and set as _Draft_, or **Submit** to save and set as _Completed_.

## Attorney review

A new tab on the left "Forms" lists all of the _Draft_ and _Completed_ forms for leadership and attorney review. For each form, users can view/edit, delete, and a special **Attorney Review** option. This option shows relevant incident details and the values filled out in the form. It also provides an attorney status dropdown and two new fields for attorney notes and open questions.

## Additional attorney questions

If additional questions are required for the attorney team to assess the information on the form, each form type has the option of asking additional attorney questions. This schema follows the same format as the main form schema. The additional attorney questions will appear only on the Attorney Section when performing the Attorney Review from the Forms page.

![](/img/attorney-section.png)

## Scoring schema

A risk score can be calculated based on the form responses. The scoring schema is a JSON array of objects of the following type:

| Attribute | Type | Notes                                  |
| --------- | ---- | -------------------------------------- |
| var       | text | the corresponding variable on the form |
| includes  | list | a JSON list of chosen options          |
| score     | int  | the score to add                       |

If the form data corresponding to `var` contains any elements in the list `includes`, then the value indicated by `score` is added to the Risk Score. Note that this is currently not cumulative, i.e., if there are two elements on the list in the form data, the score is only added once. For example, using the example form schema above and the below scoring schema, if the user selects "Very much", the risk score would be 10.

```
   [
     { "var": "like_level", "includes": [ "Very much", "A lot" ], "score": 10},
     { "var": "like_level", "includes": [ "It's ok" ], "score": 1},
   ]
```

The risk score shows up on the Forms tab in the Risk Score column as well as on the attorney summary section on the Attorney Review card.

![](/img/example-risk-score.png)


================================================
File: docs/docs/user-guide/incidents/index.mdx
================================================
---
sidebar_position: 2
---

# Incidents

Most participants will never have to use the Dispatch Incident UI. But for commanders and power users, this view provides a way to search, filter, and interact with incidents even if they are closed.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incidents.png)

</div>


================================================
File: docs/docs/user-guide/incidents/participant.mdx
================================================
---
description: What to expect as an incident participant.
---

# Participant

## Reporting

Dispatch attempts to make reporting incidents as easy as possible. Dispatch provides a dedicated incident report form that users throughout the organization can submit to engage incident-related resources.

Located at: `https://<your-dispatch-domain>/default/incidents/report`

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-report.png)

</div>

Once submitted, the user is presented with all of the incident resources they need to start managing the incident.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-report-receipt.png)

</div>

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-incident-report-resources.png)

</div>

## During

After an incident is created, Dispatch will engage new participants automatically. Which participants are engaged is determined by rules defined in the Dispatch Admin UI.

Each new participant receives a welcome message \(Email + Slack\) providing them resources and information to orient them for this given incident.

<div style={{textAlign: 'center'}}>

![Incident welcome email](/img/email-incident-welcome.png)

</div>

<div style={{textAlign: 'center'}}>

![Incident welcome slack (ephemeral)](https://lh4.googleusercontent.com/EgiaPr7p7X-MsmhU7LCNn9BoM0qgqlj-yFBRsxHYGFY6GWSVmYkqNjDzFB-iTNpZBlaxjpVJ_R8HC5jO9gu12ehtIGfT3-7At7lQms-dppkxiFZTyOA8LUQyubCDqLAU23NYwcoQfrw)

</div>

Throughout the incident, Dispatch manages the resources necessary to run your investigation, while also providing reminders and notifications.

## After

After an incident is marked stable, Dispatch continues to help with incident management creating additional resources such as Post Incident Review \(PIRs\) documents.

## Notifications

In addition to Dispatch engaging individuals that will be directly responsible for managing the incident, it provides notifications for general awareness throughout the organization.

:::info
The new incident notification message includes a "Join" button if "Self-Join" is enabled on the project; this allows individuals to add themselves to the incident \(and its resources\) without involvement from the incident commander.
:::

## Self-service engagement

Often participants will want to "self-subscribe" to incidents given a set of parameters. Dispatch allows individuals to be automatically engaged given these parameters.

To set up an individual's engagement, navigate to `Contact > Individual` and either edit an existing individual or create a new one.

Next, modify the individual's engagement by selecting or adding terms or phrases that you would like to be engaged when found in an incident attributes, inviting the user when a match is found.

For more documentation of incident engagement see [here](administration/settings/contact/index.mdx).

### How it works

For any given set of parameters (incident type, incident priority, title, description, etc.) Dispatch will attempt to engage any individual that has associated with those parameters. Currently, this is an "OR" association between terms. Meaning that if any term is matched, the individual will be pulled into the incident.

As the incident evolves, new information is uncovered. Dispatch will re-evaluate these associations any time those parameters change, adding additional individuals if necessary.

As an example, take an incident that is reported as a "Credential Leak". Dispatch will engage any individual that has associated the terms "Credential", "Leak", and "Credential Leak" (case and punctuation are ignored).

Now, if we find out during the investigation that the incident is really a "System Compromise" and we change the description and title appropriately, Dispatch will then pull in individuals associated with the terms "System", "Compromise", and "System Compromise".


================================================
File: docs/docs/user-guide/incidents/tasks.mdx
================================================
# Tasks

Similar to the incident view, incident tasks are managed in the incident channel itself. But when you want to view all incident tasks across the organization, this view gives you that ability.

<div style={{textAlign: 'center'}}>

![](/img/admin-ui-tasks.png)

</div>


================================================
File: docs/scripts/generate_api_schema.py
================================================
import yaml
import os

from fastapi.openapi.utils import get_openapi

DISPATCH_JWT_SECRET = "test"

# TEST
DATABASE_HOSTNAME = "foo"
DATABASE_CREDENTIALS = "bar:bar"
DISPATCH_ENCRYPTION_KEY = "baz"

os.environ["DISPATCH_JWT_SECRET"] = DISPATCH_JWT_SECRET
os.environ["DATABASE_HOSTNAME"] = DATABASE_HOSTNAME
os.environ["DATABASE_CREDENTIALS"] = DATABASE_CREDENTIALS
os.environ["DISPATCH_ENCRYPTION_KEY"] = DISPATCH_ENCRYPTION_KEY

from dispatch.main import api as app  # noqa


with open("openapi.yaml", "w") as f:
    yaml.dump(
        get_openapi(
            title=app.title,
            version=app.version,
            openapi_version=app.openapi_version,
            description=app.description,
            routes=app.routes,
        ),
        f,
    )


================================================
File: docs/src/components/HomepageFeatures/index.js
================================================
import React from "react"
import clsx from "clsx"
import styles from "./styles.module.css"

const FeatureList = [
  {
    title: "Easy to Use",
    Svg: require("@site/static/img/undraw_docusaurus_mountain.svg").default,
    description: (
      <>
        Dispatch was designed to stay out of the spotlight, instead opting to supercharge existing
        tools (Slack, Google Docs, etc.,) for us in incident response.
      </>
    ),
  },
  {
    title: "Focus on What Matters",
    Svg: require("@site/static/img/undraw_docusaurus_tree.svg").default,
    description: (
      <>
        Dispatch lets you focus on your incident, let Dispatch manage timelines, documentation and
        people leaving you to focus on resolve the incident.
      </>
    ),
  },
  {
    title: "API First",
    Svg: require("@site/static/img/undraw_docusaurus_react.svg").default,
    description: <>Extend or customize Dispatch via it's API or integrated plugins.</>,
  },
]

function Feature({ Svg, title, description }) {
  return (
    <div className={clsx("col col--4")}>
      <div className="text--center">
        <Svg className={styles.featureSvg} role="img" />
      </div>
      <div className="text--center padding-horiz--md">
        <h3>{title}</h3>
        <p>{description}</p>
      </div>
    </div>
  )
}

export default function HomepageFeatures() {
  return (
    <section className={styles.features}>
      <div className="container">
        <div className="row">
          {FeatureList.map((props, idx) => (
            <Feature key={idx} {...props} />
          ))}
        </div>
      </div>
    </section>
  )
}


================================================
File: docs/src/components/HomepageFeatures/styles.module.css
================================================
.features {
  display: flex;
  align-items: center;
  padding: 2rem 0;
  width: 100%;
}

.featureSvg {
  height: 200px;
  width: 200px;
}


================================================
File: docs/src/css/custom.css
================================================
/**
 * Any CSS included here will be global. The classic template
 * bundles Infima by default. Infima is a CSS framework designed to
 * work well for content-centric websites.
 */

/* You can override the default Infima variables here. */
:root {
  --ifm-color-primary: #e50914;
  --ifm-color-primary-dark: #B20710;
  --ifm-color-primary-darker: #82030a;
  --ifm-color-primary-darkest: #580307;
  --ifm-color-primary-light: #29d5b0;
  --ifm-color-primary-lighter: #359962;
  --ifm-color-primary-lightest: #3cad6e;
  --ifm-code-font-size: 95%;
  --docusaurus-highlighted-code-line-bg: rgba(0, 0, 0, 0.1);
  --aa-primary-color-rgb: 229, 9, 20 !important;
  --aa-muted-color-rgb: 255, 0, 0 !important;
}

/* For readability concerns, you should choose a lighter palette in dark mode. */
[data-theme='dark'] {
  --ifm-color-primary: #E50914;
  --ifm-color-primary-dark: #B20710;
  --ifm-color-primary-darker: #82030a;
  --ifm-color-primary-darkest: #580307;
  --ifm-color-primary-light: #29d5b0;
  --ifm-color-primary-lighter: #32d8b4;
  --ifm-color-primary-lightest: #4fddbf;
  --docusaurus-highlighted-code-line-bg: rgba(0, 0, 0, 0.3);
  --aa-primary-color-rgb: 229, 9, 20 !important;
  --aa-muted-color-rgb: 255, 0, 0 !important;
}

.header-github-link:hover {
  opacity: 0.6;
}

.header-github-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%3Csvg viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12'/%3E%3C/svg%3E")
    no-repeat;
}

[data-theme='dark'] .header-github-link::before {
  background: url("data:image/svg+xml,%3Csvg viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath fill='white' d='M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12'/%3E%3C/svg%3E")
    no-repeat;
}


================================================
File: docs/src/pages/index.js
================================================
import React from "react"
import clsx from "clsx"
import Link from "@docusaurus/Link"
import useDocusaurusContext from "@docusaurus/useDocusaurusContext"
import Layout from "@theme/Layout"
import HomepageFeatures from "@site/src/components/HomepageFeatures"

import styles from "./index.module.css"

function HomepageHeader() {
  const { siteConfig } = useDocusaurusContext()
  return (
    <header className={clsx("hero hero--primary", styles.heroBanner)}>
      <div className="container">
        <h1 className="hero__title">{siteConfig.title}</h1>
        <p className="hero__subtitle">{siteConfig.tagline}</p>
      </div>
    </header>
  )
}

export default function Home() {
  const { siteConfig } = useDocusaurusContext()
  return (
    <Layout
      title={`Hello from ${siteConfig.title}`}
      description="Description will go into a meta tag in <head />"
    >
      <HomepageHeader />
      <main>
        <HomepageFeatures />
      </main>
    </Layout>
  )
}


================================================
File: docs/src/pages/index.module.css
================================================
/**
 * CSS files with the .module.css suffix will be treated as CSS modules
 * and scoped locally.
 */

.heroBanner {
  padding: 4rem 0;
  text-align: center;
  position: relative;
  overflow: hidden;
}

@media screen and (max-width: 996px) {
  .heroBanner {
    padding: 2rem;
  }
}

.buttons {
  display: flex;
  align-items: center;
  justify-content: center;
}


================================================
File: docs/src/pages/markdown-page.md
================================================
---
title: Markdown page example
---

# Markdown page example

You don't need React to write simple standalone pages.


================================================
File: src/dispatch/__init__.py
================================================
import os
import os.path
import traceback
from subprocess import check_output

try:
    VERSION = __import__("pkg_resources").get_distribution("dispatch").version
except Exception:
    VERSION = "unknown"

# fix is in the works see: https://github.com/mpdavis/python-jose/pull/207
import warnings

warnings.filterwarnings("ignore", message="int_from_bytes is deprecated")

# sometimes we pull version info before dispatch is totally installed
try:
    from dispatch.organization.models import Organization  # noqa lgtm[py/unused-import]
    from dispatch.project.models import Project  # noqa lgtm[py/unused-import]
    from dispatch.route.models import Recommendation  # noqa lgtm[py/unused-import]
    from dispatch.conference.models import Conference  # noqa lgtm[py/unused-import]
    from dispatch.conversation.models import Conversation  # noqa lgtm[py/unused-import]
    from dispatch.cost_model.models import (
        CostModel,  # noqa lgtm[py/unused-import]
        CostModelActivity,  # noqa lgtm[py/unused-import]
    )
    from dispatch.definition.models import Definition  # noqa lgtm[py/unused-import]
    from dispatch.document.models import Document  # noqa lgtm[py/unused-import]
    from dispatch.event.models import Event  # noqa lgtm[py/unused-import]
    from dispatch.incident.models import Incident  # noqa lgtm[py/unused-import]
    from dispatch.monitor.models import Monitor  # noqa lgtm[py/unused-import]
    from dispatch.feedback.incident.models import Feedback  # noqa lgtm[py/unused-import]
    from dispatch.feedback.service.models import ServiceFeedback  # noqa lgtm[py/unused-import]
    from dispatch.group.models import Group  # noqa lgtm[py/unused-import]
    from dispatch.incident_cost.models import IncidentCost  # noqa lgtm[py/unused-import]
    from dispatch.incident_cost_type.models import IncidentCostType  # noqa lgtm[py/unused-import]
    from dispatch.incident_role.models import IncidentRole  # noqa lgtm[py/unused-import]
    from dispatch.incident.priority.models import IncidentPriority  # noqa lgtm[py/unused-import]
    from dispatch.incident.severity.models import IncidentSeverity  # noqa lgtm[py/unused-import]
    from dispatch.incident.type.models import IncidentType  # noqa lgtm[py/unused-import]
    from dispatch.individual.models import IndividualContact  # noqa lgtm[py/unused-import]
    from dispatch.notification.models import Notification  # noqa lgtm[py/unused-import]
    from dispatch.participant.models import Participant  # noqa lgtm[py/unused-import]
    from dispatch.participant_activity.models import (
        ParticipantActivity,  # noqa lgtm[py/unused-import]
    )
    from dispatch.participant_role.models import ParticipantRole  # noqa lgtm[py/unused-import]
    from dispatch.plugin.models import Plugin, PluginEvent  # noqa lgtm[py/unused-import]
    from dispatch.report.models import Report  # noqa lgtm[py/unused-import]
    from dispatch.service.models import Service  # noqa lgtm[py/unused-import]
    from dispatch.storage.models import Storage  # noqa lgtm[py/unused-import]
    from dispatch.tag.models import Tag  # noqa lgtm[py/unused-import]
    from dispatch.tag_type.models import TagType  # noqa lgtm[py/unused-import]
    from dispatch.task.models import Task  # noqa lgtm[py/unused-import]
    from dispatch.team.models import TeamContact  # noqa lgtm[py/unused-import]
    from dispatch.term.models import Term  # noqa lgtm[py/unused-import]
    from dispatch.ticket.models import Ticket  # noqa lgtm[py/unused-import]
    from dispatch.workflow.models import Workflow  # noqa lgtm[py/unused-import]
    from dispatch.data.source.status.models import SourceStatus  # noqa lgtm[py/unused-import]
    from dispatch.data.source.transport.models import SourceTransport  # noqa lgtm[py/unused-import]
    from dispatch.data.source.type.models import SourceType  # noqa lgtm[py/unused-import]
    from dispatch.data.alert.models import Alert  # noqa lgtm[py/unused-import]
    from dispatch.data.query.models import Query  # noqa lgtm[py/unused-import]
    from dispatch.data.source.models import Source  # noqa lgtm[py/unused-import]
    from dispatch.search_filter.models import SearchFilter  # noqa lgtm[py/unused-impot]
    from dispatch.case.models import Case  # noqa lgtm[py/unused-impot]
    from dispatch.case.priority.models import CasePriority  # noqa lgtm[py/unused-import]
    from dispatch.case.severity.models import CaseSeverity  # noqa lgtm[py/unused-import]
    from dispatch.case.type.models import CaseType  # noqa lgtm[py/unused-import]
    from dispatch.case_cost.models import CaseCost  # noqa lgtm[py/unused-import]
    from dispatch.case_cost_type.models import CaseCostType  # noqa lgtm[py/unused-import]
    from dispatch.signal.models import Signal  # noqa lgtm[py/unused-import]
    from dispatch.feedback.service.reminder.models import (
        ServiceFeedbackReminder,  # noqa lgtm[py/unused-import]
    )
    from dispatch.forms.type.models import FormsType  # noqa lgtm[py/unused-import]
    from dispatch.forms.models import Forms  # noqa lgtm[py/unused-import]
    from dispatch.email_templates.models import EmailTemplates  # noqa lgtm[py/unused-import]


except Exception:
    traceback.print_exc()


def _get_git_revision(path):
    if not os.path.exists(os.path.join(path, ".git")):
        return None
    try:
        revision = check_output(["git", "rev-parse", "HEAD"], cwd=path, env=os.environ)
    except Exception:
        # binary didn't exist, wasn't on path, etc
        return None
    return revision.decode("utf-8").strip()


def get_revision():
    """
    :returns: Revision number of this branch/checkout, if available. None if
        no revision number can be determined.
    """
    if "DISPATCH_BUILD" in os.environ:
        return os.environ["DISPATCH_BUILD"]
    package_dir = os.path.dirname(__file__)
    checkout_dir = os.path.normpath(os.path.join(package_dir, os.pardir, os.pardir))
    path = os.path.join(checkout_dir)
    if os.path.exists(path):
        return _get_git_revision(path)
    return None


def get_version():
    if __build__:
        return f"{__version__}.{__build__}"
    return __version__


def is_docker():
    # One of these environment variables are guaranteed to exist
    # from our official docker images.
    # DISPATCH_VERSION is from a tagged release, and DISPATCH_BUILD is from a
    # a git based image.
    return "DISPATCH_VERSION" in os.environ or "DISPATCH_BUILD" in os.environ


__version__ = VERSION
__build__ = get_revision()


================================================
File: src/dispatch/alembic.ini
================================================
# A generic, single database configuration.

[alembic]
# template used to generate migration files
file_template = %%(year)d-%%(month).2d-%%(day).2d_%%(rev)s

[core]
script_location = dispatch:database/revisions/core

[tenant]
script_location = dispatch:database/revisions/tenant

# timezone to use when rendering the date
# within the migration file as well as the filename.
# string value is passed to dateutil.tz.gettz()
# leave blank for localtime
# timezone =

# max length of characters to apply to the
# "slug" field
# truncate_slug_length = 40

# set to 'true' to run the environment during
# the 'revision' command, regardless of autogenerate
# revision_environment = false

# set to 'true' to allow .pyc and .pyo files without
# a source .py file to be detected as revisions in the
# versions/ directory
# sourceless = false

# version location specification; this defaults
# to alembic/versions.  When using multiple version
# directories, initial revisions must be specified with --version-path
# version_locations = %(here)s/bar %(here)s/bat alembic/versions

# the output encoding used when revision files
# are written from script.py.mako
# output_encoding = utf-8

# format using black
hooks = black
black.type = console_scripts
black.entrypoint = black
black.options = -l 79 REVISION_SCRIPT_FILENAME

# Logging configuration
[loggers]
keys = root,sqlalchemy,alembic

[handlers]
keys = console

[formatters]
keys = generic

[logger_root]
level = WARN
handlers = console
qualname =

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine

[logger_alembic]
level = WARN
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[formatter_generic]
format = %(levelname)-5.5s [%(name)s] %(message)s
datefmt = %H:%M:%S


================================================
File: src/dispatch/api.py
================================================
from typing import List, Optional

from fastapi import APIRouter, Depends

from pydantic import BaseModel
from starlette.responses import JSONResponse

from dispatch.auth.service import get_current_user
from dispatch.auth.views import user_router, auth_router
from dispatch.case.priority.views import router as case_priority_router
from dispatch.case.severity.views import router as case_severity_router
from dispatch.case.type.views import router as case_type_router
from dispatch.case.views import router as case_router
from dispatch.case_cost.views import router as case_cost_router
from dispatch.case_cost_type.views import router as case_cost_type_router
from dispatch.data.alert.views import router as alert_router
from dispatch.data.query.views import router as query_router
from dispatch.data.source.data_format.views import router as source_data_format_router
from dispatch.data.source.environment.views import router as source_environment_router
from dispatch.data.source.status.views import router as source_status_router
from dispatch.data.source.transport.views import router as source_transport_router
from dispatch.data.source.type.views import router as source_type_router
from dispatch.data.source.views import router as source_router
from dispatch.definition.views import router as definition_router
from dispatch.document.views import router as document_router
from dispatch.entity.views import router as entity_router
from dispatch.entity_type.views import router as entity_type_router
from dispatch.feedback.incident.views import router as feedback_router
from dispatch.feedback.service.views import router as service_feedback_router
from dispatch.incident.priority.views import router as incident_priority_router
from dispatch.incident.severity.views import router as incident_severity_router
from dispatch.incident.type.views import router as incident_type_router
from dispatch.incident.views import router as incident_router
from dispatch.incident_cost.views import router as incident_cost_router
from dispatch.cost_model.views import router as cost_model_router
from dispatch.incident_cost_type.views import router as incident_cost_type_router
from dispatch.incident_role.views import router as incident_role_router
from dispatch.individual.views import router as individual_contact_router
from dispatch.models import OrganizationSlug
from dispatch.notification.views import router as notification_router
from dispatch.organization.views import router as organization_router
from dispatch.plugin.views import router as plugin_router
from dispatch.project.views import router as project_router
from dispatch.forms.views import router as forms_router
from dispatch.forms.type.views import router as forms_type_router
from dispatch.email_templates.views import router as email_template_router


from dispatch.signal.views import router as signal_router

# from dispatch.route.views import router as route_router
from dispatch.search.views import router as search_router
from dispatch.search_filter.views import router as search_filter_router
from dispatch.service.views import router as service_router
from dispatch.tag.views import router as tag_router
from dispatch.tag_type.views import router as tag_type_router
from dispatch.task.views import router as task_router
from dispatch.team.views import router as team_contact_router
from dispatch.term.views import router as term_router
from dispatch.workflow.views import router as workflow_router


class ErrorMessage(BaseModel):
    msg: str


class ErrorResponse(BaseModel):
    detail: Optional[List[ErrorMessage]]


api_router = APIRouter(
    default_response_class=JSONResponse,
    responses={
        400: {"model": ErrorResponse},
        401: {"model": ErrorResponse},
        403: {"model": ErrorResponse},
        404: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)

# WARNING: Don't use this unless you want unauthenticated routes
authenticated_api_router = APIRouter()


def get_organization_path(organization: OrganizationSlug):
    pass


api_router.include_router(auth_router, prefix="/{organization}/auth", tags=["auth"])

# NOTE: All api routes should be authenticated by default
authenticated_api_router.include_router(
    organization_router, prefix="/organizations", tags=["organizations"]
)

authenticated_organization_api_router = APIRouter(
    prefix="/{organization}", dependencies=[Depends(get_organization_path)]
)

authenticated_organization_api_router.include_router(
    project_router, prefix="/projects", tags=["projects"]
)

# Order matters for path eval
authenticated_organization_api_router.include_router(
    source_type_router, prefix="/data/sources/types", tags=["source_types"]
)
authenticated_organization_api_router.include_router(
    source_transport_router, prefix="/data/sources/transports", tags=["source_transports"]
)
authenticated_organization_api_router.include_router(
    source_status_router, prefix="/data/sources/statuses", tags=["source_statuses"]
)

authenticated_organization_api_router.include_router(
    source_data_format_router, prefix="/data/sources/dataFormats", tags=["source_data_formats"]
)

authenticated_organization_api_router.include_router(
    source_environment_router, prefix="/data/sources/environments", tags=["source_environments"]
)

authenticated_organization_api_router.include_router(
    source_router, prefix="/data/sources", tags=["sources"]
)

authenticated_organization_api_router.include_router(
    query_router, prefix="/data/queries", tags=["queries"]
)
authenticated_organization_api_router.include_router(
    alert_router, prefix="/data/alerts", tags=["alerts"]
)

authenticated_organization_api_router.include_router(
    signal_router, prefix="/signals", tags=["signals"]
)

authenticated_organization_api_router.include_router(user_router, prefix="/users", tags=["users"])
authenticated_organization_api_router.include_router(
    document_router, prefix="/documents", tags=["documents"]
)
authenticated_organization_api_router.include_router(
    entity_router, prefix="/entity", tags=["entities"]
)
authenticated_organization_api_router.include_router(
    entity_type_router, prefix="/entity_type", tags=["entity_types"]
)
authenticated_organization_api_router.include_router(tag_router, prefix="/tags", tags=["tags"])
authenticated_organization_api_router.include_router(
    tag_type_router, prefix="/tag_types", tags=["tag_types"]
)
authenticated_organization_api_router.include_router(
    service_router, prefix="/services", tags=["services"]
)
authenticated_organization_api_router.include_router(
    team_contact_router, prefix="/teams", tags=["teams"]
)
authenticated_organization_api_router.include_router(
    individual_contact_router, prefix="/individuals", tags=["individuals"]
)
# authenticated_api_router.include_router(route_router, prefix="/route", tags=["route"])
authenticated_organization_api_router.include_router(
    definition_router, prefix="/definitions", tags=["definitions"]
)
authenticated_organization_api_router.include_router(term_router, prefix="/terms", tags=["terms"])
authenticated_organization_api_router.include_router(task_router, prefix="/tasks", tags=["tasks"])
authenticated_organization_api_router.include_router(
    search_router, prefix="/search", tags=["search"]
)
authenticated_organization_api_router.include_router(
    search_filter_router, prefix="/search/filters", tags=["search_filters"]
)
authenticated_organization_api_router.include_router(
    incident_router, prefix="/incidents", tags=["incidents"]
)
authenticated_organization_api_router.include_router(
    incident_priority_router,
    prefix="/incident_priorities",
    tags=["incident_priorities"],
)
authenticated_organization_api_router.include_router(
    incident_severity_router,
    prefix="/incident_severities",
    tags=["incident_severities"],
)
authenticated_organization_api_router.include_router(
    incident_type_router, prefix="/incident_types", tags=["incident_types"]
)
authenticated_organization_api_router.include_router(case_router, prefix="/cases", tags=["cases"])
authenticated_organization_api_router.include_router(
    case_type_router, prefix="/case_types", tags=["case_types"]
)
authenticated_organization_api_router.include_router(
    case_priority_router,
    prefix="/case_priorities",
    tags=["case_priorities"],
)
authenticated_organization_api_router.include_router(
    case_severity_router,
    prefix="/case_severities",
    tags=["case_severities"],
)
authenticated_organization_api_router.include_router(
    case_cost_router,
    prefix="/case_costs",
    tags=["case_costs"],
)
authenticated_organization_api_router.include_router(
    case_cost_type_router,
    prefix="/case_cost_types",
    tags=["case_cost_types"],
)
authenticated_organization_api_router.include_router(
    cost_model_router,
    prefix="/cost_models",
    tags=["cost_models"],
)
authenticated_organization_api_router.include_router(
    workflow_router, prefix="/workflows", tags=["workflows"]
)
authenticated_organization_api_router.include_router(
    plugin_router, prefix="/plugins", tags=["plugins"]
)
authenticated_organization_api_router.include_router(
    feedback_router, prefix="/feedback", tags=["feedback"]
)
authenticated_organization_api_router.include_router(
    service_feedback_router, prefix="/service_feedback", tags=["service_feedback"]
)
authenticated_organization_api_router.include_router(
    notification_router, prefix="/notifications", tags=["notifications"]
)
authenticated_organization_api_router.include_router(
    incident_cost_router, prefix="/incident_costs", tags=["incident_costs"]
)
authenticated_organization_api_router.include_router(
    incident_cost_type_router,
    prefix="/incident_cost_types",
    tags=["incident_cost_types"],
)
authenticated_organization_api_router.include_router(
    incident_role_router, prefix="/incident_roles", tags=["role"]
)
authenticated_organization_api_router.include_router(forms_router, prefix="/forms", tags=["forms"])
authenticated_organization_api_router.include_router(
    forms_type_router, prefix="/forms_type", tags=["forms_type"]
)
authenticated_organization_api_router.include_router(
    email_template_router, prefix="/email_template", tags=["email_template"]
)


@api_router.get("/healthcheck", include_in_schema=False)
def healthcheck():
    return {"status": "ok"}


api_router.include_router(
    authenticated_organization_api_router, dependencies=[Depends(get_current_user)]
)

api_router.include_router(
    authenticated_api_router,
    dependencies=[Depends(get_current_user)],
)


================================================
File: src/dispatch/cli.py
================================================
import logging
import os

import click
import uvicorn

from dispatch import __version__, config
from dispatch.config import DISPATCH_UI_URL
from dispatch.enums import UserRoles
from dispatch.plugin.models import PluginInstance

from .extensions import configure_extensions
from .scheduler import scheduler

os.environ["OAUTHLIB_INSECURE_TRANSPORT"] = "1"

log = logging.getLogger(__name__)


@click.group()
@click.version_option(version=__version__)
def dispatch_cli():
    """Command-line interface to Dispatch."""
    from .logging import configure_logging

    configure_logging()

    configure_extensions()


@dispatch_cli.group("plugins")
def plugins_group():
    """All commands for plugin manipulation."""
    pass


@plugins_group.command("list")
def list_plugins():
    """Shows all available plugins."""
    from tabulate import tabulate

    from dispatch.database.core import SessionLocal
    from dispatch.plugin import service as plugin_service

    db_session = SessionLocal()
    table = []
    for record in plugin_service.get_all(db_session=db_session):
        table.append(
            [
                record.title,
                record.slug,
                record.version,
                record.type,
                record.author,
                record.description,
            ]
        )

    click.secho(
        tabulate(
            table,
            headers=[
                "Title",
                "Slug",
                "Version",
                "Type",
                "Author",
                "Description",
            ],
        ),
        fg="blue",
    )


@plugins_group.command("install")
@click.option(
    "-f",
    "--force",
    is_flag=True,
    help="Force a plugin to update all details about itself, this will overwrite the current database entry.",
)
def install_plugins(force):
    """Installs all plugins, or only one."""
    from dispatch.common.utils.cli import install_plugins
    from dispatch.database.core import SessionLocal
    from dispatch.plugin import service as plugin_service
    from dispatch.plugin.models import Plugin, PluginEvent
    from dispatch.plugins.base import plugins

    install_plugins()

    db_session = SessionLocal()
    for p in plugins.all():
        record = plugin_service.get_by_slug(db_session=db_session, slug=p.slug)
        if not record:
            click.secho(f"Installing plugin... Slug: {p.slug} Version: {p.version}", fg="blue")
            plugin = Plugin(
                title=p.title,
                slug=p.slug,
                type=p.type,
                version=p.version,
                author=p.author,
                author_url=p.author_url,
                multiple=p.multiple,
                description=p.description,
            )
            db_session.add(plugin)
            record = plugin
        else:
            if force:
                click.secho(f"Updating plugin... Slug: {p.slug} Version: {p.version}", fg="blue")
                # we only update values that should change
                record.title = p.title
                record.version = p.version
                record.author = p.author
                record.author_url = p.author_url
                record.description = p.description
                record.type = p.type

        # Registers the plugin events with the plugin or updates the plugin events
        for plugin_event_in in p.plugin_events:
            click.secho(f"  Registering plugin event... Slug: {plugin_event_in.slug}", fg="blue")
            if plugin_event := plugin_service.get_plugin_event_by_slug(
                db_session=db_session, slug=plugin_event_in.slug
            ):
                plugin_event.name = plugin_event_in.name
                plugin_event.description = plugin_event_in.description
                plugin_event.plugin = record
            else:
                plugin_event = PluginEvent(
                    name=plugin_event_in.name,
                    slug=plugin_event_in.slug,
                    description=plugin_event_in.description,
                    plugin=record,
                )
                db_session.add(plugin_event)
        db_session.commit()


@plugins_group.command("uninstall")
@click.argument("plugins", nargs=-1)
def uninstall_plugins(plugins):
    """Uninstalls all plugins, or only one."""
    from dispatch.database.core import SessionLocal
    from dispatch.plugin import service as plugin_service

    db_session = SessionLocal()

    for plugin_slug in plugins:
        plugin = plugin_service.get_by_slug(db_session=db_session, slug=plugin_slug)
        if not plugin:
            click.secho(
                f"Plugin slug {plugin_slug} does not exist. Make sure you're passing the plugin's slug.",
                fg="red",
            )

        plugin_service.delete(db_session=db_session, plugin_id=plugin.id)


@dispatch_cli.group("user")
def dispatch_user():
    """Container for all user commands."""
    pass


@dispatch_user.command("register")
@click.argument("email")
@click.option(
    "--organization",
    "-o",
    required=True,
    help="Organization to set role for.",
)
@click.password_option()
@click.option(
    "--role",
    "-r",
    required=True,
    type=click.Choice(UserRoles),
    help="Role to be assigned to the user.",
)
def register_user(email: str, role: str, password: str, organization: str):
    """Registers a new user."""
    from dispatch.auth import service as user_service
    from dispatch.auth.models import UserOrganization, UserRegister
    from dispatch.database.core import refetch_db_session

    db_session = refetch_db_session(organization_slug=organization)
    user = user_service.get_by_email(email=email, db_session=db_session)
    if user:
        click.secho(f"User already exists. Email: {email}", fg="red")
        return

    user_organization = UserOrganization(role=role, organization={"name": organization})
    user_service.create(
        user_in=UserRegister(email=email, password=password, organizations=[user_organization]),
        db_session=db_session,
        organization=organization,
    )
    click.secho("User registered successfully.", fg="green")


@dispatch_user.command("update")
@click.argument("email")
@click.option(
    "--organization",
    "-o",
    required=True,
    help="Organization to set role for.",
)
@click.option(
    "--role",
    "-r",
    required=True,
    type=click.Choice(UserRoles),
    help="Role to be assigned to the user.",
)
def update_user(email: str, role: str, organization: str):
    """Updates a user's roles."""
    from dispatch.auth import service as user_service
    from dispatch.auth.models import UserOrganization, UserUpdate
    from dispatch.database.core import SessionLocal

    db_session = SessionLocal()
    user = user_service.get_by_email(email=email, db_session=db_session)
    if not user:
        click.secho(f"No user found. Email: {email}", fg="red")
        return

    organization = UserOrganization(role=role, organization={"name": organization})
    user_service.update(
        user=user,
        user_in=UserUpdate(id=user.id, organizations=[organization]),
        db_session=db_session,
    )
    click.secho("User successfully updated.", fg="green")


@dispatch_user.command("reset")
@click.argument("email")
@click.password_option()
def reset_user_password(email: str, password: str):
    """Resets a user's password."""
    from dispatch.auth import service as user_service
    from dispatch.auth.models import UserUpdate
    from dispatch.database.core import SessionLocal

    db_session = SessionLocal()
    user = user_service.get_by_email(email=email, db_session=db_session)
    if not user:
        click.secho(f"No user found. Email: {email}", fg="red")
        return

    user_service.update(
        user=user, user_in=UserUpdate(id=user.id, password=password), db_session=db_session
    )
    click.secho("User successfully updated.", fg="green")


@dispatch_cli.group("database")
def dispatch_database():
    """Container for all dispatch database commands."""
    pass


@dispatch_database.command("init")
def database_init():
    """Initializes a new database."""
    click.echo("Initializing new database...")
    from .database.core import engine
    from .database.manage import init_database

    init_database(engine)
    click.secho("Success.", fg="green")


@dispatch_database.command("restore")
@click.option(
    "--dump-file",
    default="dispatch-backup.dump",
    help="Path to a PostgreSQL text format dump file.",
)
def restore_database(dump_file):
    """Restores the database via psql."""
    from sh import ErrorReturnCode_1, createdb, psql

    from dispatch.config import (
        DATABASE_CREDENTIALS,
        DATABASE_HOSTNAME,
        DATABASE_NAME,
        DATABASE_PORT,
    )

    username, password = str(DATABASE_CREDENTIALS).split(":")

    try:
        print(
            createdb(
                "-h",
                DATABASE_HOSTNAME,
                "-p",
                DATABASE_PORT,
                "-U",
                username,
                DATABASE_NAME,
                _env={"PGPASSWORD": password},
            )
        )
    except ErrorReturnCode_1:
        print("Database already exists.")

    print(
        psql(
            "-h",
            DATABASE_HOSTNAME,
            "-p",
            DATABASE_PORT,
            "-U",
            username,
            "-d",
            DATABASE_NAME,
            "-f",
            dump_file,
            _env={"PGPASSWORD": password},
        )
    )
    click.secho("Success.", fg="green")


@dispatch_database.command("dump")
@click.option(
    "--dump-file",
    default="dispatch-backup.dump",
    help="Path to a PostgreSQL text format dump file.",
)
def dump_database(dump_file):
    """Dumps the database via pg_dump."""
    from sh import pg_dump

    from dispatch.config import (
        DATABASE_CREDENTIALS,
        DATABASE_HOSTNAME,
        DATABASE_NAME,
        DATABASE_PORT,
    )

    username, password = str(DATABASE_CREDENTIALS).split(":")

    pg_dump(
        "-f",
        dump_file,
        "-h",
        DATABASE_HOSTNAME,
        "-p",
        DATABASE_PORT,
        "-U",
        username,
        DATABASE_NAME,
        _env={"PGPASSWORD": password},
    )


@dispatch_database.command("drop")
def drop_database():
    """Drops all data in database."""
    from sqlalchemy_utils import database_exists, drop_database

    database_hostname = click.prompt(
        f"Please enter the database hostname (env = {config.DATABASE_HOSTNAME})"
    )
    database_name = click.prompt(f"Please enter the database name (env = {config.DATABASE_NAME})")
    sqlalchemy_database_uri = f"postgresql+psycopg2://{config._DATABASE_CREDENTIAL_USER}:{config._QUOTED_DATABASE_PASSWORD}@{database_hostname}:{config.DATABASE_PORT}/{database_name}"

    if database_exists(str(sqlalchemy_database_uri)):
        if click.confirm(
            f"Are you sure you want to drop database: '{database_hostname}:{database_name}'?"
        ):
            drop_database(str(sqlalchemy_database_uri))
            click.secho("Success.", fg="green")
    else:
        click.secho(f"Database '{database_hostname}:{database_name}' does not exist!!!", fg="red")


@dispatch_database.command("upgrade")
@click.option(
    "--tag", default=None, help="Arbitrary 'tag' name - can be used by custom env.py scripts."
)
@click.option(
    "--sql",
    is_flag=True,
    default=False,
    help="Don't emit SQL to database - dump to standard output instead.",
)
@click.option("--revision", nargs=1, default="head", help="Revision identifier.")
@click.option("--revision-type", type=click.Choice(["core", "tenant"]))
def upgrade_database(tag, sql, revision, revision_type):
    """Upgrades database schema to newest version."""
    import sqlalchemy
    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig
    from sqlalchemy import inspect
    from sqlalchemy_utils import database_exists

    from .database.core import engine
    from .database.manage import init_database

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)

    if not database_exists(str(config.SQLALCHEMY_DATABASE_URI)):
        click.secho("Found no database to upgrade, initializing new database...")
        init_database(engine)
    else:
        conn = engine.connect()

        # detect if we need to convert to a multi-tenant schema structure
        schema_names = inspect(engine).get_schema_names()
        if "dispatch_core" not in schema_names:
            click.secho("Detected single tenant database, converting to multi-tenant...")
            conn.execute(sqlalchemy.text(open(config.ALEMBIC_MULTI_TENANT_MIGRATION_PATH).read()))

        if revision_type:
            if revision_type == "core":
                path = config.ALEMBIC_CORE_REVISION_PATH

            elif revision_type == "tenant":
                path = config.ALEMBIC_TENANT_REVISION_PATH

            alembic_cfg.set_main_option("script_location", path)
            alembic_command.upgrade(alembic_cfg, revision, sql=sql, tag=tag)
        else:
            for path in [config.ALEMBIC_CORE_REVISION_PATH, config.ALEMBIC_TENANT_REVISION_PATH]:
                alembic_cfg.set_main_option("script_location", path)
                alembic_command.upgrade(alembic_cfg, revision, sql=sql, tag=tag)

    click.secho("Success.", fg="green")


@dispatch_database.command("merge")
@click.argument("revisions", nargs=-1)
@click.option("--revision-type", type=click.Choice(["core", "tenant"]), default="core")
@click.option("--message")
def merge_revisions(revisions, revision_type, message):
    """Combines two revisions."""
    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)
    if revision_type == "core":
        path = config.ALEMBIC_CORE_REVISION_PATH

    elif revision_type == "tenant":
        path = config.ALEMBIC_TENANT_REVISION_PATH

    alembic_cfg.set_main_option("script_location", path)
    alembic_command.merge(alembic_cfg, revisions, message=message)


@dispatch_database.command("heads")
@click.option("--revision-type", type=click.Choice(["core", "tenant"]), default="core")
def head_database(revision_type):
    """Shows the heads of the database."""
    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)
    if revision_type == "core":
        path = config.ALEMBIC_CORE_REVISION_PATH

    elif revision_type == "tenant":
        path = config.ALEMBIC_TENANT_REVISION_PATH

    alembic_cfg.set_main_option("script_location", path)
    alembic_command.heads(alembic_cfg)


@dispatch_database.command("history")
@click.option("--revision-type", type=click.Choice(["core", "tenant"]), default="core")
def history_database(revision_type):
    """Shows the history of the database."""
    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)
    if revision_type == "core":
        path = config.ALEMBIC_CORE_REVISION_PATH

    elif revision_type == "tenant":
        path = config.ALEMBIC_TENANT_REVISION_PATH

    alembic_cfg.set_main_option("script_location", path)
    alembic_command.history(alembic_cfg)


@dispatch_database.command("downgrade")
@click.option(
    "--tag", default=None, help="Arbitrary 'tag' name - can be used by custom env.py scripts."
)
@click.option(
    "--sql",
    is_flag=True,
    default=False,
    help="Don't emit SQL to database - dump to standard output instead.",
)
@click.option("--revision", nargs=1, default="head", help="Revision identifier.")
@click.option("--revision-type", type=click.Choice(["core", "tenant"]), default="core")
def downgrade_database(tag, sql, revision, revision_type):
    """Downgrades database schema to next newest version."""
    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig

    if sql and revision == "-1":
        revision = "head:-1"

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)
    if revision_type == "core":
        path = config.ALEMBIC_CORE_REVISION_PATH

    elif revision_type == "tenant":
        path = config.ALEMBIC_TENANT_REVISION_PATH

    alembic_cfg.set_main_option("script_location", path)
    alembic_command.downgrade(alembic_cfg, revision, sql=sql, tag=tag)
    click.secho("Success.", fg="green")


@dispatch_database.command("stamp")
@click.argument("revision", nargs=1, default="head")
@click.option("--revision-type", type=click.Choice(["core", "tenant"]), default="core")
@click.option(
    "--tag", default=None, help="Arbitrary 'tag' name - can be used by custom env.py scripts."
)
@click.option(
    "--sql",
    is_flag=True,
    default=False,
    help="Don't emit SQL to database - dump to standard output instead.",
)
def stamp_database(revision, revision_type, tag, sql):
    """Forces the database to a given revision."""
    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)

    if revision_type == "core":
        path = config.ALEMBIC_CORE_REVISION_PATH

    elif revision_type == "tenant":
        path = config.ALEMBIC_TENANT_REVISION_PATH

    alembic_cfg.set_main_option("script_location", path)
    alembic_command.stamp(alembic_cfg, revision, sql=sql, tag=tag)


@dispatch_database.command("revision")
@click.option("-m", "--message", default=None, help="Revision message")
@click.option(
    "--autogenerate",
    is_flag=True,
    help=(
        "Populate revision script with candidate migration "
        "operations, based on comparison of database to model"
    ),
)
@click.option("--revision-type", type=click.Choice(["core", "tenant"]))
@click.option(
    "--sql", is_flag=True, help=("Don't emit SQL to database - dump to standard output " "instead")
)
@click.option(
    "--head",
    default="head",
    help=("Specify head revision or <branchname>@head to base new " "revision on"),
)
@click.option(
    "--splice", is_flag=True, help=('Allow a non-head revision as the "head" to splice onto')
)
@click.option(
    "--branch-label", default=None, help=("Specify a branch label to apply to the new revision")
)
@click.option(
    "--version-path", default=None, help=("Specify specific path from config for version file")
)
@click.option(
    "--rev-id", default=None, help=("Specify a hardcoded revision id instead of generating " "one")
)
def revision_database(
    message, autogenerate, revision_type, sql, head, splice, branch_label, version_path, rev_id
):
    """Create new database revision."""
    import types

    from alembic import command as alembic_command
    from alembic.config import Config as AlembicConfig

    alembic_cfg = AlembicConfig(config.ALEMBIC_INI_PATH)

    if revision_type:
        if revision_type == "core":
            path = config.ALEMBIC_CORE_REVISION_PATH
        elif revision_type == "tenant":
            path = config.ALEMBIC_TENANT_REVISION_PATH

        alembic_cfg.set_main_option("script_location", path)
        alembic_cfg.cmd_opts = types.SimpleNamespace(cmd="revision")
        alembic_command.revision(
            alembic_cfg,
            message,
            autogenerate=autogenerate,
            sql=sql,
            head=head,
            splice=splice,
            branch_label=branch_label,
            version_path=version_path,
            rev_id=rev_id,
        )
    else:
        for path in [
            config.ALEMBIC_CORE_REVISION_PATH,
            config.ALEMBIC_TENANT_REVISION_PATH,
        ]:
            alembic_cfg.set_main_option("script_location", path)
            alembic_cfg.cmd_opts = types.SimpleNamespace(cmd="revision")
            alembic_command.revision(
                alembic_cfg,
                message,
                autogenerate=autogenerate,
                sql=sql,
                head=head,
                splice=splice,
                branch_label=branch_label,
                version_path=version_path,
                rev_id=rev_id,
            )


@dispatch_cli.group("scheduler")
def dispatch_scheduler():
    """Container for all dispatch scheduler commands."""
    # we need scheduled tasks to be imported
    from .case.scheduled import case_close_reminder, case_triage_reminder  # noqa
    from .case_cost.scheduled import (
        calculate_cases_response_cost,  # noqa
    )
    from .data.source.scheduled import sync_sources  # noqa
    from .document.scheduled import sync_document_terms  # noqa
    from .evergreen.scheduled import create_evergreen_reminders  # noqa
    from .feedback.incident.scheduled import feedback_report_daily  # noqa
    from .feedback.service.scheduled import oncall_shift_feedback  # noqa
    from .incident.scheduled import (
        incident_auto_tagger,  # noqa
    )
    from .incident_cost.scheduled import calculate_incidents_response_cost  # noqa
    from .monitor.scheduled import sync_active_stable_monitors  # noqa
    from .report.scheduled import incident_report_reminders  # noqa
    from .tag.scheduled import build_tag_models, sync_tags  # noqa
    from .task.scheduled import (
        create_incident_tasks_reminders,  # noqa
    )
    from .term.scheduled import sync_terms  # noqa
    from .workflow.scheduled import sync_workflows  # 